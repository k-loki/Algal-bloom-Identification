{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Main ...\n\n \n``config, load, preprocess, train, eval  for  Tick tick bloom``\n\n**Yo DON'T rerun this unless you want to overwrite past models, always fork and do your stuff and \nDON'T forget to change the name**","metadata":{}},{"cell_type":"markdown","source":"**``Mission: NNs on expanding avgs of metadata``**","metadata":{}},{"cell_type":"markdown","source":"# Load imports and dependencies","metadata":{}},{"cell_type":"code","source":"import warnings\nimport sys\nimport os\nimport time\nimport joblib\nimport random\nfrom tqdm import tqdm\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\n\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, activations, losses, metrics, models, optimizers, callbacks\nfrom category_encoders.target_encoder import TargetEncoder\n\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:35:02.150668Z","iopub.execute_input":"2023-01-11T02:35:02.151245Z","iopub.status.idle":"2023-01-11T02:35:08.831058Z","shell.execute_reply.started":"2023-01-11T02:35:02.151152Z","shell.execute_reply":"2023-01-11T02:35:08.829950Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# local utilities imports\nfrom tick_tick_bloom_utils import my_keras_rmse, comp_metric, den2sev_map","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:35:08.832946Z","iopub.execute_input":"2023-01-11T02:35:08.833630Z","iopub.status.idle":"2023-01-11T02:35:08.847925Z","shell.execute_reply.started":"2023-01-11T02:35:08.833595Z","shell.execute_reply":"2023-01-11T02:35:08.846464Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# wandb stuff for tracking\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_login = user_secrets.get_secret(\"wandb_bloom_tracker\")\n\nimport wandb\nwandb.login(key=wandb_login)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:35:08.849684Z","iopub.execute_input":"2023-01-11T02:35:08.850400Z","iopub.status.idle":"2023-01-11T02:35:11.649647Z","shell.execute_reply.started":"2023-01-11T02:35:08.850353Z","shell.execute_reply":"2023-01-11T02:35:11.648764Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"# dot dictionary\nclass dotdict(dict):\n    \"\"\"dot.notation access to dictionary attributes\"\"\"\n    __getattr__ = dict.get\n    __setattr__ = dict.__setitem__\n    __delattr__ = dict.__delitem__\n\n\n# Config\nconfig = {}\nconfig = dotdict(config)\nconfig['RANDOM_SEED'] = 18952\n\n\nconfig['unique_id'] = int(time.time())\nprint(f'unique_id: {config.unique_id}')\nconfig['name'] = f'd128_rmse_mtdata-{config.unique_id}'\n\nconfig['PROJECT_NAME'] = 'tick-tick-bloom'\n# config['DATA_DIR'] = '../data/'\n# config['MODEL_DIR'] = '../models/'\nconfig['SAVE_MODEL'] = True\n\n\n# # Img config\n# config['IMG_SIZE'] = (136, 136)\n# config['CHANNELS'] = 3\n\n# training configuration\nconfig['train'] =  dotdict({\n                        'epochs': 50,\n                        'batch_size': 128,\n                        'validation_split': 0.2,\n                        'shuffle': True,\n                        'verbose': 1\n                        })\n\nconfig['desc'] = \"\"\" xp3-to see how nns perform only on metadata(use data upto the point of availibility.) with rmse loss\"\"\" ","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:35:15.923728Z","iopub.execute_input":"2023-01-11T02:35:15.924066Z","iopub.status.idle":"2023-01-11T02:35:15.932014Z","shell.execute_reply.started":"2023-01-11T02:35:15.924038Z","shell.execute_reply":"2023-01-11T02:35:15.931293Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"unique_id: 1673404515\n","output_type":"stream"}]},{"cell_type":"code","source":"# seed everything\nrandom.seed(config.RANDOM_SEED)\nnp.random.seed(config.RANDOM_SEED)\ntf.random.set_seed(config.RANDOM_SEED)\nos.environ['TF_CUDNN_DETERMINISTIC'] = '1' \nos.environ['TF_DETERMINISTIC_OPS'] = '1'\nos.environ['PYTHONHASHSEED'] = str(config.RANDOM_SEED)\n\n# tf.keras.utils.set_random_seed(config.RANDOM_SEED)  # supposedly sets seed for python, numpy, tf","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:35:17.688299Z","iopub.execute_input":"2023-01-11T02:35:17.689093Z","iopub.status.idle":"2023-01-11T02:35:17.694466Z","shell.execute_reply.started":"2023-01-11T02:35:17.689064Z","shell.execute_reply":"2023-01-11T02:35:17.693630Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"INPUT_METADATA_DIR = '/kaggle/input/ticktickbloomdataset'\n\nmetadata = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'metadata.csv'))\nsub_format = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'submission_format.csv'))\ntrain_labels = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'train_labels.csv'))","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:35:21.988471Z","iopub.execute_input":"2023-01-11T02:35:21.988831Z","iopub.status.idle":"2023-01-11T02:35:22.100036Z","shell.execute_reply.started":"2023-01-11T02:35:21.988799Z","shell.execute_reply":"2023-01-11T02:35:22.099111Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# IMG_DIR = '/kaggle/input/pull-landsat-data-v1-500m/landsat8_500m_v1'   # landsat 8 data with raw \n# img_files = os.listdir(IMG_DIR)\n# img_file_names = [f.split('.')[0] for f in img_files]\n\n# # get only data for those 1k imgs\n# metadata_subset = metadata[metadata['uid'].isin(img_file_names)]\n# data = metadata_subset[metadata_subset.split == 'train']\n# data = data.merge(train_labels, on='uid')\n\n# test_data = metadata[metadata.split == 'train']","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:35:24.128710Z","iopub.execute_input":"2023-01-11T02:35:24.129031Z","iopub.status.idle":"2023-01-11T02:35:24.136011Z","shell.execute_reply.started":"2023-01-11T02:35:24.129005Z","shell.execute_reply":"2023-01-11T02:35:24.134503Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# def get_imgs(uids) :\n#     imgs = []\n#     for uid in uids:\n#         img_arr = np.load(IMG_DIR + f'/{uid}.npy')\n#         img_arr = np.transpose(img_arr, (2, 1, 0))\n#         # resize img\n#         img_arr = cv2.resize(img_arr, config.IMG_SIZE)\n#         img_arr = img_arr / 255   # normalizeee bro... other wise it's blowing up the networks...\n#         imgs.append(img_arr)\n#     return np.array(imgs) \n\n\n# def get_np_data(split : float = 0.2, task='train'):\n#     \"\"\"Return np data for training and validation.\"\"\"\n#     if task == 'train':\n#         print(\"Loading train and validation data...\")\n#         x_train_uids, x_val_uids, y_train, y_val = train_val_split(\n#             data['uid'],\n#             data.severity,\n#             val_size=split,\n#             random_state=config.RANDOM_SEED,\n#             stratify=data.severity\n#         )\n\n#         x_train = get_imgs(x_train_uids)\n#         x_val = get_imgs(x_val_uids)\n\n#         return x_train, y_train, x_val, y_val\n\n\n#     if task == 'test':\n#         test_ids = test_data.uids\n#         x_test\n#         return x_test","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:35:24.703620Z","iopub.execute_input":"2023-01-11T02:35:24.705005Z","iopub.status.idle":"2023-01-11T02:35:24.710147Z","shell.execute_reply.started":"2023-01-11T02:35:24.704969Z","shell.execute_reply":"2023-01-11T02:35:24.709300Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# x_train, y_train, x_val, y_val = get_np_data()\n# print(y_train.value_counts(normalize=True))\n# print(y_val.value_counts(normalize=True))\n# print('Done')","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:35:24.973938Z","iopub.execute_input":"2023-01-11T02:35:24.974516Z","iopub.status.idle":"2023-01-11T02:35:24.978763Z","shell.execute_reply.started":"2023-01-11T02:35:24.974476Z","shell.execute_reply":"2023-01-11T02:35:24.977925Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#  get data\nmetadata.date = pd.to_datetime(metadata.date)\n\nregion = pd.concat((train_labels, sub_format[['region', 'uid']]), axis=0)\n\ndata = pd.merge(metadata, region, on='uid', how='left')\nprint(data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:38:44.308892Z","iopub.execute_input":"2023-01-11T02:38:44.309205Z","iopub.status.idle":"2023-01-11T02:38:44.339459Z","shell.execute_reply.started":"2023-01-11T02:38:44.309180Z","shell.execute_reply":"2023-01-11T02:38:44.338618Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"(23570, 8)\n","output_type":"stream"}]},{"cell_type":"code","source":"# seasons\nseasons = {\n    1: 1,\n    2: 1,\n    3: 2,\n    4: 2,\n    5: 2,\n    6: 3,\n    7: 3,\n    8: 3,\n    9: 4,\n    10: 4,\n    11: 4,\n    12: 1\n}\n\n\n#  most of the samples are collected in the months of June, July, August.\n\n# add date time fts.\ndata['month'] = data.date.dt.month\ndata['year'] = data.date.dt.year\ndata['week'] = data.date.dt.isocalendar().week\n# data['day_of_year'] = data.date.dt.\ndata['season'] = data.month.map(seasons)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:38:45.128866Z","iopub.execute_input":"2023-01-11T02:38:45.129370Z","iopub.status.idle":"2023-01-11T02:38:45.147349Z","shell.execute_reply.started":"2023-01-11T02:38:45.129344Z","shell.execute_reply":"2023-01-11T02:38:45.146648Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"data.sort_values(by='date', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:38:45.868729Z","iopub.execute_input":"2023-01-11T02:38:45.869246Z","iopub.status.idle":"2023-01-11T02:38:45.881722Z","shell.execute_reply.started":"2023-01-11T02:38:45.869209Z","shell.execute_reply":"2023-01-11T02:38:45.880756Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:38:47.296197Z","iopub.execute_input":"2023-01-11T02:38:47.296800Z","iopub.status.idle":"2023-01-11T02:38:47.316911Z","shell.execute_reply.started":"2023-01-11T02:38:47.296768Z","shell.execute_reply":"2023-01-11T02:38:47.316158Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"        uid   latitude   longitude       date  split   region  severity  \\\n4387   evep  44.847993  -93.476318 2013-01-04  train  midwest       1.0   \n13644  paev  44.822478  -93.367962 2013-01-04  train  midwest       1.0   \n5566   gdxr  44.877646  -93.557842 2013-01-04  train  midwest       1.0   \n6144   guny  44.878889  -93.490833 2013-01-04  train  midwest       1.0   \n5317   fwbt  44.850500  -93.515700 2013-01-04  train  midwest       1.0   \n...     ...        ...         ...        ...    ...      ...       ...   \n12443  nsoi  36.736800 -121.734000 2021-12-29   test     west       NaN   \n17559  thki  36.725400 -121.730000 2021-12-29   test     west       NaN   \n17452  teuu  36.772300 -121.788000 2021-12-29   test     west       NaN   \n14254  prfi  36.751800 -121.742000 2021-12-29   test     west       NaN   \n6864   howu  36.708500 -121.749000 2021-12-29   test     west       NaN   \n\n       density  month  year  week  season  \n4387     115.0      1  2013     1       1  \n13644   1884.0      1  2013     1       1  \n5566    1416.0      1  2013     1       1  \n6144     558.0      1  2013     1       1  \n5317     476.0      1  2013     1       1  \n...        ...    ...   ...   ...     ...  \n12443      NaN     12  2021    52       1  \n17559      NaN     12  2021    52       1  \n17452      NaN     12  2021    52       1  \n14254      NaN     12  2021    52       1  \n6864       NaN     12  2021    52       1  \n\n[23570 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4387</th>\n      <td>evep</td>\n      <td>44.847993</td>\n      <td>-93.476318</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>115.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13644</th>\n      <td>paev</td>\n      <td>44.822478</td>\n      <td>-93.367962</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1884.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5566</th>\n      <td>gdxr</td>\n      <td>44.877646</td>\n      <td>-93.557842</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1416.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6144</th>\n      <td>guny</td>\n      <td>44.878889</td>\n      <td>-93.490833</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>558.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5317</th>\n      <td>fwbt</td>\n      <td>44.850500</td>\n      <td>-93.515700</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>476.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12443</th>\n      <td>nsoi</td>\n      <td>36.736800</td>\n      <td>-121.734000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17559</th>\n      <td>thki</td>\n      <td>36.725400</td>\n      <td>-121.730000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17452</th>\n      <td>teuu</td>\n      <td>36.772300</td>\n      <td>-121.788000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14254</th>\n      <td>prfi</td>\n      <td>36.751800</td>\n      <td>-121.742000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6864</th>\n      <td>howu</td>\n      <td>36.708500</td>\n      <td>-121.749000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>23570 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data['expanding_severity'] = data.severity.expanding().mean()\ndata['expanding_severity'] = data['expanding_severity'].apply(np.round)\ndata","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:38:48.109054Z","iopub.execute_input":"2023-01-11T02:38:48.109432Z","iopub.status.idle":"2023-01-11T02:38:48.239704Z","shell.execute_reply.started":"2023-01-11T02:38:48.109400Z","shell.execute_reply":"2023-01-11T02:38:48.238724Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"        uid   latitude   longitude       date  split   region  severity  \\\n4387   evep  44.847993  -93.476318 2013-01-04  train  midwest       1.0   \n13644  paev  44.822478  -93.367962 2013-01-04  train  midwest       1.0   \n5566   gdxr  44.877646  -93.557842 2013-01-04  train  midwest       1.0   \n6144   guny  44.878889  -93.490833 2013-01-04  train  midwest       1.0   \n5317   fwbt  44.850500  -93.515700 2013-01-04  train  midwest       1.0   \n...     ...        ...         ...        ...    ...      ...       ...   \n12443  nsoi  36.736800 -121.734000 2021-12-29   test     west       NaN   \n17559  thki  36.725400 -121.730000 2021-12-29   test     west       NaN   \n17452  teuu  36.772300 -121.788000 2021-12-29   test     west       NaN   \n14254  prfi  36.751800 -121.742000 2021-12-29   test     west       NaN   \n6864   howu  36.708500 -121.749000 2021-12-29   test     west       NaN   \n\n       density  month  year  week  season  expanding_severity  \n4387     115.0      1  2013     1       1                 1.0  \n13644   1884.0      1  2013     1       1                 1.0  \n5566    1416.0      1  2013     1       1                 1.0  \n6144     558.0      1  2013     1       1                 1.0  \n5317     476.0      1  2013     1       1                 1.0  \n...        ...    ...   ...   ...     ...                 ...  \n12443      NaN     12  2021    52       1                 2.0  \n17559      NaN     12  2021    52       1                 2.0  \n17452      NaN     12  2021    52       1                 2.0  \n14254      NaN     12  2021    52       1                 2.0  \n6864       NaN     12  2021    52       1                 2.0  \n\n[23570 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n      <th>expanding_severity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4387</th>\n      <td>evep</td>\n      <td>44.847993</td>\n      <td>-93.476318</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>115.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>13644</th>\n      <td>paev</td>\n      <td>44.822478</td>\n      <td>-93.367962</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1884.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5566</th>\n      <td>gdxr</td>\n      <td>44.877646</td>\n      <td>-93.557842</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1416.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6144</th>\n      <td>guny</td>\n      <td>44.878889</td>\n      <td>-93.490833</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>558.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5317</th>\n      <td>fwbt</td>\n      <td>44.850500</td>\n      <td>-93.515700</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>476.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12443</th>\n      <td>nsoi</td>\n      <td>36.736800</td>\n      <td>-121.734000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17559</th>\n      <td>thki</td>\n      <td>36.725400</td>\n      <td>-121.730000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17452</th>\n      <td>teuu</td>\n      <td>36.772300</td>\n      <td>-121.788000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>14254</th>\n      <td>prfi</td>\n      <td>36.751800</td>\n      <td>-121.742000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>6864</th>\n      <td>howu</td>\n      <td>36.708500</td>\n      <td>-121.749000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>23570 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data = data[data.split == 'train']\ntest_data = data[data.split == 'test']","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:38:52.183764Z","iopub.execute_input":"2023-01-11T02:38:52.184101Z","iopub.status.idle":"2023-01-11T02:38:52.197727Z","shell.execute_reply.started":"2023-01-11T02:38:52.184074Z","shell.execute_reply":"2023-01-11T02:38:52.196846Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# expanding avg of severity\nmse(train_data.severity, train_data.expanding_severity, squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:39:03.573745Z","iopub.execute_input":"2023-01-11T02:39:03.574073Z","iopub.status.idle":"2023-01-11T02:39:03.581501Z","shell.execute_reply.started":"2023-01-11T02:39:03.574047Z","shell.execute_reply":"2023-01-11T02:39:03.580441Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"1.2085810811762927"},"metadata":{}}]},{"cell_type":"code","source":"grp_by_region = data.groupby('region').severity.expanding(1).mean()\ngrp_by_region = grp_by_region.map(np.round)\n\ngrp_by_region['west'].fillna(2, inplace=True)\ngrp_by_region['northeast'].fillna(2, inplace=True)\nprint(grp_by_region.isna().sum())   # 5 --> 0.89416\n\nmse(train_data.severity.sort_index(), grp_by_region.droplevel(0).loc[train_data.index].sort_index(), squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:41:04.728147Z","iopub.execute_input":"2023-01-11T02:41:04.728677Z","iopub.status.idle":"2023-01-11T02:41:04.862152Z","shell.execute_reply.started":"2023-01-11T02:41:04.728640Z","shell.execute_reply":"2023-01-11T02:41:04.861152Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"0.894165010958815"},"metadata":{}}]},{"cell_type":"code","source":"data['expndng_sev_by_reg'] = np.nan\n\nsouth = data.region == 'south'\nmidwest = data.region == 'midwest'\nnortheast = data.region == 'northeast'\nwest = data.region == 'west'\n\ndata.loc[south , 'expndng_sev_by_reg'] = grp_by_region['south']\ndata.loc[midwest , 'expndng_sev_by_reg'] = grp_by_region['midwest']\ndata.loc[northeast , 'expndng_sev_by_reg'] = grp_by_region['northeast']\ndata.loc[west , 'expndng_sev_by_reg'] = grp_by_region['west']\n\nprint(data.shape)\ndata.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:41:07.152745Z","iopub.execute_input":"2023-01-11T02:41:07.153127Z","iopub.status.idle":"2023-01-11T02:41:07.179169Z","shell.execute_reply.started":"2023-01-11T02:41:07.153097Z","shell.execute_reply":"2023-01-11T02:41:07.178579Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"(23570, 14)\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"uid                      0\nlatitude                 0\nlongitude                0\ndate                     0\nsplit                    0\nregion                   0\nseverity              6510\ndensity               6510\nmonth                    0\nyear                     0\nweek                     0\nseason                   0\nexpanding_severity       0\nexpndng_sev_by_reg       0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"data.sort_index()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:41:09.387975Z","iopub.execute_input":"2023-01-11T02:41:09.388779Z","iopub.status.idle":"2023-01-11T02:41:09.418548Z","shell.execute_reply.started":"2023-01-11T02:41:09.388748Z","shell.execute_reply":"2023-01-11T02:41:09.417624Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"        uid   latitude   longitude       date  split   region  severity  \\\n0      aabm  39.080319  -86.430867 2018-05-14  train  midwest       1.0   \n1      aabn  36.559700 -121.510000 2016-08-31   test     west       NaN   \n2      aacd  35.875083  -78.878434 2020-11-19  train    south       1.0   \n3      aaee  35.487000  -79.062133 2016-08-24  train    south       1.0   \n4      aaff  38.049471  -99.827001 2019-07-23  train  midwest       3.0   \n...     ...        ...         ...        ...    ...      ...       ...   \n23565  zzvv  36.708500 -121.749000 2014-12-02   test     west       NaN   \n23566  zzwo  39.792190  -99.971050 2017-06-19  train  midwest       2.0   \n23567  zzwq  35.794000  -79.012551 2015-03-24  train    south       1.0   \n23568  zzyb  35.742000  -79.238600 2016-11-21  train    south       1.0   \n23569  zzzi  39.767323  -96.028617 2015-08-31   test  midwest       NaN   \n\n        density  month  year  week  season  expanding_severity  \\\n0         585.0      5  2018    20       2                 2.0   \n1           NaN      8  2016    35       3                 2.0   \n2         290.0     11  2020    47       4                 2.0   \n3        1614.0      8  2016    34       3                 2.0   \n4      111825.0      7  2019    30       3                 2.0   \n...         ...    ...   ...   ...     ...                 ...   \n23565       NaN     12  2014    49       1                 2.0   \n23566   48510.0      6  2017    25       3                 2.0   \n23567    1271.0      3  2015    13       2                 2.0   \n23568    9682.0     11  2016    47       4                 2.0   \n23569       NaN      8  2015    36       3                 2.0   \n\n       expndng_sev_by_reg  \n0                     2.0  \n1                     4.0  \n2                     2.0  \n3                     2.0  \n4                     2.0  \n...                   ...  \n23565                 4.0  \n23566                 2.0  \n23567                 1.0  \n23568                 2.0  \n23569                 2.0  \n\n[23570 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n      <th>expanding_severity</th>\n      <th>expndng_sev_by_reg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aabm</td>\n      <td>39.080319</td>\n      <td>-86.430867</td>\n      <td>2018-05-14</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>585.0</td>\n      <td>5</td>\n      <td>2018</td>\n      <td>20</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aabn</td>\n      <td>36.559700</td>\n      <td>-121.510000</td>\n      <td>2016-08-31</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>2016</td>\n      <td>35</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aacd</td>\n      <td>35.875083</td>\n      <td>-78.878434</td>\n      <td>2020-11-19</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>290.0</td>\n      <td>11</td>\n      <td>2020</td>\n      <td>47</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aaee</td>\n      <td>35.487000</td>\n      <td>-79.062133</td>\n      <td>2016-08-24</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>1614.0</td>\n      <td>8</td>\n      <td>2016</td>\n      <td>34</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aaff</td>\n      <td>38.049471</td>\n      <td>-99.827001</td>\n      <td>2019-07-23</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>3.0</td>\n      <td>111825.0</td>\n      <td>7</td>\n      <td>2019</td>\n      <td>30</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23565</th>\n      <td>zzvv</td>\n      <td>36.708500</td>\n      <td>-121.749000</td>\n      <td>2014-12-02</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2014</td>\n      <td>49</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>23566</th>\n      <td>zzwo</td>\n      <td>39.792190</td>\n      <td>-99.971050</td>\n      <td>2017-06-19</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>2.0</td>\n      <td>48510.0</td>\n      <td>6</td>\n      <td>2017</td>\n      <td>25</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>23567</th>\n      <td>zzwq</td>\n      <td>35.794000</td>\n      <td>-79.012551</td>\n      <td>2015-03-24</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>1271.0</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>13</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>23568</th>\n      <td>zzyb</td>\n      <td>35.742000</td>\n      <td>-79.238600</td>\n      <td>2016-11-21</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>9682.0</td>\n      <td>11</td>\n      <td>2016</td>\n      <td>47</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>23569</th>\n      <td>zzzi</td>\n      <td>39.767323</td>\n      <td>-96.028617</td>\n      <td>2015-08-31</td>\n      <td>test</td>\n      <td>midwest</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>2015</td>\n      <td>36</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>23570 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# #  Making submission\n\n# expanding_sev_by_reg = data[data.split == 'test'][['uid', 'expndng_sev_by_reg']]\n# expanding_sev_by_reg.expndng_sev_by_reg = expanding_sev_by_reg.expndng_sev_by_reg.astype(int)\n# expanding_sev_by_reg.sort_values(by='uid', inplace=True)\n# expanding_sev_by_reg.reset_index(drop=True, inplace=True)\n# sub_format.severity = expanding_sev_by_reg.expndng_sev_by_reg\n# sub_format.severity.value_counts()  # expected 0.894165010958815","metadata":{"execution":{"iopub.status.busy":"2023-01-10T17:06:23.906918Z","iopub.execute_input":"2023-01-10T17:06:23.908205Z","iopub.status.idle":"2023-01-10T17:06:23.930215Z","shell.execute_reply.started":"2023-01-10T17:06:23.908164Z","shell.execute_reply":"2023-01-10T17:06:23.928747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_format.to_csv('expndng_sev_by_reg_preds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:36:10.122144Z","iopub.execute_input":"2023-01-10T15:36:10.122541Z","iopub.status.idle":"2023-01-10T15:36:10.128689Z","shell.execute_reply.started":"2023-01-10T15:36:10.122511Z","shell.execute_reply":"2023-01-10T15:36:10.127040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# grp_by_week = data.groupby('week').severity.expanding(1).mean()\n# grp_by_week = grp_by_week.map(np.round)\n# print(grp_by_week.isna().sum())  # 105 --> 1.176284\n# mse(train_data.severity.sort_index(), grp_by_week.droplevel(0).sort_index()[:train_data.shape[0]], squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T03:17:16.808360Z","iopub.execute_input":"2023-01-11T03:17:16.808715Z","iopub.status.idle":"2023-01-11T03:17:16.812812Z","shell.execute_reply.started":"2023-01-11T03:17:16.808685Z","shell.execute_reply":"2023-01-11T03:17:16.811908Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# grp_by_month = data.groupby('month').severity.expanding(1).mean()\n# grp_by_month = grp_by_month.map(np.round)\n# print(grp_by_month.isna().sum()) # 5 --> 1.202625\n# mse(train_data.severity.sort_index(), grp_by_month.droplevel(0).sort_index()[:train_data.shape[0]], squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T03:17:19.037948Z","iopub.execute_input":"2023-01-11T03:17:19.038694Z","iopub.status.idle":"2023-01-11T03:17:19.042320Z","shell.execute_reply.started":"2023-01-11T03:17:19.038660Z","shell.execute_reply":"2023-01-11T03:17:19.041747Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"# grp_by_season = train_data.groupby('season').severity.expanding(1).mean()\n# grp_by_season = grp_by_season.map(np.round)\n# print(grp_by_season.isna().sum()) # 0 --> 1.208241\n# mse(train_data.severity.sort_index(), grp_by_season.droplevel(0).sort_index()[:train_data.shape[0]], squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T03:15:51.817935Z","iopub.execute_input":"2023-01-11T03:15:51.818313Z","iopub.status.idle":"2023-01-11T03:15:51.822120Z","shell.execute_reply.started":"2023-01-11T03:15:51.818272Z","shell.execute_reply":"2023-01-11T03:15:51.821121Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"# grp_by_yr = train_data.groupby('year').severity.expanding(1).mean()\n# grp_by_yr = grp_by_yr.map(np.round)\n# grp_by_yr.isna().sum()  6 --> 1.207100\n# mse(train_data.severity.sort_index(), grp_by_yr.droplevel(0).sort_index()[:train_data.shape[0]], squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T03:15:59.338927Z","iopub.execute_input":"2023-01-11T03:15:59.339251Z","iopub.status.idle":"2023-01-11T03:15:59.342926Z","shell.execute_reply.started":"2023-01-11T03:15:59.339224Z","shell.execute_reply":"2023-01-11T03:15:59.342265Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"# #  this seems to be much better than expanding avg severity by region.\n# grp_by_rw = train_data.groupby(['region', 'week']).severity.expanding(1).mean()\n# grp_by_rw = grp_by_rw.map(np.round)\n# grp_by_rw.isna().sum()\n# mse(train_data.severity.sort_index(), grp_by_rw.droplevel(0).droplevel(0).sort_index()[:train_data.shape[0]], squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T15:36:17.487157Z","iopub.execute_input":"2023-01-10T15:36:17.487568Z","iopub.status.idle":"2023-01-10T15:36:17.616078Z","shell.execute_reply.started":"2023-01-10T15:36:17.487530Z","shell.execute_reply":"2023-01-10T15:36:17.613741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['expndng_sev_by_rw_1'] = np.nan\n\ngrp_by_rw = data.groupby(['region', 'week']).severity.expanding(1).mean()\ngrp_by_rw = grp_by_rw.map(np.round)\nprint(\"Missing:\", grp_by_rw.isna().sum())  # 566 missing vaulues  --> 0.82\n\ndata['expndng_sev_by_rw_1'] = grp_by_rw.droplevel(0).droplevel(0).sort_index()\n\n\n# 1 for imputing missing values with expanding_avg_by_reg   # current best option\ndata.expndng_sev_by_rw_1 = np.where(data.expndng_sev_by_rw_1.isna(), data.expndng_sev_by_reg, data.expndng_sev_by_rw_1)\nprint(data.isna().sum())\n\nmse(train_data.severity.sort_index(), data.expndng_sev_by_rw_1.loc[data.split=='train'].sort_index(), squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:44:18.198294Z","iopub.execute_input":"2023-01-11T02:44:18.198624Z","iopub.status.idle":"2023-01-11T02:44:18.351094Z","shell.execute_reply.started":"2023-01-11T02:44:18.198598Z","shell.execute_reply":"2023-01-11T02:44:18.350059Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"566\nuid                       0\nlatitude                  0\nlongitude                 0\ndate                      0\nsplit                     0\nregion                    0\nseverity               6510\ndensity                6510\nmonth                     0\nyear                      0\nweek                      0\nseason                    0\nexpanding_severity        0\nexpndng_sev_by_reg        0\nexpndng_sev_by_rw_1       0\ndtype: int64\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"0.8209593221806205"},"metadata":{}}]},{"cell_type":"code","source":"# #  make submission for expndng_sev_by_rw_1\n\n# expndng_sev_by_rw_1 = data[data.split == 'test'][['uid', 'expndng_sev_by_rw_1']]\n# expndng_sev_by_rw_1.expndng_sev_by_rw_1 = expndng_sev_by_rw_1.expndng_sev_by_rw_1.astype(int)\n# expndng_sev_by_rw_1.sort_values(by='uid', inplace=True)\n# expndng_sev_by_rw_1.reset_index(drop=True, inplace=True)\n# sub_format.severity = expndng_sev_by_rw_1.expndng_sev_by_rw_1\n# sub_format.severity.value_counts()  # expected 0.8209593221806205 got 0.8971","metadata":{"execution":{"iopub.status.busy":"2023-01-10T17:06:11.576629Z","iopub.execute_input":"2023-01-10T17:06:11.577061Z","iopub.status.idle":"2023-01-10T17:06:11.602917Z","shell.execute_reply.started":"2023-01-10T17:06:11.577023Z","shell.execute_reply":"2023-01-10T17:06:11.601701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub_format.to_csv('expndng_sev_by_rw_exreg_preds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T17:07:40.626146Z","iopub.execute_input":"2023-01-10T17:07:40.627385Z","iopub.status.idle":"2023-01-10T17:07:40.641350Z","shell.execute_reply.started":"2023-01-10T17:07:40.627337Z","shell.execute_reply":"2023-01-10T17:07:40.640083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# grp_by_rm = train_data.groupby(['region', 'month']).severity.expanding(1).mean()\n# grp_by_rm = grp_by_rm.map(np.round)\n# grp_by_rm.isna().sum()  # 72 --> 0.8528\n# mse(train_data.severity.sort_index(), grp_by_rm.droplevel(0).droplevel(0).sort_index()[:train_data.shape[0]], squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T03:18:45.833325Z","iopub.execute_input":"2023-01-11T03:18:45.834042Z","iopub.status.idle":"2023-01-11T03:18:45.836994Z","shell.execute_reply.started":"2023-01-11T03:18:45.834015Z","shell.execute_reply":"2023-01-11T03:18:45.836434Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"# grp_by_ry = train_data.groupby(['region', 'year']).severity.expanding(1).mean()\n# grp_by_ry = grp_by_ry.map(np.round)\n# print(grp_by_ry.isna().sum()) # 40 --> 0.88\n# mse(train_data.severity.sort_index(), grp_by_ry.droplevel(0).droplevel(0).sort_index()[:train_data.shape[0]], squared=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-11T03:22:58.472270Z","iopub.execute_input":"2023-01-11T03:22:58.472623Z","iopub.status.idle":"2023-01-11T03:22:58.476732Z","shell.execute_reply.started":"2023-01-11T03:22:58.472597Z","shell.execute_reply":"2023-01-11T03:22:58.475808Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# MY ASSUMPTION: less the missing values --> more inital samples in the group are not test --> less imputations/ffills needed --> much realiable score!\ngrp_by_rs = train_data.groupby(['region', 'season']).severity.expanding(1).mean()\ngrp_by_rs = grp_by_rs.map(np.round)\nprint(grp_by_rs.isna().sum()) # 5 --> .86\nmse(train_data.severity.sort_index(), grp_by_rs.droplevel(0).droplevel(0).sort_index()[:train_data.shape[0]], squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T03:12:55.073381Z","iopub.execute_input":"2023-01-11T03:12:55.073711Z","iopub.status.idle":"2023-01-11T03:12:55.171902Z","shell.execute_reply.started":"2023-01-11T03:12:55.073685Z","shell.execute_reply":"2023-01-11T03:12:55.171038Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"},{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"0.8594349134502333"},"metadata":{}}]},{"cell_type":"code","source":"grp_by_rs = data.groupby(['region', 'season']).severity.expanding(1).mean()\ngrp_by_rs = grp_by_rs.map(np.round)\nprint(grp_by_rs.isna().sum()) # 5 --> .86\n\ndata['expanding_sev_rs'] =  grp_by_rs.droplevel(0).droplevel(0).sort_index()\n# fillna with expanding sev by region\ndata['expanding_sev_rs'] = np.where(data.expanding_sev_rs.isna(), data.expndng_sev_by_reg, data.expanding_sev_rs)\n\nmse(train_data.severity.sort_index(), data['expanding_sev_rs'].sort_index()[data.split == 'train'], squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T05:05:38.587392Z","iopub.execute_input":"2023-01-11T05:05:38.587951Z","iopub.status.idle":"2023-01-11T05:05:38.727006Z","shell.execute_reply.started":"2023-01-11T05:05:38.587922Z","shell.execute_reply":"2023-01-11T05:05:38.725997Z"},"trusted":true},"execution_count":137,"outputs":[{"name":"stdout","text":"5\n","output_type":"stream"},{"execution_count":137,"output_type":"execute_result","data":{"text/plain":"0.8594349134502333"},"metadata":{}}]},{"cell_type":"code","source":"#  make submission for expanding severity by region and season\n\nexpanding_sev_rs = data[data.split == 'test'][['uid', 'expanding_sev_rs']]          # picking up only uids and expanding_sev_rs from test samples\nexpanding_sev_rs.expanding_sev_rs = expanding_sev_rs.expanding_sev_rs.astype(int)   # casting to int\nexpanding_sev_rs.sort_values(by='uid', inplace=True)                                # sorting by uid -- safest option\nexpanding_sev_rs.reset_index(drop=True, inplace=True)                               # matching indexes with submissoin\n\nsub_format.severity = expanding_sev_rs.expanding_sev_rs\nsub_format.severity.value_counts()  # expected 0.8594349134502333","metadata":{"execution":{"iopub.status.busy":"2023-01-11T05:05:39.721024Z","iopub.execute_input":"2023-01-11T05:05:39.721363Z","iopub.status.idle":"2023-01-11T05:05:39.738038Z","shell.execute_reply.started":"2023-01-11T05:05:39.721338Z","shell.execute_reply":"2023-01-11T05:05:39.737198Z"},"trusted":true},"execution_count":138,"outputs":[{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"2    3020\n4    2308\n1    1106\n3      76\nName: severity, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"sub_format.to_csv('expanding_sev_rs_preds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T05:05:49.986623Z","iopub.execute_input":"2023-01-11T05:05:49.987415Z","iopub.status.idle":"2023-01-11T05:05:49.998599Z","shell.execute_reply.started":"2023-01-11T05:05:49.987384Z","shell.execute_reply":"2023-01-11T05:05:49.997854Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"code","source":"sub_format.severity.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T05:06:38.302023Z","iopub.execute_input":"2023-01-11T05:06:38.302625Z","iopub.status.idle":"2023-01-11T05:06:38.310673Z","shell.execute_reply.started":"2023-01-11T05:06:38.302590Z","shell.execute_reply":"2023-01-11T05:06:38.309693Z"},"trusted":true},"execution_count":142,"outputs":[{"execution_count":142,"output_type":"execute_result","data":{"text/plain":"2    0.463902\n4    0.354531\n1    0.169892\n3    0.011674\nName: severity, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"grp_by_rs.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T05:06:05.786582Z","iopub.execute_input":"2023-01-11T05:06:05.787143Z","iopub.status.idle":"2023-01-11T05:06:05.795411Z","shell.execute_reply.started":"2023-01-11T05:06:05.787110Z","shell.execute_reply":"2023-01-11T05:06:05.794436Z"},"trusted":true},"execution_count":141,"outputs":[{"execution_count":141,"output_type":"execute_result","data":{"text/plain":"2.0    0.491110\n4.0    0.249226\n1.0    0.247910\n3.0    0.011755\nName: severity, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"train_labels.severity.value_counts(normalize=True)\n# since test and train dists are almost similar my ideal model should follow this dist!","metadata":{"execution":{"iopub.status.busy":"2023-01-11T03:26:50.791668Z","iopub.execute_input":"2023-01-11T03:26:50.791992Z","iopub.status.idle":"2023-01-11T03:26:50.799659Z","shell.execute_reply.started":"2023-01-11T03:26:50.791967Z","shell.execute_reply":"2023-01-11T03:26:50.798850Z"},"trusted":true},"execution_count":105,"outputs":[{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"1    0.439449\n4    0.207913\n2    0.189859\n3    0.159379\n5    0.003400\nName: severity, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"grp_by_dt = data.groupby('date').severity.expanding(1).mean()\ngrp_by_dt = grp_by_dt.map(np.round)\nprint(grp_by_dt.isna().sum())\n# mse(train_data.severity.sort_index(), grp_by_dt.droplevel(0).sort_index()[:train_data.shape[0]], squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T02:54:36.977761Z","iopub.execute_input":"2023-01-11T02:54:36.978391Z","iopub.status.idle":"2023-01-11T02:54:37.136549Z","shell.execute_reply.started":"2023-01-11T02:54:36.978360Z","shell.execute_reply":"2023-01-11T02:54:37.135646Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"2103\n","output_type":"stream"}]},{"cell_type":"code","source":"# grp_by_rs = train_data.groupby(['region', 'date']).severity.expanding(1).mean()\n# grp_by_rs = grp_by_rs.map(np.round)\n# print(grp_by_rs.isna().sum())  # 3706 --> 0.6547\n# mse(train_data.severity.sort_index(), grp_by_rs.droplevel(0).droplevel(0).sort_index()[:train_data.shape[0]], squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T03:21:18.863583Z","iopub.execute_input":"2023-01-11T03:21:18.864079Z","iopub.status.idle":"2023-01-11T03:21:18.867010Z","shell.execute_reply.started":"2023-01-11T03:21:18.864052Z","shell.execute_reply":"2023-01-11T03:21:18.866458Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"# data['expanding_sev_by_rd'] = np.nan\n# grp_by_rs = data.groupby(['region', 'date']).severity.expanding(1).mean()\n# grp_by_rs = grp_by_rs.map(np.round)\n# print(grp_by_rs.isna().sum()) # 3706 --> 0.82095\n\n# data.expanding_sev_by_rd = np.where(data['expanding_sev_by_rd'].isna(), data.expndng_sev_by_rw_1, data.expanding_sev_by_rd)\n# data.expanding_sev_by_rd.isna().sum()\n\n# mse(train_data.severity.sort_index(), data.expanding_sev_by_rd.loc[data.split=='train'].sort_index(), squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T03:20:17.578319Z","iopub.execute_input":"2023-01-11T03:20:17.578639Z","iopub.status.idle":"2023-01-11T03:20:17.582910Z","shell.execute_reply.started":"2023-01-11T03:20:17.578614Z","shell.execute_reply":"2023-01-11T03:20:17.582053Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"# sum(data.expanding_sev_by_rd == data.expndng_sev_by_rw_1)","metadata":{"execution":{"iopub.status.busy":"2023-01-11T03:20:19.808435Z","iopub.execute_input":"2023-01-11T03:20:19.808784Z","iopub.status.idle":"2023-01-11T03:20:19.817103Z","shell.execute_reply.started":"2023-01-11T03:20:19.808754Z","shell.execute_reply":"2023-01-11T03:20:19.816317Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"23570"},"metadata":{}}]},{"cell_type":"code","source":"data.groupby(['region', 'month']).ngroups      # one group is missing!","metadata":{"execution":{"iopub.status.busy":"2023-01-10T16:44:21.406812Z","iopub.execute_input":"2023-01-10T16:44:21.407304Z","iopub.status.idle":"2023-01-10T16:44:21.420400Z","shell.execute_reply.started":"2023-01-10T16:44:21.407267Z","shell.execute_reply":"2023-01-10T16:44:21.419073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_train = data[data.split == 'train']\nall_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:30:54.650681Z","iopub.execute_input":"2023-01-09T17:30:54.651246Z","iopub.status.idle":"2023-01-09T17:30:54.733198Z","shell.execute_reply.started":"2023-01-09T17:30:54.651198Z","shell.execute_reply":"2023-01-09T17:30:54.731844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = metadata[metadata.split == 'test']\ntest_data = test_data.merge(sub_format, on='uid')\n\ntest_data['month'] = test_data.date.dt.month\ntest_data['year'] = test_data.date.dt.year\ntest_data['season'] = test_data.month.map(seasons)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:32:39.485680Z","iopub.execute_input":"2023-01-09T17:32:39.487041Z","iopub.status.idle":"2023-01-09T17:32:39.509142Z","shell.execute_reply.started":"2023-01-09T17:32:39.486997Z","shell.execute_reply":"2023-01-09T17:32:39.508024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, val = train_test_split(all_train, test_size=0.20, random_state=config.RANDOM_SEED, stratify=all_train.severity)\ntrain.shape, val.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:51:31.020211Z","iopub.execute_input":"2023-01-09T16:51:31.020636Z","iopub.status.idle":"2023-01-09T16:51:31.043541Z","shell.execute_reply.started":"2023-01-09T16:51:31.020604Z","shell.execute_reply":"2023-01-09T16:51:31.042255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_, y_train_ = train[['region', 'month', 'year', 'season']], train['severity'] \nX_val_, y_val_ = val[['region', 'month', 'year', 'season']], val['severity']\n\nX_train_.shape, y_train_.shape, X_val_.shape, y_val_.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:51:31.439972Z","iopub.execute_input":"2023-01-09T16:51:31.440520Z","iopub.status.idle":"2023-01-09T16:51:31.454636Z","shell.execute_reply.started":"2023-01-09T16:51:31.440475Z","shell.execute_reply":"2023-01-09T16:51:31.453297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_ = test_data[['region', 'month', 'year', 'season']]\nX_test_.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:34:08.490863Z","iopub.execute_input":"2023-01-09T17:34:08.492079Z","iopub.status.idle":"2023-01-09T17:34:08.499780Z","shell.execute_reply.started":"2023-01-09T17:34:08.492036Z","shell.execute_reply":"2023-01-09T17:34:08.498871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess","metadata":{}},{"cell_type":"code","source":"# # change labels to 0-3(model works this way) instead of 1-4 given range(given severity)\n# -1 for to make labels look like sparse encoded labels\n\ny_train = y_train_  -1\ny_val = y_val_ - 1\n\n\ny_train.value_counts(normalize=True), y_val.value_counts(normalize=True)  # guessing alwyas 0 gives 43% acc","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:51:35.704989Z","iopub.execute_input":"2023-01-09T16:51:35.706282Z","iopub.status.idle":"2023-01-09T16:51:35.719541Z","shell.execute_reply.started":"2023-01-09T16:51:35.706237Z","shell.execute_reply":"2023-01-09T16:51:35.717744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  target encode the cat fts.\n\nte = TargetEncoder(cols=['region', 'month', 'year', 'season'])\nte.fit(X_train_, y_train)\nX_train =  te.transform(X_train_)\nX_val = te.transform(X_val_)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:51:37.379640Z","iopub.execute_input":"2023-01-09T16:51:37.380099Z","iopub.status.idle":"2023-01-09T16:51:37.570088Z","shell.execute_reply.started":"2023-01-09T16:51:37.380062Z","shell.execute_reply":"2023-01-09T16:51:37.568735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = te.transform(X_test_)\nX_test","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:34:15.520772Z","iopub.execute_input":"2023-01-09T17:34:15.521231Z","iopub.status.idle":"2023-01-09T17:34:15.564248Z","shell.execute_reply.started":"2023-01-09T17:34:15.521191Z","shell.execute_reply":"2023-01-09T17:34:15.562909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(X_train.head())\ndisplay(X_val.head())","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:51:42.280655Z","iopub.execute_input":"2023-01-09T16:51:42.281280Z","iopub.status.idle":"2023-01-09T16:51:42.306339Z","shell.execute_reply.started":"2023-01-09T16:51:42.281237Z","shell.execute_reply":"2023-01-09T16:51:42.305321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def comp_loss(y_true, y_pred):\n    return tf.sqrt(losses.mean_squared_error(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:05:04.034887Z","iopub.execute_input":"2023-01-09T17:05:04.035248Z","iopub.status.idle":"2023-01-09T17:05:04.046413Z","shell.execute_reply.started":"2023-01-09T17:05:04.035217Z","shell.execute_reply":"2023-01-09T17:05:04.045159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    print('Loading model...')\n#     input_shape = (*config.IMG_SIZE, config.CHANNELS)\n\n    input_imgs = layers.Input(shape=(X_train.shape[1],))\n#     x = layers.Conv2D(32, (3, 3), activation='relu')(input_imgs)\n#     x = layers.MaxPooling2D((2, 2))(x)\n#     x = layers.Conv2D(32, (3, 3), activation='relu')(input_imgs)\n#     x = layers.MaxPooling2D((2, 2))(x)\n#     x = layers.Flatten()(x)\n    x = layers.Dense(128, activation='relu')(input_imgs)\n    output = layers.Dense(1)(x)     # regressing the severity level !\n\n    model = models.Model(inputs=input_imgs, outputs=output, name=config.name)\n\n    model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n                    loss=comp_loss,\n                    metrics=[\n                        comp_loss,\n                        metrics.SparseCategoricalAccuracy(name='acc')\n                    ])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:05:04.048110Z","iopub.execute_input":"2023-01-09T17:05:04.049090Z","iopub.status.idle":"2023-01-09T17:05:04.063606Z","shell.execute_reply.started":"2023-01-09T17:05:04.049054Z","shell.execute_reply":"2023-01-09T17:05:04.062072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:05:04.227238Z","iopub.execute_input":"2023-01-09T17:05:04.227921Z","iopub.status.idle":"2023-01-09T17:05:04.265635Z","shell.execute_reply.started":"2023-01-09T17:05:04.227885Z","shell.execute_reply":"2023-01-09T17:05:04.264494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train and eval","metadata":{}},{"cell_type":"code","source":"# np and tf metrics are aggreable, but why evaluate and final epoch's loss and metric each, are different?!\n# 1.5447352189134953 (np) 1.5447352189134953 (tf) , 1.5175646543502808(evaluate), \n\n\n# >> that's coz final epoch also has some batchs which are worst performing and model is still learning and final epoch loss is avg of all those batches.\n# whereas evaluete the model's fixed and no leariing believe in evaluate!","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:05:08.023116Z","iopub.execute_input":"2023-01-09T17:05:08.023607Z","iopub.status.idle":"2023-01-09T17:05:08.030147Z","shell.execute_reply.started":"2023-01-09T17:05:08.023562Z","shell.execute_reply":"2023-01-09T17:05:08.028425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model=get_model(), config=config, x_train=X_train, y_train=y_train):\n    \"\"\"fits given model to x_train and y_train\"\"\"\n    \n    train_config = config['train']\n    my_callbacks = []\n    \n    earlystopping = callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n    my_callbacks.append(earlystopping)\n    \n    try:\n        wandb_callback = wandb.keras.WandbCallback(\n            monitor='val_loss',\n            log_weights=True,\n            log_gradients=True,\n            save_model=False,\n            training_data=(x_train, y_train),\n            log_batch_frequency=None,\n        )\n\n        my_callbacks.append(wandb_callback)\n    except:\n        print('wandb not tracking')\n        \n    print(f'Training model... {config.name}')\n    history = model.fit(\n                x_train, y_train,\n                epochs=train_config.epochs,\n                batch_size=train_config.batch_size, \n                callbacks=my_callbacks, \n                validation_split=0.2, \n                shuffle=True, \n                verbose=1   \n            )\n\n    return model, history","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:07:26.370272Z","iopub.execute_input":"2023-01-09T17:07:26.370896Z","iopub.status.idle":"2023-01-09T17:07:26.419545Z","shell.execute_reply.started":"2023-01-09T17:07:26.370835Z","shell.execute_reply":"2023-01-09T17:07:26.417434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, x_val=X_val, y_val=y_val):\n    print('Evaluating model....')\n    model.evaluate(x_val, y_val, return_dict=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:07:27.828170Z","iopub.execute_input":"2023-01-09T17:07:27.828669Z","iopub.status.idle":"2023-01-09T17:07:27.836219Z","shell.execute_reply.started":"2023-01-09T17:07:27.828635Z","shell.execute_reply":"2023-01-09T17:07:27.834271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with wandb.init(project=config.PROJECT_NAME, config=config, name=config.name):\n    \n    # load nwe model or old saved model\n    model = get_model()\n\n    # train\n    model, history = train(model, config, y_train=y_train)\n    # eval\n    eval_model(model)\n    \n    # classification report\n    y_pred = model.predict(X_val)\n    y_pred_hard = np.round(y_pred)\n    error = mse(y_val, y_pred_hard, squared=False)\n    print(\"Comp Metric: \", error)\n    cr = classification_report(y_val+1, y_pred_hard+1)     # +1 to account for 0-4 as it should be 1-5 originallly\n    print(cr)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:11:09.996281Z","iopub.execute_input":"2023-01-09T17:11:09.996873Z","iopub.status.idle":"2023-01-09T17:12:47.343919Z","shell.execute_reply.started":"2023-01-09T17:11:09.996826Z","shell.execute_reply":"2023-01-09T17:12:47.342251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history.history","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:08:49.448932Z","iopub.execute_input":"2023-01-09T17:08:49.449395Z","iopub.status.idle":"2023-01-09T17:08:49.455251Z","shell.execute_reply.started":"2023-01-09T17:08:49.449360Z","shell.execute_reply":"2023-01-09T17:08:49.453951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.load_model('/kaggle/working/d128_rmse_lndsat8_raw_v1-1673283452.h5', custom_objects={'comp_loss': comp_loss})\npreds = model.predict(X_val)\nint_preds = np.round(preds)\nmse(y_val, int_preds, squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:20:25.020659Z","iopub.execute_input":"2023-01-09T17:20:25.022716Z","iopub.status.idle":"2023-01-09T17:20:25.305114Z","shell.execute_reply.started":"2023-01-09T17:20:25.022654Z","shell.execute_reply":"2023-01-09T17:20:25.303319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"int_preds.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:36:24.550001Z","iopub.execute_input":"2023-01-09T17:36:24.550596Z","iopub.status.idle":"2023-01-09T17:36:24.558866Z","shell.execute_reply.started":"2023-01-09T17:36:24.550547Z","shell.execute_reply":"2023-01-09T17:36:24.557745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series(int_preds.ravel()).value_counts()  # no 3 and 5","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:36:30.110369Z","iopub.execute_input":"2023-01-09T17:36:30.110814Z","iopub.status.idle":"2023-01-09T17:36:30.120638Z","shell.execute_reply.started":"2023-01-09T17:36:30.110759Z","shell.execute_reply":"2023-01-09T17:36:30.119846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save something..","metadata":{}},{"cell_type":"code","source":"# save model\nif config.SAVE_MODEL:\n    model.save(config.name + '.h5')\n    print(\"Model saved as \",config.name + '.h5')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:13:28.661618Z","iopub.execute_input":"2023-01-09T17:13:28.662086Z","iopub.status.idle":"2023-01-09T17:13:28.689416Z","shell.execute_reply.started":"2023-01-09T17:13:28.662052Z","shell.execute_reply":"2023-01-09T17:13:28.687423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make submission","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:21:49.599829Z","iopub.execute_input":"2023-01-09T17:21:49.601224Z","iopub.status.idle":"2023-01-09T17:21:49.612348Z","shell.execute_reply.started":"2023-01-09T17:21:49.601164Z","shell.execute_reply":"2023-01-09T17:21:49.610066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = np.round(model.predict(X_test)).ravel()\ntest_preds = test_preds + 1\nsub_format.severity = test_preds\nsub_format.severity = sub_format.severity.astype(int) \nsub_format.severity.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:42:22.921123Z","iopub.execute_input":"2023-01-09T17:42:22.921540Z","iopub.status.idle":"2023-01-09T17:42:23.150731Z","shell.execute_reply.started":"2023-01-09T17:42:22.921508Z","shell.execute_reply":"2023-01-09T17:42:23.149438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_format.to_csv(f'{config.name}_preds.csv', index=False) # expecting @ 0.9777","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:42:35.225160Z","iopub.execute_input":"2023-01-09T17:42:35.225721Z","iopub.status.idle":"2023-01-09T17:42:35.245311Z","shell.execute_reply.started":"2023-01-09T17:42:35.225682Z","shell.execute_reply":"2023-01-09T17:42:35.243648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# So...\n\n- Just realized that should only use data upto point of availibility.\n- Expanding avg severity by region @ 0.89 best\n","metadata":{}},{"cell_type":"markdown","source":"# ToDos:\n\n- IS this way of modelling with 1 output neuron better compared to 5 as clf\n- Does adding data provide any value??\n- **Try to beat expanding avg_severity_by_region with the help of imgs, Other wise no use for img data**\n- Is there any other way to extract more info than expanding_avg_severity_by_region only from metadata???","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}