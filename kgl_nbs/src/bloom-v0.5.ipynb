{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Main ...\n\n \n``config, load, preprocess, train, eval  for  Tick tick bloom``\n\n**Yo DON'T rerun this unless you want to overwrite past models, always fork and do your stuff and \nDON'T forget to change the name**","metadata":{}},{"cell_type":"markdown","source":"**``Mission: NNs on expanding avg of severity metadata``**\n\n- wondering how nns perform on metadata!","metadata":{}},{"cell_type":"markdown","source":"# Load imports and dependencies","metadata":{}},{"cell_type":"code","source":"import warnings\nimport sys\nimport os\nimport time\nimport joblib\nimport random\nfrom tqdm import tqdm\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\n\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import OrdinalEncoder\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, activations, losses, metrics, models, optimizers, callbacks\nfrom category_encoders.target_encoder import TargetEncoder\n\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:28:51.119388Z","iopub.execute_input":"2023-01-12T04:28:51.119786Z","iopub.status.idle":"2023-01-12T04:28:51.138074Z","shell.execute_reply.started":"2023-01-12T04:28:51.119754Z","shell.execute_reply":"2023-01-12T04:28:51.136942Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# local utilities imports\nfrom tick_tick_bloom_utils import comp_metric, den2sev_map","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:28:51.964662Z","iopub.execute_input":"2023-01-12T04:28:51.966016Z","iopub.status.idle":"2023-01-12T04:28:51.972007Z","shell.execute_reply.started":"2023-01-12T04:28:51.965944Z","shell.execute_reply":"2023-01-12T04:28:51.971054Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# wandb stuff for tracking\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_login = user_secrets.get_secret(\"wandb_bloom_tracker\")\n\nimport wandb\nwandb.login(key=wandb_login)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:28:53.934699Z","iopub.execute_input":"2023-01-12T04:28:53.935129Z","iopub.status.idle":"2023-01-12T04:28:54.462258Z","shell.execute_reply.started":"2023-01-12T04:28:53.935094Z","shell.execute_reply":"2023-01-12T04:28:54.460782Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"# dot dictionary\nclass dotdict(dict):\n    \"\"\"dot.notation access to dictionary attributes\"\"\"\n    __getattr__ = dict.get\n    __setattr__ = dict.__setitem__\n    __delattr__ = dict.__delitem__\n\n\n# Config\nconfig = {}\nconfig = dotdict(config)\nconfig['RANDOM_SEED'] = 18952\n\n\nconfig['unique_id'] = int(time.time())\nprint(f'unique_id: {config.unique_id}')\nconfig['name'] = f'd128_clf_mtdata-{config.unique_id}'\n\nconfig['PROJECT_NAME'] = 'tick-tick-bloom'\n# config['DATA_DIR'] = '../data/'\n# config['MODEL_DIR'] = '../models/'\nconfig['SAVE_MODEL'] = True\n\n\n# # Img config\n# config['IMG_SIZE'] = (136, 136)\n# config['CHANNELS'] = 3\n\n# training configuration\nconfig['train'] =  dotdict({\n                        'epochs': 100,\n                        'batch_size': 256,\n                        'validation_split': 0.2,\n                        'shuffle': True,\n                        'verbose': 1,\n                        'lr' : 1e-5\n                        })\n\nconfig['desc'] = \"\"\"\nxp3-to see how nns perform only on metadata(use data upto the point of availibility.)\nrmse vs log-loss which is better?? or both could be worst than gbs!\n\"\"\" ","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:35:25.943431Z","iopub.execute_input":"2023-01-12T04:35:25.943937Z","iopub.status.idle":"2023-01-12T04:35:25.955494Z","shell.execute_reply.started":"2023-01-12T04:35:25.943895Z","shell.execute_reply":"2023-01-12T04:35:25.953858Z"},"trusted":true},"execution_count":116,"outputs":[{"name":"stdout","text":"unique_id: 1673498125\n","output_type":"stream"}]},{"cell_type":"code","source":"# seed everything\ndef seed_everything(seed=config.RANDOM_SEED):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1' \n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\n# tf.keras.utils.set_random_seed(config.RANDOM_SEED)  # supposedly sets seed for python, numpy, tf\n\nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:35:28.623762Z","iopub.execute_input":"2023-01-12T04:35:28.624179Z","iopub.status.idle":"2023-01-12T04:35:28.640816Z","shell.execute_reply.started":"2023-01-12T04:35:28.624146Z","shell.execute_reply":"2023-01-12T04:35:28.639410Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def keras_rmse_clf(y_true, y_pred):\n    \"\"\"\n    valid competetion metric for clf type settings.\n    Can be trusted!\n    y_true and y_pred should be [0-4]\n    \"\"\"\n    y_pred = tf.argmax(y_pred, axis=1)\n    y_pred = tf.cast(y_pred, tf.float16)\n    y_true = tf.cast(y_true, tf.float16)\n    squared_difference = tf.square(y_true - y_pred)\n    return tf.sqrt(tf.reduce_mean(squared_difference, axis=-1))\n\ndef keras_rmse_reg(y_true, y_pred):\n    \"\"\"\n    valid competetion metric for reg type settings.\n    Can be trusted!\n    y_true and y_pred should be [0-4]\n    \"\"\"\n    y_pred = tf.math.round(y_pred)\n    y_pred = tf.cast(y_pred, tf.float16)\n    y_true = tf.cast(y_true, tf.float16)\n    squared_difference = tf.square(y_true - y_pred)\n    return tf.sqrt(tf.reduce_mean(squared_difference, axis=-1))\n\n\ndef rmse_loss(y_true, y_pred):\n    \"\"\"loss func to use in reg type settings\"\"\"\n    return tf.sqrt(losses.mean_squared_error(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:32:55.917542Z","iopub.execute_input":"2023-01-12T04:32:55.918029Z","iopub.status.idle":"2023-01-12T04:32:55.928723Z","shell.execute_reply.started":"2023-01-12T04:32:55.917992Z","shell.execute_reply":"2023-01-12T04:32:55.927131Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"INPUT_METADATA_DIR = '/kaggle/input/ticktickbloomdataset'\n\nmetadata = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'metadata.csv'))\nsub_format = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'submission_format.csv'))\ntrain_labels = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'train_labels.csv'))","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:04.444429Z","iopub.execute_input":"2023-01-12T04:29:04.445365Z","iopub.status.idle":"2023-01-12T04:29:04.513989Z","shell.execute_reply.started":"2023-01-12T04:29:04.445303Z","shell.execute_reply":"2023-01-12T04:29:04.512744Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# IMG_DIR = '/kaggle/input/pull-landsat-data-v1-500m/landsat8_500m_v1'   # landsat 8 data with raw \n# img_files = os.listdir(IMG_DIR)\n# img_file_names = [f.split('.')[0] for f in img_files]\n\n# # get only data for those 1k imgs\n# metadata_subset = metadata[metadata['uid'].isin(img_file_names)]\n# data = metadata_subset[metadata_subset.split == 'train']\n# data = data.merge(train_labels, on='uid')\n\n# test_data = metadata[metadata.split == 'train']","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:04.624732Z","iopub.execute_input":"2023-01-12T04:29:04.625203Z","iopub.status.idle":"2023-01-12T04:29:04.631709Z","shell.execute_reply.started":"2023-01-12T04:29:04.625160Z","shell.execute_reply":"2023-01-12T04:29:04.630510Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# def get_imgs(uids) :\n#     imgs = []\n#     for uid in uids:\n#         img_arr = np.load(IMG_DIR + f'/{uid}.npy')\n#         img_arr = np.transpose(img_arr, (2, 1, 0))\n#         # resize img\n#         img_arr = cv2.resize(img_arr, config.IMG_SIZE)\n#         img_arr = img_arr / 255   # normalizeee bro... other wise it's blowing up the networks...\n#         imgs.append(img_arr)\n#     return np.array(imgs) \n\n\n# def get_np_data(split : float = 0.2, task='train'):\n#     \"\"\"Return np data for training and validation.\"\"\"\n#     if task == 'train':\n#         print(\"Loading train and validation data...\")\n#         x_train_uids, x_val_uids, y_train, y_val = train_val_split(\n#             data['uid'],\n#             data.severity,\n#             val_size=split,\n#             random_state=config.RANDOM_SEED,\n#             stratify=data.severity\n#         )\n\n#         x_train = get_imgs(x_train_uids)\n#         x_val = get_imgs(x_val_uids)\n\n#         return x_train, y_train, x_val, y_val\n\n\n#     if task == 'test':\n#         test_ids = test_data.uids\n#         x_test\n#         return x_test","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:04.849854Z","iopub.execute_input":"2023-01-12T04:29:04.850616Z","iopub.status.idle":"2023-01-12T04:29:04.856277Z","shell.execute_reply.started":"2023-01-12T04:29:04.850578Z","shell.execute_reply":"2023-01-12T04:29:04.855020Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# x_train, y_train, x_val, y_val = get_np_data()\n# print(y_train.value_counts(normalize=True))\n# print(y_val.value_counts(normalize=True))\n# print('Done')","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:05.084822Z","iopub.execute_input":"2023-01-12T04:29:05.085240Z","iopub.status.idle":"2023-01-12T04:29:05.089915Z","shell.execute_reply.started":"2023-01-12T04:29:05.085207Z","shell.execute_reply":"2023-01-12T04:29:05.088956Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"#  get data\nmetadata.date = pd.to_datetime(metadata.date)\n\nregion = pd.concat((train_labels, sub_format[['region', 'uid']]), axis=0)\n\ndata = pd.merge(metadata, region, on='uid', how='left')\nprint(data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:11.455854Z","iopub.execute_input":"2023-01-12T04:29:11.456375Z","iopub.status.idle":"2023-01-12T04:29:11.500647Z","shell.execute_reply.started":"2023-01-12T04:29:11.456311Z","shell.execute_reply":"2023-01-12T04:29:11.499381Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"(23570, 8)\n","output_type":"stream"}]},{"cell_type":"code","source":"# seasons\nseasons = {\n    1: 1,\n    2: 1,\n    3: 2,\n    4: 2,\n    5: 2,\n    6: 3,\n    7: 3,\n    8: 3,\n    9: 4,\n    10: 4,\n    11: 4,\n    12: 1\n}\n\n\n#  most of the samples are collected in the months of June, July, August.\n\n# add date time fts.\ndata['month'] = data.date.dt.month\ndata['year'] = data.date.dt.year\ndata['week'] = data.date.dt.isocalendar().week\n# data['day_of_year'] = data.date.dt.\ndata['season'] = data.month.map(seasons)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:11.502937Z","iopub.execute_input":"2023-01-12T04:29:11.503277Z","iopub.status.idle":"2023-01-12T04:29:11.530905Z","shell.execute_reply.started":"2023-01-12T04:29:11.503244Z","shell.execute_reply":"2023-01-12T04:29:11.529560Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"data.sort_values(by='date', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:11.534197Z","iopub.execute_input":"2023-01-12T04:29:11.534715Z","iopub.status.idle":"2023-01-12T04:29:11.552117Z","shell.execute_reply.started":"2023-01-12T04:29:11.534667Z","shell.execute_reply":"2023-01-12T04:29:11.550748Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"data['expanding_severity'] = data.severity.expanding().mean()\ndata['expanding_severity'] = data['expanding_severity'].apply(np.round)\ndata","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:11.554316Z","iopub.execute_input":"2023-01-12T04:29:11.554697Z","iopub.status.idle":"2023-01-12T04:29:11.706095Z","shell.execute_reply.started":"2023-01-12T04:29:11.554665Z","shell.execute_reply":"2023-01-12T04:29:11.704904Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"        uid   latitude   longitude       date  split   region  severity  \\\n4387   evep  44.847993  -93.476318 2013-01-04  train  midwest       1.0   \n13644  paev  44.822478  -93.367962 2013-01-04  train  midwest       1.0   \n5566   gdxr  44.877646  -93.557842 2013-01-04  train  midwest       1.0   \n6144   guny  44.878889  -93.490833 2013-01-04  train  midwest       1.0   \n5317   fwbt  44.850500  -93.515700 2013-01-04  train  midwest       1.0   \n...     ...        ...         ...        ...    ...      ...       ...   \n12443  nsoi  36.736800 -121.734000 2021-12-29   test     west       NaN   \n17559  thki  36.725400 -121.730000 2021-12-29   test     west       NaN   \n17452  teuu  36.772300 -121.788000 2021-12-29   test     west       NaN   \n14254  prfi  36.751800 -121.742000 2021-12-29   test     west       NaN   \n6864   howu  36.708500 -121.749000 2021-12-29   test     west       NaN   \n\n       density  month  year  week  season  expanding_severity  \n4387     115.0      1  2013     1       1                 1.0  \n13644   1884.0      1  2013     1       1                 1.0  \n5566    1416.0      1  2013     1       1                 1.0  \n6144     558.0      1  2013     1       1                 1.0  \n5317     476.0      1  2013     1       1                 1.0  \n...        ...    ...   ...   ...     ...                 ...  \n12443      NaN     12  2021    52       1                 2.0  \n17559      NaN     12  2021    52       1                 2.0  \n17452      NaN     12  2021    52       1                 2.0  \n14254      NaN     12  2021    52       1                 2.0  \n6864       NaN     12  2021    52       1                 2.0  \n\n[23570 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n      <th>expanding_severity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4387</th>\n      <td>evep</td>\n      <td>44.847993</td>\n      <td>-93.476318</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>115.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>13644</th>\n      <td>paev</td>\n      <td>44.822478</td>\n      <td>-93.367962</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1884.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5566</th>\n      <td>gdxr</td>\n      <td>44.877646</td>\n      <td>-93.557842</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1416.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6144</th>\n      <td>guny</td>\n      <td>44.878889</td>\n      <td>-93.490833</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>558.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5317</th>\n      <td>fwbt</td>\n      <td>44.850500</td>\n      <td>-93.515700</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>476.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12443</th>\n      <td>nsoi</td>\n      <td>36.736800</td>\n      <td>-121.734000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17559</th>\n      <td>thki</td>\n      <td>36.725400</td>\n      <td>-121.730000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17452</th>\n      <td>teuu</td>\n      <td>36.772300</td>\n      <td>-121.788000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>14254</th>\n      <td>prfi</td>\n      <td>36.751800</td>\n      <td>-121.742000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>6864</th>\n      <td>howu</td>\n      <td>36.708500</td>\n      <td>-121.749000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>23570 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data = data[data.split == 'train']\ntest_data = data[data.split == 'test']","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:11.711158Z","iopub.execute_input":"2023-01-12T04:29:11.711537Z","iopub.status.idle":"2023-01-12T04:29:11.734416Z","shell.execute_reply.started":"2023-01-12T04:29:11.711503Z","shell.execute_reply":"2023-01-12T04:29:11.733107Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# expanding avg of severity\nmse(train_data.severity, train_data.expanding_severity, squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:11.737076Z","iopub.execute_input":"2023-01-12T04:29:11.737580Z","iopub.status.idle":"2023-01-12T04:29:11.746690Z","shell.execute_reply.started":"2023-01-12T04:29:11.737529Z","shell.execute_reply":"2023-01-12T04:29:11.745564Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"1.2085810811762927"},"metadata":{}}]},{"cell_type":"code","source":"grp_by_region = data.groupby('region').severity.expanding(1).mean()\ngrp_by_region = grp_by_region.map(np.round)\n\ngrp_by_region['west'].fillna(2, inplace=True)\ngrp_by_region['northeast'].fillna(2, inplace=True)\nprint(grp_by_region.isna().sum())   # 5 --> 0.89416\n\nprint(mse(train_data.severity.sort_index(), grp_by_region.droplevel(0).loc[train_data.index].sort_index(), squared=False))\n\ndata['expndng_sev_by_reg'] = np.nan\n\nsouth = data.region == 'south'\nmidwest = data.region == 'midwest'\nnortheast = data.region == 'northeast'\nwest = data.region == 'west'\n\ndata.loc[south , 'expndng_sev_by_reg'] = grp_by_region['south']\ndata.loc[midwest , 'expndng_sev_by_reg'] = grp_by_region['midwest']\ndata.loc[northeast , 'expndng_sev_by_reg'] = grp_by_region['northeast']\ndata.loc[west , 'expndng_sev_by_reg'] = grp_by_region['west']\n\nprint(data.shape)\ndata.isna().sum()\n\ndata.sort_index()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:11.849422Z","iopub.execute_input":"2023-01-12T04:29:11.850485Z","iopub.status.idle":"2023-01-12T04:29:12.055169Z","shell.execute_reply.started":"2023-01-12T04:29:11.850445Z","shell.execute_reply":"2023-01-12T04:29:12.054017Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"0\n0.894165010958815\n(23570, 14)\n","output_type":"stream"},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"        uid   latitude   longitude       date  split   region  severity  \\\n0      aabm  39.080319  -86.430867 2018-05-14  train  midwest       1.0   \n1      aabn  36.559700 -121.510000 2016-08-31   test     west       NaN   \n2      aacd  35.875083  -78.878434 2020-11-19  train    south       1.0   \n3      aaee  35.487000  -79.062133 2016-08-24  train    south       1.0   \n4      aaff  38.049471  -99.827001 2019-07-23  train  midwest       3.0   \n...     ...        ...         ...        ...    ...      ...       ...   \n23565  zzvv  36.708500 -121.749000 2014-12-02   test     west       NaN   \n23566  zzwo  39.792190  -99.971050 2017-06-19  train  midwest       2.0   \n23567  zzwq  35.794000  -79.012551 2015-03-24  train    south       1.0   \n23568  zzyb  35.742000  -79.238600 2016-11-21  train    south       1.0   \n23569  zzzi  39.767323  -96.028617 2015-08-31   test  midwest       NaN   \n\n        density  month  year  week  season  expanding_severity  \\\n0         585.0      5  2018    20       2                 2.0   \n1           NaN      8  2016    35       3                 2.0   \n2         290.0     11  2020    47       4                 2.0   \n3        1614.0      8  2016    34       3                 2.0   \n4      111825.0      7  2019    30       3                 2.0   \n...         ...    ...   ...   ...     ...                 ...   \n23565       NaN     12  2014    49       1                 2.0   \n23566   48510.0      6  2017    25       3                 2.0   \n23567    1271.0      3  2015    13       2                 2.0   \n23568    9682.0     11  2016    47       4                 2.0   \n23569       NaN      8  2015    36       3                 2.0   \n\n       expndng_sev_by_reg  \n0                     2.0  \n1                     4.0  \n2                     2.0  \n3                     2.0  \n4                     2.0  \n...                   ...  \n23565                 4.0  \n23566                 2.0  \n23567                 1.0  \n23568                 2.0  \n23569                 2.0  \n\n[23570 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n      <th>expanding_severity</th>\n      <th>expndng_sev_by_reg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aabm</td>\n      <td>39.080319</td>\n      <td>-86.430867</td>\n      <td>2018-05-14</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>585.0</td>\n      <td>5</td>\n      <td>2018</td>\n      <td>20</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aabn</td>\n      <td>36.559700</td>\n      <td>-121.510000</td>\n      <td>2016-08-31</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>2016</td>\n      <td>35</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aacd</td>\n      <td>35.875083</td>\n      <td>-78.878434</td>\n      <td>2020-11-19</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>290.0</td>\n      <td>11</td>\n      <td>2020</td>\n      <td>47</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aaee</td>\n      <td>35.487000</td>\n      <td>-79.062133</td>\n      <td>2016-08-24</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>1614.0</td>\n      <td>8</td>\n      <td>2016</td>\n      <td>34</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aaff</td>\n      <td>38.049471</td>\n      <td>-99.827001</td>\n      <td>2019-07-23</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>3.0</td>\n      <td>111825.0</td>\n      <td>7</td>\n      <td>2019</td>\n      <td>30</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23565</th>\n      <td>zzvv</td>\n      <td>36.708500</td>\n      <td>-121.749000</td>\n      <td>2014-12-02</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2014</td>\n      <td>49</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>23566</th>\n      <td>zzwo</td>\n      <td>39.792190</td>\n      <td>-99.971050</td>\n      <td>2017-06-19</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>2.0</td>\n      <td>48510.0</td>\n      <td>6</td>\n      <td>2017</td>\n      <td>25</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>23567</th>\n      <td>zzwq</td>\n      <td>35.794000</td>\n      <td>-79.012551</td>\n      <td>2015-03-24</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>1271.0</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>13</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>23568</th>\n      <td>zzyb</td>\n      <td>35.742000</td>\n      <td>-79.238600</td>\n      <td>2016-11-21</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>9682.0</td>\n      <td>11</td>\n      <td>2016</td>\n      <td>47</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>23569</th>\n      <td>zzzi</td>\n      <td>39.767323</td>\n      <td>-96.028617</td>\n      <td>2015-08-31</td>\n      <td>test</td>\n      <td>midwest</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>2015</td>\n      <td>36</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>23570 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# # MY ASSUMPTION: less the missing values --> more inital samples in the group are not test --> less imputations/ffills needed --> much realiable score!\n","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:12.139221Z","iopub.execute_input":"2023-01-12T04:29:12.140317Z","iopub.status.idle":"2023-01-12T04:29:12.144802Z","shell.execute_reply.started":"2023-01-12T04:29:12.140276Z","shell.execute_reply":"2023-01-12T04:29:12.143710Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"grp_by_rs = data.groupby(['region', 'season']).severity.expanding(1).mean()\ngrp_by_rs = grp_by_rs.map(np.round)\nprint(grp_by_rs.isna().sum()) # 5 --> .86\n\ndata['expanding_sev_rs'] =  grp_by_rs.droplevel(0).droplevel(0).sort_index()\n# fillna with expanding sev by region\ndata['expanding_sev_rs'] = np.where(data.expanding_sev_rs.isna(), data.expndng_sev_by_reg, data.expanding_sev_rs)\n\nprint(mse(train_data.severity.sort_index(), data['expanding_sev_rs'].sort_index()[data.split == 'train'], squared=False))\n\n# #  make submission for expanding severity by region and season\n\n# expanding_sev_rs = data[data.split == 'test'][['uid', 'expanding_sev_rs']]          # picking up only uids and expanding_sev_rs from test samples\n# expanding_sev_rs.expanding_sev_rs = expanding_sev_rs.expanding_sev_rs.astype(int)   # casting to int\n# expanding_sev_rs.sort_values(by='uid', inplace=True)                                # sorting by uid -- safest option\n# expanding_sev_rs.reset_index(drop=True, inplace=True)                               # matching indexes with submissoin\n\n# sub_format.severity = expanding_sev_rs.expanding_sev_rs\n# sub_format.severity.value_counts()  # expected 0.8594349134502333\n\n# sub_format.to_csv('expanding_sev_rs_preds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:12.169507Z","iopub.execute_input":"2023-01-12T04:29:12.169907Z","iopub.status.idle":"2023-01-12T04:29:12.329355Z","shell.execute_reply.started":"2023-01-12T04:29:12.169873Z","shell.execute_reply":"2023-01-12T04:29:12.328019Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"5\n0.8594349134502333\n","output_type":"stream"}]},{"cell_type":"code","source":"train_labels.severity.value_counts(normalize=True)\n# since test and train dists are almost similar my ideal model should follow this dist!","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:12.331230Z","iopub.execute_input":"2023-01-12T04:29:12.331585Z","iopub.status.idle":"2023-01-12T04:29:12.340418Z","shell.execute_reply.started":"2023-01-12T04:29:12.331555Z","shell.execute_reply":"2023-01-12T04:29:12.339187Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"1    0.439449\n4    0.207913\n2    0.189859\n3    0.159379\n5    0.003400\nName: severity, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:12.474447Z","iopub.execute_input":"2023-01-12T04:29:12.475292Z","iopub.status.idle":"2023-01-12T04:29:12.497064Z","shell.execute_reply.started":"2023-01-12T04:29:12.475255Z","shell.execute_reply":"2023-01-12T04:29:12.495939Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"        uid   latitude  longitude       date  split   region  severity  \\\n4387   evep  44.847993 -93.476318 2013-01-04  train  midwest       1.0   \n13644  paev  44.822478 -93.367962 2013-01-04  train  midwest       1.0   \n5566   gdxr  44.877646 -93.557842 2013-01-04  train  midwest       1.0   \n6144   guny  44.878889 -93.490833 2013-01-04  train  midwest       1.0   \n5317   fwbt  44.850500 -93.515700 2013-01-04  train  midwest       1.0   \n\n       density  month  year  week  season  expanding_severity  \\\n4387     115.0      1  2013     1       1                 1.0   \n13644   1884.0      1  2013     1       1                 1.0   \n5566    1416.0      1  2013     1       1                 1.0   \n6144     558.0      1  2013     1       1                 1.0   \n5317     476.0      1  2013     1       1                 1.0   \n\n       expndng_sev_by_reg  expanding_sev_rs  \n4387                  1.0               1.0  \n13644                 1.0               1.0  \n5566                  1.0               1.0  \n6144                  1.0               1.0  \n5317                  1.0               1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n      <th>expanding_severity</th>\n      <th>expndng_sev_by_reg</th>\n      <th>expanding_sev_rs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4387</th>\n      <td>evep</td>\n      <td>44.847993</td>\n      <td>-93.476318</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>115.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>13644</th>\n      <td>paev</td>\n      <td>44.822478</td>\n      <td>-93.367962</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1884.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5566</th>\n      <td>gdxr</td>\n      <td>44.877646</td>\n      <td>-93.557842</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1416.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6144</th>\n      <td>guny</td>\n      <td>44.878889</td>\n      <td>-93.490833</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>558.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5317</th>\n      <td>fwbt</td>\n      <td>44.850500</td>\n      <td>-93.515700</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>476.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:13.244828Z","iopub.execute_input":"2023-01-12T04:29:13.245727Z","iopub.status.idle":"2023-01-12T04:29:13.263731Z","shell.execute_reply.started":"2023-01-12T04:29:13.245675Z","shell.execute_reply":"2023-01-12T04:29:13.262292Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"uid                      0\nlatitude                 0\nlongitude                0\ndate                     0\nsplit                    0\nregion                   0\nseverity              6510\ndensity               6510\nmonth                    0\nyear                     0\nweek                     0\nseason                   0\nexpanding_severity       0\nexpndng_sev_by_reg       0\nexpanding_sev_rs         0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"all_train = data[data.split == 'train']\nall_train.sort_values(by='uid', inplace=True)\nall_train.reset_index(drop=True, inplace=True)\nall_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:13.384905Z","iopub.execute_input":"2023-01-12T04:29:13.385398Z","iopub.status.idle":"2023-01-12T04:29:13.424528Z","shell.execute_reply.started":"2023-01-12T04:29:13.385360Z","shell.execute_reply":"2023-01-12T04:29:13.423248Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"(17060, 15)"},"metadata":{}}]},{"cell_type":"code","source":"all_train","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:13.725111Z","iopub.execute_input":"2023-01-12T04:29:13.726736Z","iopub.status.idle":"2023-01-12T04:29:13.759068Z","shell.execute_reply.started":"2023-01-12T04:29:13.726675Z","shell.execute_reply":"2023-01-12T04:29:13.758191Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"        uid   latitude  longitude       date  split   region  severity  \\\n0      aabm  39.080319 -86.430867 2018-05-14  train  midwest       1.0   \n1      aacd  35.875083 -78.878434 2020-11-19  train    south       1.0   \n2      aaee  35.487000 -79.062133 2016-08-24  train    south       1.0   \n3      aaff  38.049471 -99.827001 2019-07-23  train  midwest       3.0   \n4      aafl  39.474744 -86.898353 2021-08-23  train  midwest       4.0   \n...     ...        ...        ...        ...    ...      ...       ...   \n17055  zzsv  38.707825 -75.080867 2018-06-27  train    south       3.0   \n17056  zzuq  35.794000 -79.015368 2015-08-06  train    south       3.0   \n17057  zzwo  39.792190 -99.971050 2017-06-19  train  midwest       2.0   \n17058  zzwq  35.794000 -79.012551 2015-03-24  train    south       1.0   \n17059  zzyb  35.742000 -79.238600 2016-11-21  train    south       1.0   \n\n         density  month  year  week  season  expanding_severity  \\\n0          585.0      5  2018    20       2                 2.0   \n1          290.0     11  2020    47       4                 2.0   \n2         1614.0      8  2016    34       3                 2.0   \n3       111825.0      7  2019    30       3                 2.0   \n4      2017313.0      8  2021    34       3                 2.0   \n...          ...    ...   ...   ...     ...                 ...   \n17055   113125.0      6  2018    26       3                 2.0   \n17056   175726.0      8  2015    32       3                 2.0   \n17057    48510.0      6  2017    25       3                 2.0   \n17058     1271.0      3  2015    13       2                 2.0   \n17059     9682.0     11  2016    47       4                 2.0   \n\n       expndng_sev_by_reg  expanding_sev_rs  \n0                     2.0               1.0  \n1                     2.0               2.0  \n2                     2.0               2.0  \n3                     2.0               2.0  \n4                     2.0               2.0  \n...                   ...               ...  \n17055                 2.0               2.0  \n17056                 1.0               2.0  \n17057                 2.0               2.0  \n17058                 1.0               1.0  \n17059                 2.0               2.0  \n\n[17060 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n      <th>expanding_severity</th>\n      <th>expndng_sev_by_reg</th>\n      <th>expanding_sev_rs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aabm</td>\n      <td>39.080319</td>\n      <td>-86.430867</td>\n      <td>2018-05-14</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>585.0</td>\n      <td>5</td>\n      <td>2018</td>\n      <td>20</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aacd</td>\n      <td>35.875083</td>\n      <td>-78.878434</td>\n      <td>2020-11-19</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>290.0</td>\n      <td>11</td>\n      <td>2020</td>\n      <td>47</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aaee</td>\n      <td>35.487000</td>\n      <td>-79.062133</td>\n      <td>2016-08-24</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>1614.0</td>\n      <td>8</td>\n      <td>2016</td>\n      <td>34</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aaff</td>\n      <td>38.049471</td>\n      <td>-99.827001</td>\n      <td>2019-07-23</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>3.0</td>\n      <td>111825.0</td>\n      <td>7</td>\n      <td>2019</td>\n      <td>30</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aafl</td>\n      <td>39.474744</td>\n      <td>-86.898353</td>\n      <td>2021-08-23</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>4.0</td>\n      <td>2017313.0</td>\n      <td>8</td>\n      <td>2021</td>\n      <td>34</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17055</th>\n      <td>zzsv</td>\n      <td>38.707825</td>\n      <td>-75.080867</td>\n      <td>2018-06-27</td>\n      <td>train</td>\n      <td>south</td>\n      <td>3.0</td>\n      <td>113125.0</td>\n      <td>6</td>\n      <td>2018</td>\n      <td>26</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17056</th>\n      <td>zzuq</td>\n      <td>35.794000</td>\n      <td>-79.015368</td>\n      <td>2015-08-06</td>\n      <td>train</td>\n      <td>south</td>\n      <td>3.0</td>\n      <td>175726.0</td>\n      <td>8</td>\n      <td>2015</td>\n      <td>32</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17057</th>\n      <td>zzwo</td>\n      <td>39.792190</td>\n      <td>-99.971050</td>\n      <td>2017-06-19</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>2.0</td>\n      <td>48510.0</td>\n      <td>6</td>\n      <td>2017</td>\n      <td>25</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17058</th>\n      <td>zzwq</td>\n      <td>35.794000</td>\n      <td>-79.012551</td>\n      <td>2015-03-24</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>1271.0</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>13</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>17059</th>\n      <td>zzyb</td>\n      <td>35.742000</td>\n      <td>-79.238600</td>\n      <td>2016-11-21</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>9682.0</td>\n      <td>11</td>\n      <td>2016</td>\n      <td>47</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>17060 rows × 15 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"all_train.expanding_sev_rs.value_counts(normalize=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:14.469694Z","iopub.execute_input":"2023-01-12T04:29:14.471170Z","iopub.status.idle":"2023-01-12T04:29:14.482857Z","shell.execute_reply.started":"2023-01-12T04:29:14.471087Z","shell.execute_reply":"2023-01-12T04:29:14.481554Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"2.0    8558\n1.0    4736\n4.0    3565\n3.0     201\nName: expanding_sev_rs, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"all_train.expndng_sev_by_reg.value_counts(normalize=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:14.634869Z","iopub.execute_input":"2023-01-12T04:29:14.635929Z","iopub.status.idle":"2023-01-12T04:29:14.646498Z","shell.execute_reply.started":"2023-01-12T04:29:14.635883Z","shell.execute_reply":"2023-01-12T04:29:14.644905Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"2.0    10241\n4.0     3769\n1.0     3050\nName: expndng_sev_by_reg, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"sum(all_train.expanding_sev_rs == all_train.expndng_sev_by_reg)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:14.804675Z","iopub.execute_input":"2023-01-12T04:29:14.805140Z","iopub.status.idle":"2023-01-12T04:29:14.813957Z","shell.execute_reply.started":"2023-01-12T04:29:14.805099Z","shell.execute_reply":"2023-01-12T04:29:14.812971Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"12866"},"metadata":{}}]},{"cell_type":"code","source":"test_data = metadata[metadata.split == 'test']\ntest_data = test_data.merge(sub_format, on='uid')\n\ntest_data['month'] = test_data.date.dt.month\ntest_data['year'] = test_data.date.dt.year\ntest_data['season'] = test_data.month.map(seasons)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:15.445082Z","iopub.execute_input":"2023-01-12T04:29:15.445780Z","iopub.status.idle":"2023-01-12T04:29:15.469804Z","shell.execute_reply.started":"2023-01-12T04:29:15.445742Z","shell.execute_reply":"2023-01-12T04:29:15.468659Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"all_train.columns","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:15.644455Z","iopub.execute_input":"2023-01-12T04:29:15.645141Z","iopub.status.idle":"2023-01-12T04:29:15.654008Z","shell.execute_reply.started":"2023-01-12T04:29:15.645091Z","shell.execute_reply":"2023-01-12T04:29:15.652213Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"Index(['uid', 'latitude', 'longitude', 'date', 'split', 'region', 'severity',\n       'density', 'month', 'year', 'week', 'season', 'expanding_severity',\n       'expndng_sev_by_reg', 'expanding_sev_rs'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"req_cols = ['region', 'month', 'year', 'season', 'expanding_sev_rs']","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:16.344591Z","iopub.execute_input":"2023-01-12T04:29:16.345027Z","iopub.status.idle":"2023-01-12T04:29:16.350375Z","shell.execute_reply.started":"2023-01-12T04:29:16.344995Z","shell.execute_reply":"2023-01-12T04:29:16.349232Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"X_ , y_ = all_train[req_cols], all_train['severity']\nX_.shape, y_.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:16.484640Z","iopub.execute_input":"2023-01-12T04:29:16.485868Z","iopub.status.idle":"2023-01-12T04:29:16.495849Z","shell.execute_reply.started":"2023-01-12T04:29:16.485822Z","shell.execute_reply":"2023-01-12T04:29:16.494554Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"((17060, 5), (17060,))"},"metadata":{}}]},{"cell_type":"code","source":"X_.isna().sum().sum(), y_.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:16.664790Z","iopub.execute_input":"2023-01-12T04:29:16.665480Z","iopub.status.idle":"2023-01-12T04:29:16.677061Z","shell.execute_reply.started":"2023-01-12T04:29:16.665442Z","shell.execute_reply":"2023-01-12T04:29:16.675895Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"(0, 0)"},"metadata":{}}]},{"cell_type":"code","source":"X_train_,X_val_, y_train_, y_val_ = train_test_split(X_, y_, test_size=0.20, random_state=config.RANDOM_SEED, stratify=y_)\nX_train_.shape, y_train_.shape, X_val_.shape, y_val_.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:16.859492Z","iopub.execute_input":"2023-01-12T04:29:16.860809Z","iopub.status.idle":"2023-01-12T04:29:16.883527Z","shell.execute_reply.started":"2023-01-12T04:29:16.860753Z","shell.execute_reply":"2023-01-12T04:29:16.882039Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"((13648, 5), (13648,), (3412, 5), (3412,))"},"metadata":{}}]},{"cell_type":"code","source":"test_data['expanding_severity'] = data[data.split == 'test']['expanding_severity'].sort_index().values\ntest_data['expndng_sev_by_reg'] = data[data.split == 'test']['expndng_sev_by_reg'].sort_index().values\ntest_data['expanding_sev_rs'] = data[data.split == 'test']['expanding_sev_rs'].sort_index().values","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:17.064627Z","iopub.execute_input":"2023-01-12T04:29:17.065020Z","iopub.status.idle":"2023-01-12T04:29:17.088241Z","shell.execute_reply.started":"2023-01-12T04:29:17.064988Z","shell.execute_reply":"2023-01-12T04:29:17.087156Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"X_test_ = test_data[req_cols]\nX_test_.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:17.864043Z","iopub.execute_input":"2023-01-12T04:29:17.864467Z","iopub.status.idle":"2023-01-12T04:29:17.875259Z","shell.execute_reply.started":"2023-01-12T04:29:17.864433Z","shell.execute_reply":"2023-01-12T04:29:17.873882Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"(6510, 5)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocess","metadata":{}},{"cell_type":"code","source":"# # change labels to 0-3(model works this way) instead of 1-4 given range(given severity)\n# -1 for to make labels look like sparse encoded labels\n\ny_train = y_train_  -1\ny_val = y_val_ - 1\n\ny_train.value_counts(normalize=True), y_val.value_counts(normalize=True)  # guessing alwyas 0 gives 43% acc","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:18.404741Z","iopub.execute_input":"2023-01-12T04:29:18.405221Z","iopub.status.idle":"2023-01-12T04:29:18.419600Z","shell.execute_reply.started":"2023-01-12T04:29:18.405186Z","shell.execute_reply":"2023-01-12T04:29:18.418187Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"(0.0    0.439478\n 3.0    0.207943\n 1.0    0.189845\n 2.0    0.159364\n 4.0    0.003370\n Name: severity, dtype: float64,\n 0.0    0.439332\n 3.0    0.207796\n 1.0    0.189918\n 2.0    0.159437\n 4.0    0.003517\n Name: severity, dtype: float64)"},"metadata":{}}]},{"cell_type":"code","source":"y = y_ - 1\ny.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:18.624750Z","iopub.execute_input":"2023-01-12T04:29:18.625281Z","iopub.status.idle":"2023-01-12T04:29:18.635991Z","shell.execute_reply.started":"2023-01-12T04:29:18.625241Z","shell.execute_reply":"2023-01-12T04:29:18.634786Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"0.0    7497\n3.0    3547\n1.0    3239\n2.0    2719\n4.0      58\nName: severity, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# #  target encode the cat fts.\n\n# te = TargetEncoder(cols=['region', 'month', 'year', 'season'])\n# te.fit(X_train_, y_train)\n# X_train =  te.transform(X_train_)\n# X_val = te.transform(X_val_)\n\n# X_test = te.transform(X_test_)\n# X_test","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:19.244911Z","iopub.execute_input":"2023-01-12T04:29:19.245402Z","iopub.status.idle":"2023-01-12T04:29:19.250976Z","shell.execute_reply.started":"2023-01-12T04:29:19.245367Z","shell.execute_reply":"2023-01-12T04:29:19.249764Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"X_train_.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:19.404249Z","iopub.execute_input":"2023-01-12T04:29:19.404734Z","iopub.status.idle":"2023-01-12T04:29:19.416001Z","shell.execute_reply.started":"2023-01-12T04:29:19.404689Z","shell.execute_reply":"2023-01-12T04:29:19.414348Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"region               object\nmonth                 int64\nyear                  int64\nseason                int64\nexpanding_sev_rs    float64\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"#  Encode region\n# from category_encoders.ordinal import OrdinalEncoder as COE\n\noe = OrdinalEncoder()\nX_train = oe.fit_transform(X_train_)\nX_test = oe.transform(X_test_)\nX_val = oe.transform(X_val_)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:19.564570Z","iopub.execute_input":"2023-01-12T04:29:19.564962Z","iopub.status.idle":"2023-01-12T04:29:19.593950Z","shell.execute_reply.started":"2023-01-12T04:29:19.564928Z","shell.execute_reply":"2023-01-12T04:29:19.592583Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"X_train = pd.DataFrame(X_train, columns=X_train_.columns, index=X_train_.index)\nX_test = pd.DataFrame(X_test, columns=X_test_.columns, index=X_test_.index)\nX_val = pd.DataFrame(X_val, columns=X_val_.columns, index=X_val_.index)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:20.124500Z","iopub.execute_input":"2023-01-12T04:29:20.124894Z","iopub.status.idle":"2023-01-12T04:29:20.131986Z","shell.execute_reply.started":"2023-01-12T04:29:20.124855Z","shell.execute_reply":"2023-01-12T04:29:20.130709Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"# Normalize values\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:29:20.264501Z","iopub.execute_input":"2023-01-12T04:29:20.264899Z","iopub.status.idle":"2023-01-12T04:29:20.270255Z","shell.execute_reply.started":"2023-01-12T04:29:20.264867Z","shell.execute_reply":"2023-01-12T04:29:20.268715Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def get_model():\n    print('Loading model...')\n#     input_shape = (*config.IMG_SIZE, config.CHANNELS)\n\n    input_imgs = layers.Input(shape=(X_train.shape[1],))\n#     x = layers.Conv2D(32, (3, 3), activation='relu')(input_imgs)\n#     x = layers.MaxPooling2D((2, 2))(x)\n#     x = layers.Conv2D(32, (3, 3), activation='relu')(input_imgs)\n#     x = layers.MaxPooling2D((2, 2))(x)\n#     x = layers.Flatten()(x)\n    x = layers.Dense(128, activation='relu')(input_imgs)\n    output = layers.Dense(1)(x)     # regressing the severity level !\n\n    model = models.Model(inputs=input_imgs, outputs=output, name=config.name)\n\n    model.compile(optimizer=optimizers.Adam(learning_rate=config.train.lr),\n                    # loss=losses.SparseCategoricalCrossentropy(),\n                    loss = rmse_loss,\n                    metrics=[\n                        keras_rmse_reg,\n                        metrics.SparseCategoricalAccuracy(name='acc')\n                    ])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:33:01.746881Z","iopub.execute_input":"2023-01-12T04:33:01.747343Z","iopub.status.idle":"2023-01-12T04:33:01.756508Z","shell.execute_reply.started":"2023-01-12T04:33:01.747293Z","shell.execute_reply":"2023-01-12T04:33:01.755140Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:33:02.182039Z","iopub.execute_input":"2023-01-12T04:33:02.182821Z","iopub.status.idle":"2023-01-12T04:33:02.220253Z","shell.execute_reply.started":"2023-01-12T04:33:02.182738Z","shell.execute_reply":"2023-01-12T04:33:02.219148Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stdout","text":"Loading model...\nModel: \"d128_clf_mtdata-1673497740\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_7 (InputLayer)         [(None, 5)]               0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 128)               768       \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 897\nTrainable params: 897\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:33:12.661599Z","iopub.execute_input":"2023-01-12T04:33:12.662111Z","iopub.status.idle":"2023-01-12T04:33:12.667636Z","shell.execute_reply.started":"2023-01-12T04:33:12.662073Z","shell.execute_reply":"2023-01-12T04:33:12.666146Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":"# Train and eval","metadata":{}},{"cell_type":"code","source":"def train_(model, config=config, x_train=X_train, y_train=y_train, debug=None):\n    \"\"\"fits given model to x_train and y_train\"\"\"\n    \n    train_config = config['train']\n    my_callbacks = []\n    \n#     earlystopping = callbacks.EarlyStopping(patience=15, monitor='val_keras_rmse', restore_best_weights=True)\n#     my_callbacks.append(earlystopping)\n    \n    try:\n        wandb_callback = wandb.keras.WandbCallback(\n            monitor='val_loss',\n            log_weights=True,\n            log_gradients=True,\n            save_model=False,\n            training_data=(x_train, y_train),\n            log_batch_frequency=None,\n        )\n\n        my_callbacks.append(wandb_callback)\n    except:\n        print('wandb not tracking')\n        \n    print(f'Training model... {config.name}')\n    if debug == True:\n        epochs = 1000\n    else:\n        epochs = train_config.epochs\n    history = model.fit(\n                x_train, y_train,\n                epochs=epochs,\n                batch_size=train_config.batch_size, \n                callbacks=my_callbacks, \n                validation_split=0.2, \n                shuffle=True, \n                verbose=1 \n            )\n\n    return model, history\n\n\ndef eval_(model, x_val=X_val, y_val=y_val):\n    print('Evaluating model....')\n    eval_preds = model.evaluate(x_val, y_val, return_dict=True)\n    return eval_preds\n","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:35:36.607495Z","iopub.execute_input":"2023-01-12T04:35:36.607904Z","iopub.status.idle":"2023-01-12T04:35:36.620275Z","shell.execute_reply.started":"2023-01-12T04:35:36.607862Z","shell.execute_reply":"2023-01-12T04:35:36.618598Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"def train_eval(model=None, debug=False):\n    \n    if model is None:\n        print('Getting New model')\n        model = get_model()\n    \n    # train\n    model, history = train_(model, config, X_train, y_train=y_train, debug=debug)  # try to overfit thsi batch\n    # eval\n    eval_preds = eval_(model)\n\n    # classification report\n    y_pred = model.predict(X_val)\n    y_pred_hard = np.argmax(y_pred, axis=1)\n    print(y_pred_hard)\n    error = mse(y_val, y_pred_hard, squared=False)\n    print(\"Comp Metric: \", error)\n    cr = classification_report(y_val+1, y_pred_hard+1)     # +1 to account for 0-4 as it should be 1-5 originallly\n    print(cr)\n    \n    return eval_preds\n","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:35:36.882471Z","iopub.execute_input":"2023-01-12T04:35:36.882960Z","iopub.status.idle":"2023-01-12T04:35:36.893042Z","shell.execute_reply.started":"2023-01-12T04:35:36.882922Z","shell.execute_reply":"2023-01-12T04:35:36.890900Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"config.desc = \"overfitting dense model on mtdata sev by rs rmse-loss\"","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:35:37.082254Z","iopub.execute_input":"2023-01-12T04:35:37.082695Z","iopub.status.idle":"2023-01-12T04:35:37.088430Z","shell.execute_reply.started":"2023-01-12T04:35:37.082651Z","shell.execute_reply":"2023-01-12T04:35:37.087432Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"with wandb.init(project=config.PROJECT_NAME, config=config, name=config.name):\n    train_eval()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:35:38.942527Z","iopub.execute_input":"2023-01-12T04:35:38.943561Z","iopub.status.idle":"2023-01-12T04:38:01.149689Z","shell.execute_reply.started":"2023-01-12T04:35:38.943519Z","shell.execute_reply":"2023-01-12T04:38:01.148295Z"},"trusted":true},"execution_count":121,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.8 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230112_043538-35ij0jar</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/k_loki/tick-tick-bloom/runs/35ij0jar\" target=\"_blank\">d128_clf_mtdata-1673498125</a></strong> to <a href=\"https://wandb.ai/k_loki/tick-tick-bloom\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stdout","text":"Getting New model\nLoading model...\nTraining model... d128_clf_mtdata-1673498125\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"2023-01-12 04:35:55.914710: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n2023-01-12 04:35:55.914994: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n2023-01-12 04:35:55.916500: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n  function_optimizer: function_optimizer did nothing. time = 0.009ms.\n  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n\n","output_type":"stream"},{"name":"stdout","text":"43/43 [==============================] - 1s 8ms/step - loss: 2.4338 - keras_rmse_reg: 2.4254 - acc: 0.4392 - val_loss: 2.4057 - val_keras_rmse_reg: 2.3824 - val_acc: 0.4407\nEpoch 2/100\n43/43 [==============================] - 0s 4ms/step - loss: 2.3668 - keras_rmse_reg: 2.3491 - acc: 0.4392 - val_loss: 2.3386 - val_keras_rmse_reg: 2.3147 - val_acc: 0.4407\nEpoch 3/100\n43/43 [==============================] - 0s 3ms/step - loss: 2.2999 - keras_rmse_reg: 2.2849 - acc: 0.4392 - val_loss: 2.2716 - val_keras_rmse_reg: 2.2601 - val_acc: 0.4407\nEpoch 4/100\n43/43 [==============================] - 0s 3ms/step - loss: 2.2332 - keras_rmse_reg: 2.2310 - acc: 0.4392 - val_loss: 2.2048 - val_keras_rmse_reg: 2.2103 - val_acc: 0.4407\nEpoch 5/100\n43/43 [==============================] - 0s 4ms/step - loss: 2.1665 - keras_rmse_reg: 2.1650 - acc: 0.4392 - val_loss: 2.1378 - val_keras_rmse_reg: 2.1429 - val_acc: 0.4407\nEpoch 6/100\n43/43 [==============================] - 0s 3ms/step - loss: 2.0999 - keras_rmse_reg: 2.1008 - acc: 0.4392 - val_loss: 2.0711 - val_keras_rmse_reg: 2.0788 - val_acc: 0.4407\nEpoch 7/100\n43/43 [==============================] - 0s 3ms/step - loss: 2.0333 - keras_rmse_reg: 2.0389 - acc: 0.4392 - val_loss: 2.0042 - val_keras_rmse_reg: 2.0271 - val_acc: 0.4407\nEpoch 8/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.9668 - keras_rmse_reg: 1.9888 - acc: 0.4392 - val_loss: 1.9376 - val_keras_rmse_reg: 1.9601 - val_acc: 0.4407\nEpoch 9/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.9004 - keras_rmse_reg: 1.9200 - acc: 0.4392 - val_loss: 1.8710 - val_keras_rmse_reg: 1.8971 - val_acc: 0.4407\nEpoch 10/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.8340 - keras_rmse_reg: 1.8717 - acc: 0.4392 - val_loss: 1.8043 - val_keras_rmse_reg: 1.8300 - val_acc: 0.4407\nEpoch 11/100\n43/43 [==============================] - 0s 4ms/step - loss: 1.7678 - keras_rmse_reg: 1.7975 - acc: 0.4392 - val_loss: 1.7380 - val_keras_rmse_reg: 1.7425 - val_acc: 0.4407\nEpoch 12/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.7026 - keras_rmse_reg: 1.7013 - acc: 0.4392 - val_loss: 1.6735 - val_keras_rmse_reg: 1.6740 - val_acc: 0.4407\nEpoch 13/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.6389 - keras_rmse_reg: 1.6289 - acc: 0.4392 - val_loss: 1.6105 - val_keras_rmse_reg: 1.6048 - val_acc: 0.4407\nEpoch 14/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.5773 - keras_rmse_reg: 1.5578 - acc: 0.4392 - val_loss: 1.5496 - val_keras_rmse_reg: 1.5267 - val_acc: 0.4407\nEpoch 15/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.5172 - keras_rmse_reg: 1.4816 - acc: 0.4392 - val_loss: 1.4897 - val_keras_rmse_reg: 1.4608 - val_acc: 0.4407\nEpoch 16/100\n43/43 [==============================] - 0s 4ms/step - loss: 1.4577 - keras_rmse_reg: 1.4193 - acc: 0.4392 - val_loss: 1.4306 - val_keras_rmse_reg: 1.3751 - val_acc: 0.4407\nEpoch 17/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.3993 - keras_rmse_reg: 1.3388 - acc: 0.4392 - val_loss: 1.3733 - val_keras_rmse_reg: 1.3143 - val_acc: 0.4407\nEpoch 18/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.3426 - keras_rmse_reg: 1.2884 - acc: 0.4392 - val_loss: 1.3185 - val_keras_rmse_reg: 1.2469 - val_acc: 0.4407\nEpoch 19/100\n43/43 [==============================] - 0s 4ms/step - loss: 1.2893 - keras_rmse_reg: 1.2243 - acc: 0.4392 - val_loss: 1.2665 - val_keras_rmse_reg: 1.2136 - val_acc: 0.4407\nEpoch 20/100\n43/43 [==============================] - 1s 17ms/step - loss: 1.2382 - keras_rmse_reg: 1.1757 - acc: 0.4392 - val_loss: 1.2198 - val_keras_rmse_reg: 1.1469 - val_acc: 0.4407\nEpoch 21/100\n43/43 [==============================] - 0s 4ms/step - loss: 1.1955 - keras_rmse_reg: 1.1247 - acc: 0.4392 - val_loss: 1.1806 - val_keras_rmse_reg: 1.1088 - val_acc: 0.4407\nEpoch 22/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.1579 - keras_rmse_reg: 1.0908 - acc: 0.4392 - val_loss: 1.1465 - val_keras_rmse_reg: 1.0916 - val_acc: 0.4407\nEpoch 23/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.1243 - keras_rmse_reg: 1.0677 - acc: 0.4392 - val_loss: 1.1151 - val_keras_rmse_reg: 1.0678 - val_acc: 0.4407\nEpoch 24/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.0944 - keras_rmse_reg: 1.0494 - acc: 0.4392 - val_loss: 1.0886 - val_keras_rmse_reg: 1.0553 - val_acc: 0.4407\nEpoch 25/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.0694 - keras_rmse_reg: 1.0325 - acc: 0.4392 - val_loss: 1.0664 - val_keras_rmse_reg: 1.0344 - val_acc: 0.4407\nEpoch 26/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.0487 - keras_rmse_reg: 1.0061 - acc: 0.4392 - val_loss: 1.0480 - val_keras_rmse_reg: 1.0004 - val_acc: 0.4407\nEpoch 27/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.0308 - keras_rmse_reg: 0.9886 - acc: 0.4392 - val_loss: 1.0319 - val_keras_rmse_reg: 0.9824 - val_acc: 0.4407\nEpoch 28/100\n43/43 [==============================] - 0s 3ms/step - loss: 1.0152 - keras_rmse_reg: 0.9782 - acc: 0.4392 - val_loss: 1.0186 - val_keras_rmse_reg: 0.9714 - val_acc: 0.4407\nEpoch 29/100\n43/43 [==============================] - 0s 4ms/step - loss: 1.0025 - keras_rmse_reg: 0.9671 - acc: 0.4392 - val_loss: 1.0074 - val_keras_rmse_reg: 0.9623 - val_acc: 0.4407\nEpoch 30/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.9917 - keras_rmse_reg: 0.9578 - acc: 0.4392 - val_loss: 0.9979 - val_keras_rmse_reg: 0.9615 - val_acc: 0.4407\nEpoch 31/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.9825 - keras_rmse_reg: 0.9539 - acc: 0.4392 - val_loss: 0.9896 - val_keras_rmse_reg: 0.9564 - val_acc: 0.4407\nEpoch 32/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.9743 - keras_rmse_reg: 0.9468 - acc: 0.4392 - val_loss: 0.9817 - val_keras_rmse_reg: 0.9524 - val_acc: 0.4407\nEpoch 33/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.9667 - keras_rmse_reg: 0.9408 - acc: 0.4392 - val_loss: 0.9745 - val_keras_rmse_reg: 0.9487 - val_acc: 0.4407\nEpoch 34/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.9594 - keras_rmse_reg: 0.9405 - acc: 0.4392 - val_loss: 0.9676 - val_keras_rmse_reg: 0.9491 - val_acc: 0.4407\nEpoch 35/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.9522 - keras_rmse_reg: 0.9392 - acc: 0.4392 - val_loss: 0.9606 - val_keras_rmse_reg: 0.9473 - val_acc: 0.4407\nEpoch 36/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.9452 - keras_rmse_reg: 0.9343 - acc: 0.4392 - val_loss: 0.9538 - val_keras_rmse_reg: 0.9425 - val_acc: 0.4407\nEpoch 37/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.9385 - keras_rmse_reg: 0.9243 - acc: 0.4392 - val_loss: 0.9471 - val_keras_rmse_reg: 0.9253 - val_acc: 0.4407\nEpoch 38/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.9317 - keras_rmse_reg: 0.9178 - acc: 0.4392 - val_loss: 0.9403 - val_keras_rmse_reg: 0.9308 - val_acc: 0.4407\nEpoch 39/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.9250 - keras_rmse_reg: 0.9134 - acc: 0.4392 - val_loss: 0.9336 - val_keras_rmse_reg: 0.9315 - val_acc: 0.4407\nEpoch 40/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.9183 - keras_rmse_reg: 0.9062 - acc: 0.4392 - val_loss: 0.9270 - val_keras_rmse_reg: 0.9231 - val_acc: 0.4407\nEpoch 41/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.9118 - keras_rmse_reg: 0.9068 - acc: 0.4392 - val_loss: 0.9207 - val_keras_rmse_reg: 0.9260 - val_acc: 0.4407\nEpoch 42/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.9058 - keras_rmse_reg: 0.9055 - acc: 0.4392 - val_loss: 0.9145 - val_keras_rmse_reg: 0.9212 - val_acc: 0.4407\nEpoch 43/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8997 - keras_rmse_reg: 0.8925 - acc: 0.4392 - val_loss: 0.9085 - val_keras_rmse_reg: 0.9117 - val_acc: 0.4407\nEpoch 44/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8938 - keras_rmse_reg: 0.8839 - acc: 0.4392 - val_loss: 0.9026 - val_keras_rmse_reg: 0.9143 - val_acc: 0.4407\nEpoch 45/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8880 - keras_rmse_reg: 0.8807 - acc: 0.4392 - val_loss: 0.8971 - val_keras_rmse_reg: 0.9106 - val_acc: 0.4407\nEpoch 46/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8824 - keras_rmse_reg: 0.8735 - acc: 0.4392 - val_loss: 0.8914 - val_keras_rmse_reg: 0.8945 - val_acc: 0.4407\nEpoch 47/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8770 - keras_rmse_reg: 0.8637 - acc: 0.4392 - val_loss: 0.8861 - val_keras_rmse_reg: 0.8835 - val_acc: 0.4407\nEpoch 48/100\n43/43 [==============================] - 0s 4ms/step - loss: 0.8719 - keras_rmse_reg: 0.8579 - acc: 0.4392 - val_loss: 0.8810 - val_keras_rmse_reg: 0.8718 - val_acc: 0.4407\nEpoch 49/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8668 - keras_rmse_reg: 0.8399 - acc: 0.4392 - val_loss: 0.8760 - val_keras_rmse_reg: 0.8520 - val_acc: 0.4407\nEpoch 50/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8618 - keras_rmse_reg: 0.8293 - acc: 0.4392 - val_loss: 0.8710 - val_keras_rmse_reg: 0.8399 - val_acc: 0.4407\nEpoch 51/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8570 - keras_rmse_reg: 0.8154 - acc: 0.4392 - val_loss: 0.8662 - val_keras_rmse_reg: 0.8256 - val_acc: 0.4407\nEpoch 52/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8523 - keras_rmse_reg: 0.8133 - acc: 0.4392 - val_loss: 0.8618 - val_keras_rmse_reg: 0.8275 - val_acc: 0.4407\nEpoch 53/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8480 - keras_rmse_reg: 0.8056 - acc: 0.4392 - val_loss: 0.8574 - val_keras_rmse_reg: 0.8223 - val_acc: 0.4407\nEpoch 54/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8436 - keras_rmse_reg: 0.8023 - acc: 0.4392 - val_loss: 0.8531 - val_keras_rmse_reg: 0.8205 - val_acc: 0.4407\nEpoch 55/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8394 - keras_rmse_reg: 0.8008 - acc: 0.4392 - val_loss: 0.8490 - val_keras_rmse_reg: 0.8176 - val_acc: 0.4407\nEpoch 56/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8354 - keras_rmse_reg: 0.7963 - acc: 0.4392 - val_loss: 0.8449 - val_keras_rmse_reg: 0.8150 - val_acc: 0.4407\nEpoch 57/100\n43/43 [==============================] - 0s 4ms/step - loss: 0.8315 - keras_rmse_reg: 0.7912 - acc: 0.4392 - val_loss: 0.8410 - val_keras_rmse_reg: 0.8029 - val_acc: 0.4407\nEpoch 58/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8276 - keras_rmse_reg: 0.7859 - acc: 0.4392 - val_loss: 0.8373 - val_keras_rmse_reg: 0.8018 - val_acc: 0.4407\nEpoch 59/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8239 - keras_rmse_reg: 0.7828 - acc: 0.4392 - val_loss: 0.8335 - val_keras_rmse_reg: 0.8011 - val_acc: 0.4407\nEpoch 60/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8202 - keras_rmse_reg: 0.7817 - acc: 0.4392 - val_loss: 0.8299 - val_keras_rmse_reg: 0.7978 - val_acc: 0.4407\nEpoch 61/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8167 - keras_rmse_reg: 0.7742 - acc: 0.4392 - val_loss: 0.8263 - val_keras_rmse_reg: 0.7894 - val_acc: 0.4407\nEpoch 62/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8132 - keras_rmse_reg: 0.7679 - acc: 0.4392 - val_loss: 0.8227 - val_keras_rmse_reg: 0.7886 - val_acc: 0.4407\nEpoch 63/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8097 - keras_rmse_reg: 0.7659 - acc: 0.4392 - val_loss: 0.8193 - val_keras_rmse_reg: 0.7846 - val_acc: 0.4407\nEpoch 64/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8063 - keras_rmse_reg: 0.7598 - acc: 0.4392 - val_loss: 0.8158 - val_keras_rmse_reg: 0.7788 - val_acc: 0.4407\nEpoch 65/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.8029 - keras_rmse_reg: 0.7557 - acc: 0.4392 - val_loss: 0.8123 - val_keras_rmse_reg: 0.7740 - val_acc: 0.4407\nEpoch 66/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7995 - keras_rmse_reg: 0.7535 - acc: 0.4392 - val_loss: 0.8089 - val_keras_rmse_reg: 0.7740 - val_acc: 0.4407\nEpoch 67/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7961 - keras_rmse_reg: 0.7500 - acc: 0.4392 - val_loss: 0.8054 - val_keras_rmse_reg: 0.7634 - val_acc: 0.4407\nEpoch 68/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7928 - keras_rmse_reg: 0.7413 - acc: 0.4392 - val_loss: 0.8021 - val_keras_rmse_reg: 0.7579 - val_acc: 0.4407\nEpoch 69/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7896 - keras_rmse_reg: 0.7388 - acc: 0.4392 - val_loss: 0.7988 - val_keras_rmse_reg: 0.7538 - val_acc: 0.4407\nEpoch 70/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7864 - keras_rmse_reg: 0.7365 - acc: 0.4392 - val_loss: 0.7956 - val_keras_rmse_reg: 0.7524 - val_acc: 0.4407\nEpoch 71/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7832 - keras_rmse_reg: 0.7326 - acc: 0.4392 - val_loss: 0.7924 - val_keras_rmse_reg: 0.7491 - val_acc: 0.4407\nEpoch 72/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7801 - keras_rmse_reg: 0.7300 - acc: 0.4392 - val_loss: 0.7893 - val_keras_rmse_reg: 0.7443 - val_acc: 0.4407\nEpoch 73/100\n43/43 [==============================] - 0s 4ms/step - loss: 0.7771 - keras_rmse_reg: 0.7271 - acc: 0.4392 - val_loss: 0.7864 - val_keras_rmse_reg: 0.7366 - val_acc: 0.4407\nEpoch 74/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7741 - keras_rmse_reg: 0.7243 - acc: 0.4392 - val_loss: 0.7833 - val_keras_rmse_reg: 0.7352 - val_acc: 0.4407\nEpoch 75/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7711 - keras_rmse_reg: 0.7218 - acc: 0.4392 - val_loss: 0.7805 - val_keras_rmse_reg: 0.7352 - val_acc: 0.4407\nEpoch 76/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7683 - keras_rmse_reg: 0.7218 - acc: 0.4392 - val_loss: 0.7777 - val_keras_rmse_reg: 0.7352 - val_acc: 0.4407\nEpoch 77/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7655 - keras_rmse_reg: 0.7218 - acc: 0.4392 - val_loss: 0.7748 - val_keras_rmse_reg: 0.7352 - val_acc: 0.4407\nEpoch 78/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7627 - keras_rmse_reg: 0.7192 - acc: 0.4392 - val_loss: 0.7721 - val_keras_rmse_reg: 0.7304 - val_acc: 0.4407\nEpoch 79/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7599 - keras_rmse_reg: 0.7186 - acc: 0.4392 - val_loss: 0.7694 - val_keras_rmse_reg: 0.7304 - val_acc: 0.4407\nEpoch 80/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7571 - keras_rmse_reg: 0.7186 - acc: 0.4392 - val_loss: 0.7668 - val_keras_rmse_reg: 0.7304 - val_acc: 0.4407\nEpoch 81/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7544 - keras_rmse_reg: 0.7186 - acc: 0.4392 - val_loss: 0.7640 - val_keras_rmse_reg: 0.7304 - val_acc: 0.4407\nEpoch 82/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7516 - keras_rmse_reg: 0.7186 - acc: 0.4392 - val_loss: 0.7612 - val_keras_rmse_reg: 0.7304 - val_acc: 0.4407\nEpoch 83/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7488 - keras_rmse_reg: 0.7177 - acc: 0.4392 - val_loss: 0.7584 - val_keras_rmse_reg: 0.7300 - val_acc: 0.4407\nEpoch 84/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7460 - keras_rmse_reg: 0.7176 - acc: 0.4392 - val_loss: 0.7556 - val_keras_rmse_reg: 0.7300 - val_acc: 0.4407\nEpoch 85/100\n43/43 [==============================] - 0s 4ms/step - loss: 0.7432 - keras_rmse_reg: 0.7176 - acc: 0.4392 - val_loss: 0.7528 - val_keras_rmse_reg: 0.7300 - val_acc: 0.4407\nEpoch 86/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7403 - keras_rmse_reg: 0.7176 - acc: 0.4392 - val_loss: 0.7500 - val_keras_rmse_reg: 0.7300 - val_acc: 0.4407\nEpoch 87/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7375 - keras_rmse_reg: 0.7176 - acc: 0.4392 - val_loss: 0.7471 - val_keras_rmse_reg: 0.7286 - val_acc: 0.4407\nEpoch 88/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7346 - keras_rmse_reg: 0.7155 - acc: 0.4392 - val_loss: 0.7443 - val_keras_rmse_reg: 0.7267 - val_acc: 0.4407\nEpoch 89/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7318 - keras_rmse_reg: 0.7117 - acc: 0.4392 - val_loss: 0.7415 - val_keras_rmse_reg: 0.7231 - val_acc: 0.4407\nEpoch 90/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7289 - keras_rmse_reg: 0.7075 - acc: 0.4392 - val_loss: 0.7387 - val_keras_rmse_reg: 0.7179 - val_acc: 0.4407\nEpoch 91/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7260 - keras_rmse_reg: 0.7038 - acc: 0.4392 - val_loss: 0.7358 - val_keras_rmse_reg: 0.7117 - val_acc: 0.4407\nEpoch 92/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7231 - keras_rmse_reg: 0.6979 - acc: 0.4392 - val_loss: 0.7328 - val_keras_rmse_reg: 0.7095 - val_acc: 0.4407\nEpoch 93/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7202 - keras_rmse_reg: 0.6902 - acc: 0.4392 - val_loss: 0.7300 - val_keras_rmse_reg: 0.6996 - val_acc: 0.4407\nEpoch 94/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7174 - keras_rmse_reg: 0.6869 - acc: 0.4392 - val_loss: 0.7270 - val_keras_rmse_reg: 0.6945 - val_acc: 0.4407\nEpoch 95/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7144 - keras_rmse_reg: 0.6757 - acc: 0.4392 - val_loss: 0.7241 - val_keras_rmse_reg: 0.6777 - val_acc: 0.4407\nEpoch 96/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7115 - keras_rmse_reg: 0.6664 - acc: 0.4392 - val_loss: 0.7211 - val_keras_rmse_reg: 0.6740 - val_acc: 0.4407\nEpoch 97/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7086 - keras_rmse_reg: 0.6597 - acc: 0.4392 - val_loss: 0.7181 - val_keras_rmse_reg: 0.6663 - val_acc: 0.4407\nEpoch 98/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.7056 - keras_rmse_reg: 0.6557 - acc: 0.4392 - val_loss: 0.7151 - val_keras_rmse_reg: 0.6652 - val_acc: 0.4407\nEpoch 99/100\n43/43 [==============================] - 0s 7ms/step - loss: 0.7026 - keras_rmse_reg: 0.6539 - acc: 0.4392 - val_loss: 0.7120 - val_keras_rmse_reg: 0.6623 - val_acc: 0.4407\nEpoch 100/100\n43/43 [==============================] - 0s 3ms/step - loss: 0.6996 - keras_rmse_reg: 0.6465 - acc: 0.4392 - val_loss: 0.7089 - val_keras_rmse_reg: 0.6546 - val_acc: 0.4407\nEvaluating model....\n107/107 [==============================] - 0s 967us/step - loss: 0.7066 - keras_rmse_reg: 0.6597 - acc: 0.4393\n[0 0 0 ... 0 0 0]\nComp Metric:  1.6595490849320924\n              precision    recall  f1-score   support\n\n         1.0       0.44      1.00      0.61      1499\n         2.0       0.00      0.00      0.00       648\n         3.0       0.00      0.00      0.00       544\n         4.0       0.00      0.00      0.00       709\n         5.0       0.00      0.00      0.00        12\n\n    accuracy                           0.44      3412\n   macro avg       0.09      0.20      0.12      3412\nweighted avg       0.19      0.44      0.27      3412\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>keras_rmse_reg</td><td>█▇▇▆▆▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▇▇▆▅▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_keras_rmse_reg</td><td>██▇▆▅▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▇▆▅▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPS</td><td>0.0</td></tr><tr><td>acc</td><td>0.43918</td></tr><tr><td>best_epoch</td><td>99</td></tr><tr><td>best_val_loss</td><td>0.70895</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>keras_rmse_reg</td><td>0.64655</td></tr><tr><td>loss</td><td>0.69962</td></tr><tr><td>val_acc</td><td>0.44066</td></tr><tr><td>val_keras_rmse_reg</td><td>0.65458</td></tr><tr><td>val_loss</td><td>0.70895</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">d128_clf_mtdata-1673498125</strong>: <a href=\"https://wandb.ai/k_loki/tick-tick-bloom/runs/35ij0jar\" target=\"_blank\">https://wandb.ai/k_loki/tick-tick-bloom/runs/35ij0jar</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230112_043538-35ij0jar/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"y_val.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T04:38:28.002149Z","iopub.execute_input":"2023-01-12T04:38:28.002569Z","iopub.status.idle":"2023-01-12T04:38:28.014928Z","shell.execute_reply.started":"2023-01-12T04:38:28.002535Z","shell.execute_reply":"2023-01-12T04:38:28.013551Z"},"trusted":true},"execution_count":122,"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"0.0    0.439332\n3.0    0.207796\n1.0    0.189918\n2.0    0.159437\n4.0    0.003517\nName: severity, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"# this is intresting...\n# rmse going up while log loss is going down!\n# When regressing severity the rmse loss is going down but acc is not going up! there is definetly some disconnect between loss func and my metric\n# predicting all zeros (ones) --> 1.65, have to fix the metrics ig","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history.history","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:08:49.448932Z","iopub.execute_input":"2023-01-09T17:08:49.449395Z","iopub.status.idle":"2023-01-09T17:08:49.455251Z","shell.execute_reply.started":"2023-01-09T17:08:49.449360Z","shell.execute_reply":"2023-01-09T17:08:49.453951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = models.load_model('/kaggle/working/d128_rmse_lndsat8_raw_v1-1673283452.h5', custom_objects={'comp_loss': comp_loss})\n# preds = model.predict(X_val)\n# int_preds = np.round(preds)\n# mse(y_val, int_preds, squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:20:25.020659Z","iopub.execute_input":"2023-01-09T17:20:25.022716Z","iopub.status.idle":"2023-01-09T17:20:25.305114Z","shell.execute_reply.started":"2023-01-09T17:20:25.022654Z","shell.execute_reply":"2023-01-09T17:20:25.303319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save something..","metadata":{}},{"cell_type":"code","source":"# save model\nif config.SAVE_MODEL:\n    model.save(config.name + '.h5')\n    print(\"Model saved as \",config.name + '.h5')","metadata":{"execution":{"iopub.status.busy":"2023-01-12T03:36:26.897059Z","iopub.execute_input":"2023-01-12T03:36:26.897609Z","iopub.status.idle":"2023-01-12T03:36:26.928756Z","shell.execute_reply.started":"2023-01-12T03:36:26.897558Z","shell.execute_reply":"2023-01-12T03:36:26.926960Z"},"trusted":true},"execution_count":190,"outputs":[{"name":"stdout","text":"Model saved as  d128_clf_mtdata-1673494436.h5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Make submission","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T05:56:22.448352Z","iopub.execute_input":"2023-01-11T05:56:22.449800Z","iopub.status.idle":"2023-01-11T05:56:22.458223Z","shell.execute_reply.started":"2023-01-11T05:56:22.449712Z","shell.execute_reply":"2023-01-11T05:56:22.456889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = np.round(model.predict(X_test)).ravel()\ntest_preds = test_preds + 1\nsub_format.severity = test_preds\nsub_format.severity = sub_format.severity.astype(int) \nsub_format.severity.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T05:56:22.741866Z","iopub.execute_input":"2023-01-11T05:56:22.742308Z","iopub.status.idle":"2023-01-11T05:56:22.998609Z","shell.execute_reply.started":"2023-01-11T05:56:22.742275Z","shell.execute_reply":"2023-01-11T05:56:22.997319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_format.to_csv(f'{config.name}_preds.csv', index=False) # expecting @ 0.9777","metadata":{"execution":{"iopub.status.busy":"2023-01-11T05:56:26.096876Z","iopub.execute_input":"2023-01-11T05:56:26.098443Z","iopub.status.idle":"2023-01-11T05:56:26.118229Z","shell.execute_reply.started":"2023-01-11T05:56:26.098369Z","shell.execute_reply":"2023-01-11T05:56:26.116399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# So...\n\n- Training even simple NNs is really hard!!\n- NNs with log_loss not at all improving mostly coz of loss -func!","metadata":{}},{"cell_type":"markdown","source":"# ToDos:\n\n- IS this way of modelling with 1 output neuron better compared to 5 as clf\n- Does adding data provide any value??\n- **Try to beat expanding avg_severity_by_region with the help of imgs, Other wise no use for img data**\n- Is there any other way to extract more info than expanding_avg_severity_by_region only from metadata???","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}