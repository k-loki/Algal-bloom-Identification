{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Main ...\n\n \n``config, load, preprocess, train, eval  for  Tick tick bloom``\n\n**Yo DON'T rerun this unless you want to overwrite past models, always fork and do your stuff and \nDON'T forget to change the name**","metadata":{}},{"cell_type":"markdown","source":"**``Mission: NNs on expanding avg of severity metadata``**\n\n- wondering how nns perform on metadata!","metadata":{}},{"cell_type":"markdown","source":"# Load imports and dependencies","metadata":{}},{"cell_type":"code","source":"import warnings\nimport sys\nimport os\nimport time\nimport joblib\nimport random\nfrom tqdm import tqdm\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\n\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import OrdinalEncoder\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, activations, losses, metrics, models, optimizers, callbacks\nfrom category_encoders.target_encoder import TargetEncoder\n\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:34:27.847334Z","iopub.execute_input":"2023-01-12T11:34:27.847746Z","iopub.status.idle":"2023-01-12T11:34:27.857272Z","shell.execute_reply.started":"2023-01-12T11:34:27.847708Z","shell.execute_reply":"2023-01-12T11:34:27.855852Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# local utilities imports\nfrom tick_tick_bloom_utils import comp_metric, den2sev_map","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:34:29.021366Z","iopub.execute_input":"2023-01-12T11:34:29.022378Z","iopub.status.idle":"2023-01-12T11:34:29.028329Z","shell.execute_reply.started":"2023-01-12T11:34:29.022329Z","shell.execute_reply":"2023-01-12T11:34:29.026941Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# wandb stuff for tracking\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_login = user_secrets.get_secret(\"wandb_bloom_tracker\")\n\nimport wandb\nwandb.login(key=wandb_login)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:34:30.746749Z","iopub.execute_input":"2023-01-12T11:34:30.747559Z","iopub.status.idle":"2023-01-12T11:34:33.866413Z","shell.execute_reply.started":"2023-01-12T11:34:30.747496Z","shell.execute_reply":"2023-01-12T11:34:33.865006Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"raw","source":"# dot dictionary\nclass dotdict(dict):\n    \"\"\"dot.notation access to dictionary attributes\"\"\"\n    __getattr__ = dict.get\n    __setattr__ = dict.__setitem__\n    __delattr__ = dict.__delitem__\n\n\n# Config\nconfig = {}\nconfig = dotdict(config)\nconfig['RANDOM_SEED'] = 18952\n\n\nconfig['unique_id'] = int(time.time())\nprint(f'unique_id: {config.unique_id}')\nconfig['name'] = f'd128_clf_mtdata-{config.unique_id}'\n\nconfig['PROJECT_NAME'] = 'tick-tick-bloom'\n# config['DATA_DIR'] = '../data/'\n# config['MODEL_DIR'] = '../models/'\nconfig['SAVE_MODEL'] = True\n\n\n# # Img config\n# config['IMG_SIZE'] = (136, 136)\n# config['CHANNELS'] = 3\n\n# training configuration\nconfig['train'] =  dotdict({\n                        'epochs': 100,\n                        'batch_size': 256,\n                        'validation_split': 0.2,\n                        'shuffle': True,\n                        'verbose': 1,\n                        'lr' : 1e-5\n                        })\n\nconfig['desc'] = \"\"\"\nxp3-to see how nns perform only on metadata(use data upto the point of availibility.)\nrmse vs log-loss which is better?? or both could be worst than gbs!\n\"\"\" ","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:34:56.050988Z","iopub.execute_input":"2023-01-12T11:34:56.051395Z","iopub.status.idle":"2023-01-12T11:34:56.062658Z","shell.execute_reply.started":"2023-01-12T11:34:56.051363Z","shell.execute_reply":"2023-01-12T11:34:56.061100Z"}}},{"cell_type":"code","source":"# seed everything\ndef seed_everything(seed=config.RANDOM_SEED):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1' \n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\n# tf.keras.utils.set_random_seed(config.RANDOM_SEED)  # supposedly sets seed for python, numpy, tf\n\nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:34:57.771480Z","iopub.execute_input":"2023-01-12T11:34:57.771981Z","iopub.status.idle":"2023-01-12T11:34:57.780290Z","shell.execute_reply.started":"2023-01-12T11:34:57.771937Z","shell.execute_reply":"2023-01-12T11:34:57.778715Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def keras_rmse_clf(y_true, y_pred):\n    \"\"\"\n    valid competetion metric for clf type settings.\n    Can be trusted!\n    y_true and y_pred should be [0-4]\n    \"\"\"\n    y_pred = tf.argmax(y_pred, axis=1)\n    y_pred = tf.cast(y_pred, tf.float16)\n    y_true = tf.cast(y_true, tf.float16)\n    squared_difference = tf.square(y_true - y_pred)\n    return tf.sqrt(tf.reduce_mean(squared_difference, axis=-1))\n\ndef keras_rmse_reg(y_true, y_pred):\n    \"\"\"\n    valid competetion metric for reg type settings.\n    Can be trusted!\n    y_true and y_pred should be [0-4]\n    \"\"\"\n    y_pred = tf.math.round(y_pred)\n    y_pred = tf.cast(y_pred, tf.float16)\n    y_true = tf.cast(y_true, tf.float16)\n    squared_difference = tf.square(y_true - y_pred)\n    return tf.sqrt(tf.reduce_mean(squared_difference, axis=-1))\n\n\ndef rmse_loss(y_true, y_pred):\n    \"\"\"loss func to use in reg type settings\"\"\"\n    return tf.sqrt(losses.mean_squared_error(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:36:29.996357Z","iopub.execute_input":"2023-01-12T11:36:29.996810Z","iopub.status.idle":"2023-01-12T11:36:30.007822Z","shell.execute_reply.started":"2023-01-12T11:36:29.996772Z","shell.execute_reply":"2023-01-12T11:36:30.006960Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"INPUT_METADATA_DIR = '/kaggle/input/ticktickbloomdataset'\n\nmetadata = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'metadata.csv'))\nsub_format = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'submission_format.csv'))\ntrain_labels = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'train_labels.csv'))","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:34:59.271323Z","iopub.execute_input":"2023-01-12T11:34:59.271802Z","iopub.status.idle":"2023-01-12T11:34:59.384059Z","shell.execute_reply.started":"2023-01-12T11:34:59.271765Z","shell.execute_reply":"2023-01-12T11:34:59.382829Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# IMG_DIR = '/kaggle/input/pull-landsat-data-v1-500m/landsat8_500m_v1'   # landsat 8 data with raw \n# img_files = os.listdir(IMG_DIR)\n# img_file_names = [f.split('.')[0] for f in img_files]\n\n# # get only data for those 1k imgs\n# metadata_subset = metadata[metadata['uid'].isin(img_file_names)]\n# data = metadata_subset[metadata_subset.split == 'train']\n# data = data.merge(train_labels, on='uid')\n\n# test_data = metadata[metadata.split == 'train']","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:00.411045Z","iopub.execute_input":"2023-01-12T11:35:00.411468Z","iopub.status.idle":"2023-01-12T11:35:00.417876Z","shell.execute_reply.started":"2023-01-12T11:35:00.411434Z","shell.execute_reply":"2023-01-12T11:35:00.415944Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# def get_imgs(uids) :\n#     imgs = []\n#     for uid in uids:\n#         img_arr = np.load(IMG_DIR + f'/{uid}.npy')\n#         img_arr = np.transpose(img_arr, (2, 1, 0))\n#         # resize img\n#         img_arr = cv2.resize(img_arr, config.IMG_SIZE)\n#         img_arr = img_arr / 255   # normalizeee bro... other wise it's blowing up the networks...\n#         imgs.append(img_arr)\n#     return np.array(imgs) \n\n\n# def get_np_data(split : float = 0.2, task='train'):\n#     \"\"\"Return np data for training and validation.\"\"\"\n#     if task == 'train':\n#         print(\"Loading train and validation data...\")\n#         x_train_uids, x_val_uids, y_train, y_val = train_val_split(\n#             data['uid'],\n#             data.severity,\n#             val_size=split,\n#             random_state=config.RANDOM_SEED,\n#             stratify=data.severity\n#         )\n\n#         x_train = get_imgs(x_train_uids)\n#         x_val = get_imgs(x_val_uids)\n\n#         return x_train, y_train, x_val, y_val\n\n\n#     if task == 'test':\n#         test_ids = test_data.uids\n#         x_test\n#         return x_test","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:00.428358Z","iopub.execute_input":"2023-01-12T11:35:00.428855Z","iopub.status.idle":"2023-01-12T11:35:00.437410Z","shell.execute_reply.started":"2023-01-12T11:35:00.428819Z","shell.execute_reply":"2023-01-12T11:35:00.436046Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# x_train, y_train, x_val, y_val = get_np_data()\n# print(y_train.value_counts(normalize=True))\n# print(y_val.value_counts(normalize=True))\n# print('Done')","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:00.446415Z","iopub.execute_input":"2023-01-12T11:35:00.447580Z","iopub.status.idle":"2023-01-12T11:35:00.455269Z","shell.execute_reply.started":"2023-01-12T11:35:00.447503Z","shell.execute_reply":"2023-01-12T11:35:00.453962Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#  get data\nmetadata.date = pd.to_datetime(metadata.date)\n\nregion = pd.concat((train_labels, sub_format[['region', 'uid']]), axis=0)\n\ndata = pd.merge(metadata, region, on='uid', how='left')\nprint(data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:00.706564Z","iopub.execute_input":"2023-01-12T11:35:00.707496Z","iopub.status.idle":"2023-01-12T11:35:00.778244Z","shell.execute_reply.started":"2023-01-12T11:35:00.707444Z","shell.execute_reply":"2023-01-12T11:35:00.776544Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(23570, 8)\n","output_type":"stream"}]},{"cell_type":"code","source":"# seasons\nseasons = {\n    1: 1,\n    2: 1,\n    3: 2,\n    4: 2,\n    5: 2,\n    6: 3,\n    7: 3,\n    8: 3,\n    9: 4,\n    10: 4,\n    11: 4,\n    12: 1\n}\n\n\n#  most of the samples are collected in the months of June, July, August.\n\n# add date time fts.\ndata['month'] = data.date.dt.month\ndata['year'] = data.date.dt.year\ndata['week'] = data.date.dt.isocalendar().week\n# data['day_of_year'] = data.date.dt.\ndata['season'] = data.month.map(seasons)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:00.866509Z","iopub.execute_input":"2023-01-12T11:35:00.866972Z","iopub.status.idle":"2023-01-12T11:35:00.904451Z","shell.execute_reply.started":"2023-01-12T11:35:00.866935Z","shell.execute_reply":"2023-01-12T11:35:00.903171Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"data.sort_values(by='date', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:02.811182Z","iopub.execute_input":"2023-01-12T11:35:02.811726Z","iopub.status.idle":"2023-01-12T11:35:02.829555Z","shell.execute_reply.started":"2023-01-12T11:35:02.811689Z","shell.execute_reply":"2023-01-12T11:35:02.828121Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"data['expanding_severity'] = data.severity.expanding().mean()\ndata['expanding_severity'] = data['expanding_severity'].apply(np.round)\ndata","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:03.035570Z","iopub.execute_input":"2023-01-12T11:35:03.035979Z","iopub.status.idle":"2023-01-12T11:35:03.198648Z","shell.execute_reply.started":"2023-01-12T11:35:03.035949Z","shell.execute_reply":"2023-01-12T11:35:03.197200Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"        uid   latitude   longitude       date  split   region  severity  \\\n4387   evep  44.847993  -93.476318 2013-01-04  train  midwest       1.0   \n13644  paev  44.822478  -93.367962 2013-01-04  train  midwest       1.0   \n5566   gdxr  44.877646  -93.557842 2013-01-04  train  midwest       1.0   \n6144   guny  44.878889  -93.490833 2013-01-04  train  midwest       1.0   \n5317   fwbt  44.850500  -93.515700 2013-01-04  train  midwest       1.0   \n...     ...        ...         ...        ...    ...      ...       ...   \n12443  nsoi  36.736800 -121.734000 2021-12-29   test     west       NaN   \n17559  thki  36.725400 -121.730000 2021-12-29   test     west       NaN   \n17452  teuu  36.772300 -121.788000 2021-12-29   test     west       NaN   \n14254  prfi  36.751800 -121.742000 2021-12-29   test     west       NaN   \n6864   howu  36.708500 -121.749000 2021-12-29   test     west       NaN   \n\n       density  month  year  week  season  expanding_severity  \n4387     115.0      1  2013     1       1                 1.0  \n13644   1884.0      1  2013     1       1                 1.0  \n5566    1416.0      1  2013     1       1                 1.0  \n6144     558.0      1  2013     1       1                 1.0  \n5317     476.0      1  2013     1       1                 1.0  \n...        ...    ...   ...   ...     ...                 ...  \n12443      NaN     12  2021    52       1                 2.0  \n17559      NaN     12  2021    52       1                 2.0  \n17452      NaN     12  2021    52       1                 2.0  \n14254      NaN     12  2021    52       1                 2.0  \n6864       NaN     12  2021    52       1                 2.0  \n\n[23570 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n      <th>expanding_severity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4387</th>\n      <td>evep</td>\n      <td>44.847993</td>\n      <td>-93.476318</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>115.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>13644</th>\n      <td>paev</td>\n      <td>44.822478</td>\n      <td>-93.367962</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1884.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5566</th>\n      <td>gdxr</td>\n      <td>44.877646</td>\n      <td>-93.557842</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1416.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6144</th>\n      <td>guny</td>\n      <td>44.878889</td>\n      <td>-93.490833</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>558.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5317</th>\n      <td>fwbt</td>\n      <td>44.850500</td>\n      <td>-93.515700</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>476.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12443</th>\n      <td>nsoi</td>\n      <td>36.736800</td>\n      <td>-121.734000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17559</th>\n      <td>thki</td>\n      <td>36.725400</td>\n      <td>-121.730000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17452</th>\n      <td>teuu</td>\n      <td>36.772300</td>\n      <td>-121.788000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>14254</th>\n      <td>prfi</td>\n      <td>36.751800</td>\n      <td>-121.742000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>6864</th>\n      <td>howu</td>\n      <td>36.708500</td>\n      <td>-121.749000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>23570 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data = data[data.split == 'train']\ntest_data = data[data.split == 'test']","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:04.351505Z","iopub.execute_input":"2023-01-12T11:35:04.352209Z","iopub.status.idle":"2023-01-12T11:35:04.371946Z","shell.execute_reply.started":"2023-01-12T11:35:04.352171Z","shell.execute_reply":"2023-01-12T11:35:04.370668Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# expanding avg of severity\nmse(train_data.severity, train_data.expanding_severity, squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:04.836094Z","iopub.execute_input":"2023-01-12T11:35:04.836526Z","iopub.status.idle":"2023-01-12T11:35:04.847868Z","shell.execute_reply.started":"2023-01-12T11:35:04.836492Z","shell.execute_reply":"2023-01-12T11:35:04.845983Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"1.2085810811762927"},"metadata":{}}]},{"cell_type":"code","source":"grp_by_region = data.groupby('region').severity.expanding(1).mean()\ngrp_by_region = grp_by_region.map(np.round)\n\ngrp_by_region['west'].fillna(2, inplace=True)\ngrp_by_region['northeast'].fillna(2, inplace=True)\nprint(grp_by_region.isna().sum())   # 5 --> 0.89416\n\nprint(mse(train_data.severity.sort_index(), grp_by_region.droplevel(0).loc[train_data.index].sort_index(), squared=False))\n\ndata['expndng_sev_by_reg'] = np.nan\n\nsouth = data.region == 'south'\nmidwest = data.region == 'midwest'\nnortheast = data.region == 'northeast'\nwest = data.region == 'west'\n\ndata.loc[south , 'expndng_sev_by_reg'] = grp_by_region['south']\ndata.loc[midwest , 'expndng_sev_by_reg'] = grp_by_region['midwest']\ndata.loc[northeast , 'expndng_sev_by_reg'] = grp_by_region['northeast']\ndata.loc[west , 'expndng_sev_by_reg'] = grp_by_region['west']\n\nprint(data.shape)\ndata.isna().sum()\n\ndata.sort_index()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:11.898134Z","iopub.execute_input":"2023-01-12T11:35:11.898648Z","iopub.status.idle":"2023-01-12T11:35:12.116070Z","shell.execute_reply.started":"2023-01-12T11:35:11.898613Z","shell.execute_reply":"2023-01-12T11:35:12.114740Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"0\n0.894165010958815\n(23570, 14)\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"        uid   latitude   longitude       date  split   region  severity  \\\n0      aabm  39.080319  -86.430867 2018-05-14  train  midwest       1.0   \n1      aabn  36.559700 -121.510000 2016-08-31   test     west       NaN   \n2      aacd  35.875083  -78.878434 2020-11-19  train    south       1.0   \n3      aaee  35.487000  -79.062133 2016-08-24  train    south       1.0   \n4      aaff  38.049471  -99.827001 2019-07-23  train  midwest       3.0   \n...     ...        ...         ...        ...    ...      ...       ...   \n23565  zzvv  36.708500 -121.749000 2014-12-02   test     west       NaN   \n23566  zzwo  39.792190  -99.971050 2017-06-19  train  midwest       2.0   \n23567  zzwq  35.794000  -79.012551 2015-03-24  train    south       1.0   \n23568  zzyb  35.742000  -79.238600 2016-11-21  train    south       1.0   \n23569  zzzi  39.767323  -96.028617 2015-08-31   test  midwest       NaN   \n\n        density  month  year  week  season  expanding_severity  \\\n0         585.0      5  2018    20       2                 2.0   \n1           NaN      8  2016    35       3                 2.0   \n2         290.0     11  2020    47       4                 2.0   \n3        1614.0      8  2016    34       3                 2.0   \n4      111825.0      7  2019    30       3                 2.0   \n...         ...    ...   ...   ...     ...                 ...   \n23565       NaN     12  2014    49       1                 2.0   \n23566   48510.0      6  2017    25       3                 2.0   \n23567    1271.0      3  2015    13       2                 2.0   \n23568    9682.0     11  2016    47       4                 2.0   \n23569       NaN      8  2015    36       3                 2.0   \n\n       expndng_sev_by_reg  \n0                     2.0  \n1                     4.0  \n2                     2.0  \n3                     2.0  \n4                     2.0  \n...                   ...  \n23565                 4.0  \n23566                 2.0  \n23567                 1.0  \n23568                 2.0  \n23569                 2.0  \n\n[23570 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n      <th>expanding_severity</th>\n      <th>expndng_sev_by_reg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aabm</td>\n      <td>39.080319</td>\n      <td>-86.430867</td>\n      <td>2018-05-14</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>585.0</td>\n      <td>5</td>\n      <td>2018</td>\n      <td>20</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aabn</td>\n      <td>36.559700</td>\n      <td>-121.510000</td>\n      <td>2016-08-31</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>2016</td>\n      <td>35</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aacd</td>\n      <td>35.875083</td>\n      <td>-78.878434</td>\n      <td>2020-11-19</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>290.0</td>\n      <td>11</td>\n      <td>2020</td>\n      <td>47</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aaee</td>\n      <td>35.487000</td>\n      <td>-79.062133</td>\n      <td>2016-08-24</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>1614.0</td>\n      <td>8</td>\n      <td>2016</td>\n      <td>34</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aaff</td>\n      <td>38.049471</td>\n      <td>-99.827001</td>\n      <td>2019-07-23</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>3.0</td>\n      <td>111825.0</td>\n      <td>7</td>\n      <td>2019</td>\n      <td>30</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23565</th>\n      <td>zzvv</td>\n      <td>36.708500</td>\n      <td>-121.749000</td>\n      <td>2014-12-02</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2014</td>\n      <td>49</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>23566</th>\n      <td>zzwo</td>\n      <td>39.792190</td>\n      <td>-99.971050</td>\n      <td>2017-06-19</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>2.0</td>\n      <td>48510.0</td>\n      <td>6</td>\n      <td>2017</td>\n      <td>25</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>23567</th>\n      <td>zzwq</td>\n      <td>35.794000</td>\n      <td>-79.012551</td>\n      <td>2015-03-24</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>1271.0</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>13</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>23568</th>\n      <td>zzyb</td>\n      <td>35.742000</td>\n      <td>-79.238600</td>\n      <td>2016-11-21</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>9682.0</td>\n      <td>11</td>\n      <td>2016</td>\n      <td>47</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>23569</th>\n      <td>zzzi</td>\n      <td>39.767323</td>\n      <td>-96.028617</td>\n      <td>2015-08-31</td>\n      <td>test</td>\n      <td>midwest</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>2015</td>\n      <td>36</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>23570 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# # MY ASSUMPTION: less the missing values --> more inital samples in the group are not test --> less imputations/ffills needed --> much realiable score!\n","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:12.118475Z","iopub.execute_input":"2023-01-12T11:35:12.118914Z","iopub.status.idle":"2023-01-12T11:35:12.124430Z","shell.execute_reply.started":"2023-01-12T11:35:12.118857Z","shell.execute_reply":"2023-01-12T11:35:12.122754Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"grp_by_rs = data.groupby(['region', 'season']).severity.expanding(1).mean()\ngrp_by_rs = grp_by_rs.map(np.round)\nprint(grp_by_rs.isna().sum()) # 5 --> .86\n\ndata['expanding_sev_rs'] =  grp_by_rs.droplevel(0).droplevel(0).sort_index()\n# fillna with expanding sev by region\ndata['expanding_sev_rs'] = np.where(data.expanding_sev_rs.isna(), data.expndng_sev_by_reg, data.expanding_sev_rs)\n\nprint(mse(train_data.severity.sort_index(), data['expanding_sev_rs'].sort_index()[data.split == 'train'], squared=False))\n\n# #  make submission for expanding severity by region and season\n\n# expanding_sev_rs = data[data.split == 'test'][['uid', 'expanding_sev_rs']]          # picking up only uids and expanding_sev_rs from test samples\n# expanding_sev_rs.expanding_sev_rs = expanding_sev_rs.expanding_sev_rs.astype(int)   # casting to int\n# expanding_sev_rs.sort_values(by='uid', inplace=True)                                # sorting by uid -- safest option\n# expanding_sev_rs.reset_index(drop=True, inplace=True)                               # matching indexes with submissoin\n\n# sub_format.severity = expanding_sev_rs.expanding_sev_rs\n# sub_format.severity.value_counts()  # expected 0.8594349134502333\n\n# sub_format.to_csv('expanding_sev_rs_preds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:12.212362Z","iopub.execute_input":"2023-01-12T11:35:12.212817Z","iopub.status.idle":"2023-01-12T11:35:12.383627Z","shell.execute_reply.started":"2023-01-12T11:35:12.212783Z","shell.execute_reply":"2023-01-12T11:35:12.382269Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"5\n0.8594349134502333\n","output_type":"stream"}]},{"cell_type":"code","source":"train_labels.severity.value_counts(normalize=True)\n# since test and train dists are almost similar my ideal model should follow this dist!","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:12.386174Z","iopub.execute_input":"2023-01-12T11:35:12.386595Z","iopub.status.idle":"2023-01-12T11:35:12.398273Z","shell.execute_reply.started":"2023-01-12T11:35:12.386562Z","shell.execute_reply":"2023-01-12T11:35:12.396986Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"1    0.439449\n4    0.207913\n2    0.189859\n3    0.159379\n5    0.003400\nName: severity, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:12.535705Z","iopub.execute_input":"2023-01-12T11:35:12.536159Z","iopub.status.idle":"2023-01-12T11:35:12.563158Z","shell.execute_reply.started":"2023-01-12T11:35:12.536125Z","shell.execute_reply":"2023-01-12T11:35:12.561314Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"        uid   latitude  longitude       date  split   region  severity  \\\n4387   evep  44.847993 -93.476318 2013-01-04  train  midwest       1.0   \n13644  paev  44.822478 -93.367962 2013-01-04  train  midwest       1.0   \n5566   gdxr  44.877646 -93.557842 2013-01-04  train  midwest       1.0   \n6144   guny  44.878889 -93.490833 2013-01-04  train  midwest       1.0   \n5317   fwbt  44.850500 -93.515700 2013-01-04  train  midwest       1.0   \n\n       density  month  year  week  season  expanding_severity  \\\n4387     115.0      1  2013     1       1                 1.0   \n13644   1884.0      1  2013     1       1                 1.0   \n5566    1416.0      1  2013     1       1                 1.0   \n6144     558.0      1  2013     1       1                 1.0   \n5317     476.0      1  2013     1       1                 1.0   \n\n       expndng_sev_by_reg  expanding_sev_rs  \n4387                  1.0               1.0  \n13644                 1.0               1.0  \n5566                  1.0               1.0  \n6144                  1.0               1.0  \n5317                  1.0               1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n      <th>expanding_severity</th>\n      <th>expndng_sev_by_reg</th>\n      <th>expanding_sev_rs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4387</th>\n      <td>evep</td>\n      <td>44.847993</td>\n      <td>-93.476318</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>115.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>13644</th>\n      <td>paev</td>\n      <td>44.822478</td>\n      <td>-93.367962</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1884.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5566</th>\n      <td>gdxr</td>\n      <td>44.877646</td>\n      <td>-93.557842</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1416.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6144</th>\n      <td>guny</td>\n      <td>44.878889</td>\n      <td>-93.490833</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>558.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5317</th>\n      <td>fwbt</td>\n      <td>44.850500</td>\n      <td>-93.515700</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>476.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:12.716117Z","iopub.execute_input":"2023-01-12T11:35:12.716571Z","iopub.status.idle":"2023-01-12T11:35:12.737227Z","shell.execute_reply.started":"2023-01-12T11:35:12.716537Z","shell.execute_reply":"2023-01-12T11:35:12.735350Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"uid                      0\nlatitude                 0\nlongitude                0\ndate                     0\nsplit                    0\nregion                   0\nseverity              6510\ndensity               6510\nmonth                    0\nyear                     0\nweek                     0\nseason                   0\nexpanding_severity       0\nexpndng_sev_by_reg       0\nexpanding_sev_rs         0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"all_train = data[data.split == 'train']\nall_train.sort_values(by='uid', inplace=True)\nall_train.reset_index(drop=True, inplace=True)\nall_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:12.886209Z","iopub.execute_input":"2023-01-12T11:35:12.886662Z","iopub.status.idle":"2023-01-12T11:35:12.930294Z","shell.execute_reply.started":"2023-01-12T11:35:12.886626Z","shell.execute_reply":"2023-01-12T11:35:12.928733Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(17060, 15)"},"metadata":{}}]},{"cell_type":"code","source":"all_train","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:13.601049Z","iopub.execute_input":"2023-01-12T11:35:13.601454Z","iopub.status.idle":"2023-01-12T11:35:13.641156Z","shell.execute_reply.started":"2023-01-12T11:35:13.601423Z","shell.execute_reply":"2023-01-12T11:35:13.639615Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"        uid   latitude  longitude       date  split   region  severity  \\\n0      aabm  39.080319 -86.430867 2018-05-14  train  midwest       1.0   \n1      aacd  35.875083 -78.878434 2020-11-19  train    south       1.0   \n2      aaee  35.487000 -79.062133 2016-08-24  train    south       1.0   \n3      aaff  38.049471 -99.827001 2019-07-23  train  midwest       3.0   \n4      aafl  39.474744 -86.898353 2021-08-23  train  midwest       4.0   \n...     ...        ...        ...        ...    ...      ...       ...   \n17055  zzsv  38.707825 -75.080867 2018-06-27  train    south       3.0   \n17056  zzuq  35.794000 -79.015368 2015-08-06  train    south       3.0   \n17057  zzwo  39.792190 -99.971050 2017-06-19  train  midwest       2.0   \n17058  zzwq  35.794000 -79.012551 2015-03-24  train    south       1.0   \n17059  zzyb  35.742000 -79.238600 2016-11-21  train    south       1.0   \n\n         density  month  year  week  season  expanding_severity  \\\n0          585.0      5  2018    20       2                 2.0   \n1          290.0     11  2020    47       4                 2.0   \n2         1614.0      8  2016    34       3                 2.0   \n3       111825.0      7  2019    30       3                 2.0   \n4      2017313.0      8  2021    34       3                 2.0   \n...          ...    ...   ...   ...     ...                 ...   \n17055   113125.0      6  2018    26       3                 2.0   \n17056   175726.0      8  2015    32       3                 2.0   \n17057    48510.0      6  2017    25       3                 2.0   \n17058     1271.0      3  2015    13       2                 2.0   \n17059     9682.0     11  2016    47       4                 2.0   \n\n       expndng_sev_by_reg  expanding_sev_rs  \n0                     2.0               1.0  \n1                     2.0               2.0  \n2                     2.0               2.0  \n3                     2.0               2.0  \n4                     2.0               2.0  \n...                   ...               ...  \n17055                 2.0               2.0  \n17056                 1.0               2.0  \n17057                 2.0               2.0  \n17058                 1.0               1.0  \n17059                 2.0               2.0  \n\n[17060 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n      <th>expanding_severity</th>\n      <th>expndng_sev_by_reg</th>\n      <th>expanding_sev_rs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aabm</td>\n      <td>39.080319</td>\n      <td>-86.430867</td>\n      <td>2018-05-14</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>585.0</td>\n      <td>5</td>\n      <td>2018</td>\n      <td>20</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aacd</td>\n      <td>35.875083</td>\n      <td>-78.878434</td>\n      <td>2020-11-19</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>290.0</td>\n      <td>11</td>\n      <td>2020</td>\n      <td>47</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aaee</td>\n      <td>35.487000</td>\n      <td>-79.062133</td>\n      <td>2016-08-24</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>1614.0</td>\n      <td>8</td>\n      <td>2016</td>\n      <td>34</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aaff</td>\n      <td>38.049471</td>\n      <td>-99.827001</td>\n      <td>2019-07-23</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>3.0</td>\n      <td>111825.0</td>\n      <td>7</td>\n      <td>2019</td>\n      <td>30</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aafl</td>\n      <td>39.474744</td>\n      <td>-86.898353</td>\n      <td>2021-08-23</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>4.0</td>\n      <td>2017313.0</td>\n      <td>8</td>\n      <td>2021</td>\n      <td>34</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17055</th>\n      <td>zzsv</td>\n      <td>38.707825</td>\n      <td>-75.080867</td>\n      <td>2018-06-27</td>\n      <td>train</td>\n      <td>south</td>\n      <td>3.0</td>\n      <td>113125.0</td>\n      <td>6</td>\n      <td>2018</td>\n      <td>26</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17056</th>\n      <td>zzuq</td>\n      <td>35.794000</td>\n      <td>-79.015368</td>\n      <td>2015-08-06</td>\n      <td>train</td>\n      <td>south</td>\n      <td>3.0</td>\n      <td>175726.0</td>\n      <td>8</td>\n      <td>2015</td>\n      <td>32</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17057</th>\n      <td>zzwo</td>\n      <td>39.792190</td>\n      <td>-99.971050</td>\n      <td>2017-06-19</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>2.0</td>\n      <td>48510.0</td>\n      <td>6</td>\n      <td>2017</td>\n      <td>25</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17058</th>\n      <td>zzwq</td>\n      <td>35.794000</td>\n      <td>-79.012551</td>\n      <td>2015-03-24</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>1271.0</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>13</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>17059</th>\n      <td>zzyb</td>\n      <td>35.742000</td>\n      <td>-79.238600</td>\n      <td>2016-11-21</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>9682.0</td>\n      <td>11</td>\n      <td>2016</td>\n      <td>47</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>17060 rows × 15 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"all_train.expanding_sev_rs.value_counts(normalize=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:13.736063Z","iopub.execute_input":"2023-01-12T11:35:13.736461Z","iopub.status.idle":"2023-01-12T11:35:13.750032Z","shell.execute_reply.started":"2023-01-12T11:35:13.736431Z","shell.execute_reply":"2023-01-12T11:35:13.748860Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"2.0    8558\n1.0    4736\n4.0    3565\n3.0     201\nName: expanding_sev_rs, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"all_train.expndng_sev_by_reg.value_counts(normalize=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:13.871075Z","iopub.execute_input":"2023-01-12T11:35:13.871481Z","iopub.status.idle":"2023-01-12T11:35:13.882680Z","shell.execute_reply.started":"2023-01-12T11:35:13.871451Z","shell.execute_reply":"2023-01-12T11:35:13.880984Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"2.0    10241\n4.0     3769\n1.0     3050\nName: expndng_sev_by_reg, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"sum(all_train.expanding_sev_rs == all_train.expndng_sev_by_reg)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:14.046166Z","iopub.execute_input":"2023-01-12T11:35:14.046549Z","iopub.status.idle":"2023-01-12T11:35:14.056733Z","shell.execute_reply.started":"2023-01-12T11:35:14.046519Z","shell.execute_reply":"2023-01-12T11:35:14.055283Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"12866"},"metadata":{}}]},{"cell_type":"code","source":"test_data = metadata[metadata.split == 'test']\ntest_data = test_data.merge(sub_format, on='uid')\n\ntest_data['month'] = test_data.date.dt.month\ntest_data['year'] = test_data.date.dt.year\ntest_data['season'] = test_data.month.map(seasons)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:14.696121Z","iopub.execute_input":"2023-01-12T11:35:14.696521Z","iopub.status.idle":"2023-01-12T11:35:14.730024Z","shell.execute_reply.started":"2023-01-12T11:35:14.696490Z","shell.execute_reply":"2023-01-12T11:35:14.728868Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"all_train.columns","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:14.856409Z","iopub.execute_input":"2023-01-12T11:35:14.857178Z","iopub.status.idle":"2023-01-12T11:35:14.868950Z","shell.execute_reply.started":"2023-01-12T11:35:14.857131Z","shell.execute_reply":"2023-01-12T11:35:14.867324Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"Index(['uid', 'latitude', 'longitude', 'date', 'split', 'region', 'severity',\n       'density', 'month', 'year', 'week', 'season', 'expanding_severity',\n       'expndng_sev_by_reg', 'expanding_sev_rs'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"req_cols = ['region', 'month', 'year', 'season', 'expanding_sev_rs']","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:15.011188Z","iopub.execute_input":"2023-01-12T11:35:15.011611Z","iopub.status.idle":"2023-01-12T11:35:15.016795Z","shell.execute_reply.started":"2023-01-12T11:35:15.011574Z","shell.execute_reply":"2023-01-12T11:35:15.015768Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"X_ , y_ = all_train[req_cols], all_train['severity']\nX_.shape, y_.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:15.801787Z","iopub.execute_input":"2023-01-12T11:35:15.802651Z","iopub.status.idle":"2023-01-12T11:35:15.813702Z","shell.execute_reply.started":"2023-01-12T11:35:15.802598Z","shell.execute_reply":"2023-01-12T11:35:15.812158Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"((17060, 5), (17060,))"},"metadata":{}}]},{"cell_type":"code","source":"X_.isna().sum().sum(), y_.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:16.816067Z","iopub.execute_input":"2023-01-12T11:35:16.816553Z","iopub.status.idle":"2023-01-12T11:35:16.830023Z","shell.execute_reply.started":"2023-01-12T11:35:16.816516Z","shell.execute_reply":"2023-01-12T11:35:16.828339Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"(0, 0)"},"metadata":{}}]},{"cell_type":"code","source":"X_train_,X_val_, y_train_, y_val_ = train_test_split(X_, y_, test_size=0.20, random_state=config.RANDOM_SEED, stratify=y_)\nX_train_.shape, y_train_.shape, X_val_.shape, y_val_.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:17.016234Z","iopub.execute_input":"2023-01-12T11:35:17.016695Z","iopub.status.idle":"2023-01-12T11:35:17.038516Z","shell.execute_reply.started":"2023-01-12T11:35:17.016659Z","shell.execute_reply":"2023-01-12T11:35:17.037111Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"((13648, 5), (13648,), (3412, 5), (3412,))"},"metadata":{}}]},{"cell_type":"code","source":"test_data['expanding_severity'] = data[data.split == 'test']['expanding_severity'].sort_index().values\ntest_data['expndng_sev_by_reg'] = data[data.split == 'test']['expndng_sev_by_reg'].sort_index().values\ntest_data['expanding_sev_rs'] = data[data.split == 'test']['expanding_sev_rs'].sort_index().values","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:17.181069Z","iopub.execute_input":"2023-01-12T11:35:17.181519Z","iopub.status.idle":"2023-01-12T11:35:17.211290Z","shell.execute_reply.started":"2023-01-12T11:35:17.181484Z","shell.execute_reply":"2023-01-12T11:35:17.210100Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"X_test_ = test_data[req_cols]\nX_test_.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:18.255799Z","iopub.execute_input":"2023-01-12T11:35:18.256277Z","iopub.status.idle":"2023-01-12T11:35:18.268096Z","shell.execute_reply.started":"2023-01-12T11:35:18.256242Z","shell.execute_reply":"2023-01-12T11:35:18.266407Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"(6510, 5)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocess","metadata":{}},{"cell_type":"code","source":"# # change labels to 0-3(model works this way) instead of 1-4 given range(given severity)\n# -1 for to make labels look like sparse encoded labels\n\ny_train = y_train_  -1\ny_val = y_val_ - 1\n\ny_train.value_counts(normalize=True), y_val.value_counts(normalize=True)  # guessing alwyas 0 gives 43% acc","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:18.535854Z","iopub.execute_input":"2023-01-12T11:35:18.536262Z","iopub.status.idle":"2023-01-12T11:35:18.552774Z","shell.execute_reply.started":"2023-01-12T11:35:18.536231Z","shell.execute_reply":"2023-01-12T11:35:18.550969Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(0.0    0.439478\n 3.0    0.207943\n 1.0    0.189845\n 2.0    0.159364\n 4.0    0.003370\n Name: severity, dtype: float64,\n 0.0    0.439332\n 3.0    0.207796\n 1.0    0.189918\n 2.0    0.159437\n 4.0    0.003517\n Name: severity, dtype: float64)"},"metadata":{}}]},{"cell_type":"code","source":"y = y_ - 1\ny.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:19.211277Z","iopub.execute_input":"2023-01-12T11:35:19.211804Z","iopub.status.idle":"2023-01-12T11:35:19.223828Z","shell.execute_reply.started":"2023-01-12T11:35:19.211766Z","shell.execute_reply":"2023-01-12T11:35:19.222397Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"0.0    7497\n3.0    3547\n1.0    3239\n2.0    2719\n4.0      58\nName: severity, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# #  target encode the cat fts.\n\n# te = TargetEncoder(cols=['region', 'month', 'year', 'season'])\n# te.fit(X_train_, y_train)\n# X_train =  te.transform(X_train_)\n# X_val = te.transform(X_val_)\n\n# X_test = te.transform(X_test_)\n# X_test","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:19.371162Z","iopub.execute_input":"2023-01-12T11:35:19.371579Z","iopub.status.idle":"2023-01-12T11:35:19.376406Z","shell.execute_reply.started":"2023-01-12T11:35:19.371546Z","shell.execute_reply":"2023-01-12T11:35:19.375483Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"X_train_.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:20.021036Z","iopub.execute_input":"2023-01-12T11:35:20.021504Z","iopub.status.idle":"2023-01-12T11:35:20.031124Z","shell.execute_reply.started":"2023-01-12T11:35:20.021471Z","shell.execute_reply":"2023-01-12T11:35:20.030002Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"region               object\nmonth                 int64\nyear                  int64\nseason                int64\nexpanding_sev_rs    float64\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"#  Encode region\n# from category_encoders.ordinal import OrdinalEncoder as COE\n\noe = OrdinalEncoder()\nX_train = oe.fit_transform(X_train_)\nX_test = oe.transform(X_test_)\nX_val = oe.transform(X_val_)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:20.135626Z","iopub.execute_input":"2023-01-12T11:35:20.136062Z","iopub.status.idle":"2023-01-12T11:35:20.166342Z","shell.execute_reply.started":"2023-01-12T11:35:20.136029Z","shell.execute_reply":"2023-01-12T11:35:20.164871Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"X_train = pd.DataFrame(X_train, columns=X_train_.columns, index=X_train_.index)\nX_test = pd.DataFrame(X_test, columns=X_test_.columns, index=X_test_.index)\nX_val = pd.DataFrame(X_val, columns=X_val_.columns, index=X_val_.index)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:20.296652Z","iopub.execute_input":"2023-01-12T11:35:20.297162Z","iopub.status.idle":"2023-01-12T11:35:20.304412Z","shell.execute_reply.started":"2023-01-12T11:35:20.297125Z","shell.execute_reply":"2023-01-12T11:35:20.303385Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Normalize values\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:35:20.818522Z","iopub.execute_input":"2023-01-12T11:35:20.819034Z","iopub.status.idle":"2023-01-12T11:35:20.825021Z","shell.execute_reply.started":"2023-01-12T11:35:20.818999Z","shell.execute_reply":"2023-01-12T11:35:20.823494Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def get_model(mdtype='reg'):\n    print(f'Loading {mdtype} type model...')\n    #     input_shape = (*config.IMG_SIZE, config.CHANNELS)\n\n    if mdtype == 'clf':\n        loss = losses.SparseCategoricalCrossentropy()\n        comp_metric = keras_rmse_clf\n        last_layer = layers.Dense(5, activation='softmax')\n\n    if mdtype == 'reg':\n        loss = rmse_loss\n        comp_metric = keras_rmse_reg\n        last_layer = layers.Dense(1)\n    \n    \n    \n    input_imgs = layers.Input(shape=(X_train.shape[1],))\n    #     x = layers.Conv2D(32, (3, 3), activation='relu')(input_imgs)\n    #     x = layers.MaxPooling2D((2, 2))(x)\n    #     x = layers.Flatten()(x)\n    x = layers.Dense(128, activation='relu')(input_imgs)\n    output = last_layer(x)\n\n    model = models.Model(inputs=input_imgs, outputs=output, name=config.name)\n    \n    \n\n    model.compile(optimizer=optimizers.Adam(learning_rate=config.train.lr),\n                    loss = loss,\n                    metrics=[\n                        comp_metric,\n                        metrics.SparseCategoricalAccuracy(name='acc')\n                    ])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:40:13.653594Z","iopub.execute_input":"2023-01-12T11:40:13.654074Z","iopub.status.idle":"2023-01-12T11:40:13.666336Z","shell.execute_reply.started":"2023-01-12T11:40:13.654035Z","shell.execute_reply":"2023-01-12T11:40:13.664733Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"model = get_model('reg')\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:40:35.483983Z","iopub.execute_input":"2023-01-12T11:40:35.484525Z","iopub.status.idle":"2023-01-12T11:40:35.530678Z","shell.execute_reply.started":"2023-01-12T11:40:35.484481Z","shell.execute_reply":"2023-01-12T11:40:35.529251Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Loading reg type model...\nModel: \"d128_clf_mtdata-1673523296\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_11 (InputLayer)        [(None, 5)]               0         \n_________________________________________________________________\ndense_22 (Dense)             (None, 128)               768       \n_________________________________________________________________\ndense_21 (Dense)             (None, 1)                 129       \n=================================================================\nTotal params: 897\nTrainable params: 897\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:40:40.763689Z","iopub.execute_input":"2023-01-12T11:40:40.765300Z","iopub.status.idle":"2023-01-12T11:40:40.770801Z","shell.execute_reply.started":"2023-01-12T11:40:40.765239Z","shell.execute_reply":"2023-01-12T11:40:40.769119Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"# Train and eval","metadata":{}},{"cell_type":"code","source":"def train_(model, config=config, x_train=X_train, y_train=y_train, debug=None):\n    \"\"\"fits given model to x_train and y_train\"\"\"\n    \n    train_config = config['train']\n    my_callbacks = []\n    \n    earlystopping = callbacks.EarlyStopping(patience=15, monitor='val_loss', restore_best_weights=True)\n    my_callbacks.append(earlystopping)\n    \n    try:\n        wandb_callback = wandb.keras.WandbCallback(\n            monitor='val_loss',\n            log_weights=True,\n            log_gradients=True,\n            save_model=False,\n            training_data=(x_train, y_train),\n            log_batch_frequency=None,\n        )\n\n        my_callbacks.append(wandb_callback)\n    except:\n        print('wandb not tracking')\n        \n    print(f'Training model... {config.name}')\n    if debug == True:\n        epochs = 1000\n    else:\n        epochs = train_config.epochs\n    history = model.fit(\n                x_train, y_train,\n                epochs=epochs,\n                batch_size=train_config.batch_size, \n                callbacks=my_callbacks, \n                validation_split=0.2, \n                shuffle=True, \n                verbose=1 \n            )\n\n    return model, history\n\n\ndef eval_(model, x_val=X_val, y_val=y_val):\n    print('Evaluating model....')\n    model.evaluate(x_val, y_val, return_dict=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:57:36.814242Z","iopub.execute_input":"2023-01-12T11:57:36.814999Z","iopub.status.idle":"2023-01-12T11:57:36.826433Z","shell.execute_reply.started":"2023-01-12T11:57:36.814949Z","shell.execute_reply":"2023-01-12T11:57:36.824977Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"def train_eval(model=None, mdtype='reg', X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, debug=False):\n    \n    if model is None:\n        print('Getting New model')\n        model = get_model()\n    \n    # train\n    model, history = train_(model, config, X_train, y_train=y_train, debug=debug)  # try to overfit thsi batch\n    # eval\n    eval_(model)\n\n    # classification report\n    y_pred = model.predict(X_val)\n    if mdtype == 'clf':\n        y_pred_hard = np.argmax(y_pred, axis=1)             # fuck this shit forgot to \n    if mdtype == 'reg':\n        y_pred_hard = np.round(y_pred)\n        \n    print(y_pred_hard)\n    error = mse(y_val, y_pred_hard, squared=False)\n    print(\"Comp Metric: \", error)\n    cr = classification_report(y_val, y_pred_hard)     # +1 to account for 0-4 as it should be 1-5 originallly\n    print(cr)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:57:38.749519Z","iopub.execute_input":"2023-01-12T11:57:38.749921Z","iopub.status.idle":"2023-01-12T11:57:38.759234Z","shell.execute_reply.started":"2023-01-12T11:57:38.749873Z","shell.execute_reply":"2023-01-12T11:57:38.757693Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"model = get_model('clf')\ntrain_eval(model, 'clf', y_train=y_train, y_val=y_val)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:52:26.450187Z","iopub.execute_input":"2023-01-12T11:52:26.450598Z","iopub.status.idle":"2023-01-12T11:53:08.409171Z","shell.execute_reply.started":"2023-01-12T11:52:26.450565Z","shell.execute_reply":"2023-01-12T11:53:08.405372Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"Loading clf type model...\nwandb not tracking\nTraining model... d128_clf_mtdata-1673523296\nEpoch 1/100\n43/43 [==============================] - 1s 10ms/step - loss: 1.7681 - keras_rmse_clf: 1.1842 - acc: 0.2814 - val_loss: 1.7625 - val_keras_rmse_clf: 1.1968 - val_acc: 0.2810\nEpoch 2/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.7429 - keras_rmse_clf: 1.1977 - acc: 0.2952 - val_loss: 1.7377 - val_keras_rmse_clf: 1.2089 - val_acc: 0.2897\nEpoch 3/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.7195 - keras_rmse_clf: 1.2123 - acc: 0.3101 - val_loss: 1.7149 - val_keras_rmse_clf: 1.2269 - val_acc: 0.3073\nEpoch 4/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.6979 - keras_rmse_clf: 1.2247 - acc: 0.3230 - val_loss: 1.6937 - val_keras_rmse_clf: 1.2388 - val_acc: 0.3201\nEpoch 5/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.6779 - keras_rmse_clf: 1.2380 - acc: 0.3359 - val_loss: 1.6741 - val_keras_rmse_clf: 1.2567 - val_acc: 0.3542\nEpoch 6/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.6592 - keras_rmse_clf: 1.2518 - acc: 0.3642 - val_loss: 1.6557 - val_keras_rmse_clf: 1.2654 - val_acc: 0.3700\nEpoch 7/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.6418 - keras_rmse_clf: 1.2594 - acc: 0.3807 - val_loss: 1.6384 - val_keras_rmse_clf: 1.2693 - val_acc: 0.3905\nEpoch 8/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.6254 - keras_rmse_clf: 1.2609 - acc: 0.3927 - val_loss: 1.6224 - val_keras_rmse_clf: 1.2686 - val_acc: 0.3938\nEpoch 9/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.6099 - keras_rmse_clf: 1.2598 - acc: 0.3991 - val_loss: 1.6068 - val_keras_rmse_clf: 1.2650 - val_acc: 0.4044\nEpoch 10/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.5951 - keras_rmse_clf: 1.2560 - acc: 0.4085 - val_loss: 1.5922 - val_keras_rmse_clf: 1.2627 - val_acc: 0.4139\nEpoch 11/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.5810 - keras_rmse_clf: 1.2536 - acc: 0.4128 - val_loss: 1.5783 - val_keras_rmse_clf: 1.2588 - val_acc: 0.4216\nEpoch 12/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.5675 - keras_rmse_clf: 1.2495 - acc: 0.4181 - val_loss: 1.5649 - val_keras_rmse_clf: 1.2542 - val_acc: 0.4223\nEpoch 13/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.5546 - keras_rmse_clf: 1.2441 - acc: 0.4236 - val_loss: 1.5521 - val_keras_rmse_clf: 1.2502 - val_acc: 0.4264\nEpoch 14/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.5421 - keras_rmse_clf: 1.2417 - acc: 0.4251 - val_loss: 1.5397 - val_keras_rmse_clf: 1.2494 - val_acc: 0.4271\nEpoch 15/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.5301 - keras_rmse_clf: 1.2381 - acc: 0.4257 - val_loss: 1.5277 - val_keras_rmse_clf: 1.2458 - val_acc: 0.4253\nEpoch 16/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.5185 - keras_rmse_clf: 1.2369 - acc: 0.4255 - val_loss: 1.5161 - val_keras_rmse_clf: 1.2447 - val_acc: 0.4260\nEpoch 17/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.5073 - keras_rmse_clf: 1.2359 - acc: 0.4260 - val_loss: 1.5050 - val_keras_rmse_clf: 1.2435 - val_acc: 0.4264\nEpoch 18/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.4964 - keras_rmse_clf: 1.2323 - acc: 0.4251 - val_loss: 1.4943 - val_keras_rmse_clf: 1.2395 - val_acc: 0.4249\nEpoch 19/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.4859 - keras_rmse_clf: 1.2297 - acc: 0.4246 - val_loss: 1.4839 - val_keras_rmse_clf: 1.2352 - val_acc: 0.4256\nEpoch 20/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.4757 - keras_rmse_clf: 1.2263 - acc: 0.4251 - val_loss: 1.4738 - val_keras_rmse_clf: 1.2352 - val_acc: 0.4256\nEpoch 21/100\n43/43 [==============================] - 0s 9ms/step - loss: 1.4658 - keras_rmse_clf: 1.2260 - acc: 0.4263 - val_loss: 1.4641 - val_keras_rmse_clf: 1.2341 - val_acc: 0.4264\nEpoch 22/100\n43/43 [==============================] - 0s 11ms/step - loss: 1.4563 - keras_rmse_clf: 1.2249 - acc: 0.4274 - val_loss: 1.4546 - val_keras_rmse_clf: 1.2338 - val_acc: 0.4264\nEpoch 23/100\n43/43 [==============================] - 0s 8ms/step - loss: 1.4470 - keras_rmse_clf: 1.2219 - acc: 0.4281 - val_loss: 1.4455 - val_keras_rmse_clf: 1.2297 - val_acc: 0.4275\nEpoch 24/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.4380 - keras_rmse_clf: 1.2186 - acc: 0.4283 - val_loss: 1.4365 - val_keras_rmse_clf: 1.2281 - val_acc: 0.4267\nEpoch 25/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.4292 - keras_rmse_clf: 1.2180 - acc: 0.4276 - val_loss: 1.4280 - val_keras_rmse_clf: 1.2275 - val_acc: 0.4271\nEpoch 26/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.4208 - keras_rmse_clf: 1.2167 - acc: 0.4278 - val_loss: 1.4196 - val_keras_rmse_clf: 1.2243 - val_acc: 0.4256\nEpoch 27/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.4126 - keras_rmse_clf: 1.2151 - acc: 0.4285 - val_loss: 1.4115 - val_keras_rmse_clf: 1.2239 - val_acc: 0.4264\nEpoch 28/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.4046 - keras_rmse_clf: 1.2144 - acc: 0.4286 - val_loss: 1.4037 - val_keras_rmse_clf: 1.2202 - val_acc: 0.4282\nEpoch 29/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.3969 - keras_rmse_clf: 1.2104 - acc: 0.4293 - val_loss: 1.3960 - val_keras_rmse_clf: 1.2202 - val_acc: 0.4282\nEpoch 30/100\n43/43 [==============================] - 0s 7ms/step - loss: 1.3894 - keras_rmse_clf: 1.2108 - acc: 0.4293 - val_loss: 1.3887 - val_keras_rmse_clf: 1.2202 - val_acc: 0.4282\nEpoch 31/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.3821 - keras_rmse_clf: 1.2090 - acc: 0.4287 - val_loss: 1.3815 - val_keras_rmse_clf: 1.2191 - val_acc: 0.4282\nEpoch 32/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.3750 - keras_rmse_clf: 1.2093 - acc: 0.4286 - val_loss: 1.3745 - val_keras_rmse_clf: 1.2187 - val_acc: 0.4282\nEpoch 33/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.3681 - keras_rmse_clf: 1.2082 - acc: 0.4286 - val_loss: 1.3677 - val_keras_rmse_clf: 1.2171 - val_acc: 0.4271\nEpoch 34/100\n43/43 [==============================] - 0s 7ms/step - loss: 1.3613 - keras_rmse_clf: 1.2079 - acc: 0.4282 - val_loss: 1.3611 - val_keras_rmse_clf: 1.2171 - val_acc: 0.4271\nEpoch 35/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.3548 - keras_rmse_clf: 1.2077 - acc: 0.4291 - val_loss: 1.3546 - val_keras_rmse_clf: 1.2153 - val_acc: 0.4293\nEpoch 36/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.3484 - keras_rmse_clf: 1.2060 - acc: 0.4303 - val_loss: 1.3484 - val_keras_rmse_clf: 1.2153 - val_acc: 0.4293\nEpoch 37/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.3422 - keras_rmse_clf: 1.2040 - acc: 0.4307 - val_loss: 1.3423 - val_keras_rmse_clf: 1.2126 - val_acc: 0.4308\nEpoch 38/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.3362 - keras_rmse_clf: 1.2039 - acc: 0.4308 - val_loss: 1.3364 - val_keras_rmse_clf: 1.2121 - val_acc: 0.4311\nEpoch 39/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.3303 - keras_rmse_clf: 1.2177 - acc: 0.4323 - val_loss: 1.3306 - val_keras_rmse_clf: 1.2490 - val_acc: 0.4355\nEpoch 40/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.3246 - keras_rmse_clf: 1.2982 - acc: 0.4442 - val_loss: 1.3251 - val_keras_rmse_clf: 1.3042 - val_acc: 0.4443\nEpoch 41/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.3191 - keras_rmse_clf: 1.3057 - acc: 0.4459 - val_loss: 1.3196 - val_keras_rmse_clf: 1.3266 - val_acc: 0.4487\nEpoch 42/100\n43/43 [==============================] - 0s 7ms/step - loss: 1.3137 - keras_rmse_clf: 1.3315 - acc: 0.4525 - val_loss: 1.3143 - val_keras_rmse_clf: 1.3447 - val_acc: 0.4564\nEpoch 43/100\n43/43 [==============================] - 0s 7ms/step - loss: 1.3084 - keras_rmse_clf: 1.3499 - acc: 0.4588 - val_loss: 1.3091 - val_keras_rmse_clf: 1.3484 - val_acc: 0.4575\nEpoch 44/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.3033 - keras_rmse_clf: 1.3685 - acc: 0.4633 - val_loss: 1.3040 - val_keras_rmse_clf: 1.3632 - val_acc: 0.4612\nEpoch 45/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2982 - keras_rmse_clf: 1.3845 - acc: 0.4688 - val_loss: 1.2992 - val_keras_rmse_clf: 1.3792 - val_acc: 0.4656\nEpoch 46/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2934 - keras_rmse_clf: 1.4011 - acc: 0.4733 - val_loss: 1.2944 - val_keras_rmse_clf: 1.3909 - val_acc: 0.4685\nEpoch 47/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2886 - keras_rmse_clf: 1.4064 - acc: 0.4756 - val_loss: 1.2896 - val_keras_rmse_clf: 1.4076 - val_acc: 0.4729\nEpoch 48/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2838 - keras_rmse_clf: 1.4250 - acc: 0.4819 - val_loss: 1.2850 - val_keras_rmse_clf: 1.4208 - val_acc: 0.4773\nEpoch 49/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2792 - keras_rmse_clf: 1.4296 - acc: 0.4828 - val_loss: 1.2805 - val_keras_rmse_clf: 1.4208 - val_acc: 0.4773\nEpoch 50/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2746 - keras_rmse_clf: 1.4313 - acc: 0.4837 - val_loss: 1.2760 - val_keras_rmse_clf: 1.4553 - val_acc: 0.4897\nEpoch 51/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2702 - keras_rmse_clf: 1.4706 - acc: 0.4970 - val_loss: 1.2716 - val_keras_rmse_clf: 1.4823 - val_acc: 0.4993\nEpoch 52/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2658 - keras_rmse_clf: 1.4920 - acc: 0.5058 - val_loss: 1.2673 - val_keras_rmse_clf: 1.5059 - val_acc: 0.5088\nEpoch 53/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2615 - keras_rmse_clf: 1.5187 - acc: 0.5166 - val_loss: 1.2631 - val_keras_rmse_clf: 1.5378 - val_acc: 0.5190\nEpoch 54/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2572 - keras_rmse_clf: 1.5413 - acc: 0.5250 - val_loss: 1.2589 - val_keras_rmse_clf: 1.5442 - val_acc: 0.5216\nEpoch 55/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2530 - keras_rmse_clf: 1.5480 - acc: 0.5290 - val_loss: 1.2548 - val_keras_rmse_clf: 1.5549 - val_acc: 0.5267\nEpoch 56/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2490 - keras_rmse_clf: 1.5566 - acc: 0.5331 - val_loss: 1.2508 - val_keras_rmse_clf: 1.5549 - val_acc: 0.5267\nEpoch 57/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.2449 - keras_rmse_clf: 1.5600 - acc: 0.5343 - val_loss: 1.2469 - val_keras_rmse_clf: 1.5586 - val_acc: 0.5289\nEpoch 58/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2410 - keras_rmse_clf: 1.5616 - acc: 0.5365 - val_loss: 1.2431 - val_keras_rmse_clf: 1.5642 - val_acc: 0.5348\nEpoch 59/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2371 - keras_rmse_clf: 1.5719 - acc: 0.5420 - val_loss: 1.2392 - val_keras_rmse_clf: 1.5701 - val_acc: 0.5377\nEpoch 60/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2333 - keras_rmse_clf: 1.5739 - acc: 0.5436 - val_loss: 1.2355 - val_keras_rmse_clf: 1.5701 - val_acc: 0.5377\nEpoch 61/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2295 - keras_rmse_clf: 1.5777 - acc: 0.5447 - val_loss: 1.2318 - val_keras_rmse_clf: 1.5856 - val_acc: 0.5447\nEpoch 62/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.2258 - keras_rmse_clf: 1.5885 - acc: 0.5501 - val_loss: 1.2280 - val_keras_rmse_clf: 1.5894 - val_acc: 0.5469\nEpoch 63/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2220 - keras_rmse_clf: 1.5911 - acc: 0.5506 - val_loss: 1.2244 - val_keras_rmse_clf: 1.5896 - val_acc: 0.5476\nEpoch 64/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2184 - keras_rmse_clf: 1.5897 - acc: 0.5501 - val_loss: 1.2208 - val_keras_rmse_clf: 1.5896 - val_acc: 0.5476\nEpoch 65/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2148 - keras_rmse_clf: 1.5959 - acc: 0.5529 - val_loss: 1.2173 - val_keras_rmse_clf: 1.5994 - val_acc: 0.5527\nEpoch 66/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.2112 - keras_rmse_clf: 1.6072 - acc: 0.5586 - val_loss: 1.2137 - val_keras_rmse_clf: 1.6022 - val_acc: 0.5538\nEpoch 67/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.2077 - keras_rmse_clf: 1.6082 - acc: 0.5591 - val_loss: 1.2103 - val_keras_rmse_clf: 1.6022 - val_acc: 0.5538\nEpoch 68/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.2042 - keras_rmse_clf: 1.6066 - acc: 0.5591 - val_loss: 1.2068 - val_keras_rmse_clf: 1.6022 - val_acc: 0.5538\nEpoch 69/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.2007 - keras_rmse_clf: 1.6099 - acc: 0.5601 - val_loss: 1.2034 - val_keras_rmse_clf: 1.6085 - val_acc: 0.5575\nEpoch 70/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.1974 - keras_rmse_clf: 1.6117 - acc: 0.5611 - val_loss: 1.2001 - val_keras_rmse_clf: 1.6090 - val_acc: 0.5571\nEpoch 71/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.1940 - keras_rmse_clf: 1.6126 - acc: 0.5618 - val_loss: 1.1968 - val_keras_rmse_clf: 1.6110 - val_acc: 0.5586\nEpoch 72/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1907 - keras_rmse_clf: 1.6136 - acc: 0.5615 - val_loss: 1.1935 - val_keras_rmse_clf: 1.6110 - val_acc: 0.5586\nEpoch 73/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1874 - keras_rmse_clf: 1.6215 - acc: 0.5638 - val_loss: 1.1903 - val_keras_rmse_clf: 1.6231 - val_acc: 0.5630\nEpoch 74/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1842 - keras_rmse_clf: 1.6267 - acc: 0.5659 - val_loss: 1.1871 - val_keras_rmse_clf: 1.6231 - val_acc: 0.5630\nEpoch 75/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.1810 - keras_rmse_clf: 1.6285 - acc: 0.5673 - val_loss: 1.1840 - val_keras_rmse_clf: 1.6296 - val_acc: 0.5667\nEpoch 76/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.1779 - keras_rmse_clf: 1.6327 - acc: 0.5695 - val_loss: 1.1809 - val_keras_rmse_clf: 1.6296 - val_acc: 0.5667\nEpoch 77/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.1748 - keras_rmse_clf: 1.6315 - acc: 0.5711 - val_loss: 1.1778 - val_keras_rmse_clf: 1.6323 - val_acc: 0.5681\nEpoch 78/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1718 - keras_rmse_clf: 1.6343 - acc: 0.5715 - val_loss: 1.1748 - val_keras_rmse_clf: 1.6323 - val_acc: 0.5681\nEpoch 79/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.1688 - keras_rmse_clf: 1.6349 - acc: 0.5715 - val_loss: 1.1719 - val_keras_rmse_clf: 1.6323 - val_acc: 0.5681\nEpoch 80/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1658 - keras_rmse_clf: 1.6345 - acc: 0.5715 - val_loss: 1.1690 - val_keras_rmse_clf: 1.6323 - val_acc: 0.5681\nEpoch 81/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.1629 - keras_rmse_clf: 1.6339 - acc: 0.5715 - val_loss: 1.1660 - val_keras_rmse_clf: 1.6323 - val_acc: 0.5681\nEpoch 82/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1600 - keras_rmse_clf: 1.6355 - acc: 0.5715 - val_loss: 1.1632 - val_keras_rmse_clf: 1.6323 - val_acc: 0.5681\nEpoch 83/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1571 - keras_rmse_clf: 1.6362 - acc: 0.5718 - val_loss: 1.1604 - val_keras_rmse_clf: 1.6355 - val_acc: 0.5703\nEpoch 84/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1543 - keras_rmse_clf: 1.6412 - acc: 0.5738 - val_loss: 1.1576 - val_keras_rmse_clf: 1.6390 - val_acc: 0.5729\nEpoch 85/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1515 - keras_rmse_clf: 1.6446 - acc: 0.5763 - val_loss: 1.1549 - val_keras_rmse_clf: 1.6405 - val_acc: 0.5736\nEpoch 86/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1488 - keras_rmse_clf: 1.6446 - acc: 0.5770 - val_loss: 1.1521 - val_keras_rmse_clf: 1.6431 - val_acc: 0.5747\nEpoch 87/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1461 - keras_rmse_clf: 1.6507 - acc: 0.5788 - val_loss: 1.1495 - val_keras_rmse_clf: 1.6482 - val_acc: 0.5769\nEpoch 88/100\n43/43 [==============================] - 0s 7ms/step - loss: 1.1434 - keras_rmse_clf: 1.6524 - acc: 0.5811 - val_loss: 1.1469 - val_keras_rmse_clf: 1.6499 - val_acc: 0.5780\nEpoch 89/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.1408 - keras_rmse_clf: 1.6533 - acc: 0.5812 - val_loss: 1.1443 - val_keras_rmse_clf: 1.6503 - val_acc: 0.5784\nEpoch 90/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1382 - keras_rmse_clf: 1.6546 - acc: 0.5817 - val_loss: 1.1417 - val_keras_rmse_clf: 1.6503 - val_acc: 0.5784\nEpoch 91/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1357 - keras_rmse_clf: 1.6541 - acc: 0.5816 - val_loss: 1.1392 - val_keras_rmse_clf: 1.6539 - val_acc: 0.5795\nEpoch 92/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.1331 - keras_rmse_clf: 1.6564 - acc: 0.5822 - val_loss: 1.1366 - val_keras_rmse_clf: 1.6539 - val_acc: 0.5795\nEpoch 93/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1306 - keras_rmse_clf: 1.6556 - acc: 0.5822 - val_loss: 1.1342 - val_keras_rmse_clf: 1.6539 - val_acc: 0.5795\nEpoch 94/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1282 - keras_rmse_clf: 1.6594 - acc: 0.5840 - val_loss: 1.1317 - val_keras_rmse_clf: 1.6581 - val_acc: 0.5824\nEpoch 95/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1257 - keras_rmse_clf: 1.6610 - acc: 0.5844 - val_loss: 1.1293 - val_keras_rmse_clf: 1.6581 - val_acc: 0.5824\nEpoch 96/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1233 - keras_rmse_clf: 1.6605 - acc: 0.5844 - val_loss: 1.1269 - val_keras_rmse_clf: 1.6621 - val_acc: 0.5853\nEpoch 97/100\n43/43 [==============================] - 0s 5ms/step - loss: 1.1210 - keras_rmse_clf: 1.6656 - acc: 0.5883 - val_loss: 1.1246 - val_keras_rmse_clf: 1.6635 - val_acc: 0.5857\nEpoch 98/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1186 - keras_rmse_clf: 1.6669 - acc: 0.5889 - val_loss: 1.1223 - val_keras_rmse_clf: 1.6652 - val_acc: 0.5868\nEpoch 99/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1163 - keras_rmse_clf: 1.6699 - acc: 0.5901 - val_loss: 1.1200 - val_keras_rmse_clf: 1.6688 - val_acc: 0.5897\nEpoch 100/100\n43/43 [==============================] - 0s 6ms/step - loss: 1.1141 - keras_rmse_clf: 1.6712 - acc: 0.5917 - val_loss: 1.1177 - val_keras_rmse_clf: 1.6705 - val_acc: 0.5901\nEvaluating model....\n107/107 [==============================] - 0s 1ms/step - loss: 1.1277 - keras_rmse_clf: 1.6584 - acc: 0.5882\n[0 0 3 ... 0 0 0]\nComp Metric:  1.1679081208141078\n              precision    recall  f1-score   support\n\n         0.0       0.53      0.98      0.69      1499\n         1.0       0.00      0.00      0.00       648\n         2.0       0.00      0.00      0.00       544\n         3.0       0.84      0.76      0.80       709\n         4.0       0.00      0.00      0.00        12\n\n    accuracy                           0.59      3412\n   macro avg       0.27      0.35      0.30      3412\nweighted avg       0.41      0.59      0.47      3412\n\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = np.argmax(model.predict(X_val), axis=1)\nmse(y_val, preds.ravel(), squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:55:16.948749Z","iopub.execute_input":"2023-01-12T11:55:16.950163Z","iopub.status.idle":"2023-01-12T11:55:17.089706Z","shell.execute_reply.started":"2023-01-12T11:55:16.950119Z","shell.execute_reply":"2023-01-12T11:55:17.088936Z"},"trusted":true},"execution_count":106,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"1.1679081208141078"},"metadata":{}}]},{"cell_type":"code","source":"config.train.epochs = 300\nconfig.desc = \"overfitting dense model on mtdata sev by rs log-loss\"","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:57:58.157545Z","iopub.execute_input":"2023-01-12T11:57:58.158048Z","iopub.status.idle":"2023-01-12T11:57:58.163841Z","shell.execute_reply.started":"2023-01-12T11:57:58.158010Z","shell.execute_reply":"2023-01-12T11:57:58.162874Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"with wandb.init(project=config.PROJECT_NAME, config=config, name=config.name):\n    model = get_model('clf')\n    train_eval(model, 'clf', y_train=y_train, y_val=y_val)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T11:57:59.437784Z","iopub.execute_input":"2023-01-12T11:57:59.438586Z","iopub.status.idle":"2023-01-12T12:05:41.191626Z","shell.execute_reply.started":"2023-01-12T11:57:59.438545Z","shell.execute_reply":"2023-01-12T12:05:41.190045Z"},"trusted":true},"execution_count":113,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.8 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230112_115759-i5qd6xwg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/k_loki/tick-tick-bloom/runs/i5qd6xwg\" target=\"_blank\">d128_clf_mtdata-1673523296</a></strong> to <a href=\"https://wandb.ai/k_loki/tick-tick-bloom\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stdout","text":"Loading clf type model...\nTraining model... d128_clf_mtdata-1673523296\n","output_type":"stream"},{"name":"stderr","text":"2023-01-12 11:58:17.497585: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n2023-01-12 11:58:17.497871: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n2023-01-12 11:58:17.504628: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n  function_optimizer: function_optimizer did nothing. time = 0.017ms.\n  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/300\n43/43 [==============================] - 1s 12ms/step - loss: 1.8881 - keras_rmse_clf: 2.5425 - acc: 0.1019 - val_loss: 1.8640 - val_keras_rmse_clf: 2.5105 - val_acc: 0.1084\nEpoch 2/300\n43/43 [==============================] - 0s 8ms/step - loss: 1.8551 - keras_rmse_clf: 2.4885 - acc: 0.1164 - val_loss: 1.8321 - val_keras_rmse_clf: 2.4671 - val_acc: 0.1212\nEpoch 3/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.8237 - keras_rmse_clf: 2.4469 - acc: 0.1275 - val_loss: 1.8019 - val_keras_rmse_clf: 2.4241 - val_acc: 0.1326\nEpoch 4/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.7938 - keras_rmse_clf: 2.4127 - acc: 0.1380 - val_loss: 1.7730 - val_keras_rmse_clf: 2.3869 - val_acc: 0.1484\nEpoch 5/300\n43/43 [==============================] - 0s 9ms/step - loss: 1.7654 - keras_rmse_clf: 2.3813 - acc: 0.1468 - val_loss: 1.7457 - val_keras_rmse_clf: 2.3449 - val_acc: 0.1538\nEpoch 6/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.7385 - keras_rmse_clf: 2.3277 - acc: 0.1607 - val_loss: 1.7197 - val_keras_rmse_clf: 2.2981 - val_acc: 0.1755\nEpoch 7/300\n43/43 [==============================] - 0s 8ms/step - loss: 1.7130 - keras_rmse_clf: 2.2759 - acc: 0.1716 - val_loss: 1.6950 - val_keras_rmse_clf: 2.2443 - val_acc: 0.1824\nEpoch 8/300\n43/43 [==============================] - 0s 9ms/step - loss: 1.6888 - keras_rmse_clf: 2.1920 - acc: 0.1849 - val_loss: 1.6717 - val_keras_rmse_clf: 2.1153 - val_acc: 0.2106\nEpoch 9/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.6658 - keras_rmse_clf: 2.1001 - acc: 0.2150 - val_loss: 1.6495 - val_keras_rmse_clf: 2.0736 - val_acc: 0.2209\nEpoch 10/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.6440 - keras_rmse_clf: 2.0323 - acc: 0.2228 - val_loss: 1.6285 - val_keras_rmse_clf: 2.0091 - val_acc: 0.2300\nEpoch 11/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.6233 - keras_rmse_clf: 1.9884 - acc: 0.2470 - val_loss: 1.6087 - val_keras_rmse_clf: 1.9371 - val_acc: 0.2718\nEpoch 12/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.6038 - keras_rmse_clf: 1.9109 - acc: 0.2833 - val_loss: 1.5897 - val_keras_rmse_clf: 1.8780 - val_acc: 0.3051\nEpoch 13/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.5852 - keras_rmse_clf: 1.8096 - acc: 0.3440 - val_loss: 1.5719 - val_keras_rmse_clf: 1.7560 - val_acc: 0.3718\nEpoch 14/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.5676 - keras_rmse_clf: 1.7405 - acc: 0.3741 - val_loss: 1.5548 - val_keras_rmse_clf: 1.6969 - val_acc: 0.3894\nEpoch 15/300\n43/43 [==============================] - 0s 8ms/step - loss: 1.5509 - keras_rmse_clf: 1.6915 - acc: 0.3928 - val_loss: 1.5387 - val_keras_rmse_clf: 1.6735 - val_acc: 0.3930\nEpoch 16/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.5350 - keras_rmse_clf: 1.6570 - acc: 0.3994 - val_loss: 1.5234 - val_keras_rmse_clf: 1.6362 - val_acc: 0.3993\nEpoch 17/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.5199 - keras_rmse_clf: 1.6180 - acc: 0.4070 - val_loss: 1.5089 - val_keras_rmse_clf: 1.6026 - val_acc: 0.4084\nEpoch 18/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.5056 - keras_rmse_clf: 1.5887 - acc: 0.4138 - val_loss: 1.4950 - val_keras_rmse_clf: 1.5595 - val_acc: 0.4216\nEpoch 19/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.4921 - keras_rmse_clf: 1.5533 - acc: 0.4211 - val_loss: 1.4819 - val_keras_rmse_clf: 1.5344 - val_acc: 0.4238\nEpoch 20/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.4792 - keras_rmse_clf: 1.5230 - acc: 0.4256 - val_loss: 1.4694 - val_keras_rmse_clf: 1.5162 - val_acc: 0.4253\nEpoch 21/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.4669 - keras_rmse_clf: 1.5128 - acc: 0.4247 - val_loss: 1.4576 - val_keras_rmse_clf: 1.5075 - val_acc: 0.4223\nEpoch 22/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.4552 - keras_rmse_clf: 1.4980 - acc: 0.4285 - val_loss: 1.4464 - val_keras_rmse_clf: 1.4978 - val_acc: 0.4260\nEpoch 23/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.4441 - keras_rmse_clf: 1.4981 - acc: 0.4295 - val_loss: 1.4356 - val_keras_rmse_clf: 1.4939 - val_acc: 0.4271\nEpoch 24/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.4335 - keras_rmse_clf: 1.4875 - acc: 0.4322 - val_loss: 1.4253 - val_keras_rmse_clf: 1.4843 - val_acc: 0.4326\nEpoch 25/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.4234 - keras_rmse_clf: 1.4787 - acc: 0.4305 - val_loss: 1.4155 - val_keras_rmse_clf: 1.4728 - val_acc: 0.4304\nEpoch 59/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.2131 - keras_rmse_clf: 1.6341 - acc: 0.5585 - val_loss: 1.2101 - val_keras_rmse_clf: 1.6350 - val_acc: 0.5590\nEpoch 60/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.2088 - keras_rmse_clf: 1.6347 - acc: 0.5618 - val_loss: 1.2059 - val_keras_rmse_clf: 1.6340 - val_acc: 0.5601\nEpoch 61/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.2045 - keras_rmse_clf: 1.6397 - acc: 0.5648 - val_loss: 1.2018 - val_keras_rmse_clf: 1.6428 - val_acc: 0.5659\nEpoch 62/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.2004 - keras_rmse_clf: 1.6454 - acc: 0.5693 - val_loss: 1.1976 - val_keras_rmse_clf: 1.6495 - val_acc: 0.5703\nEpoch 63/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1962 - keras_rmse_clf: 1.6517 - acc: 0.5721 - val_loss: 1.1936 - val_keras_rmse_clf: 1.6498 - val_acc: 0.5711\nEpoch 64/300\n43/43 [==============================] - 0s 11ms/step - loss: 1.1921 - keras_rmse_clf: 1.6539 - acc: 0.5742 - val_loss: 1.1896 - val_keras_rmse_clf: 1.6509 - val_acc: 0.5725\nEpoch 65/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1881 - keras_rmse_clf: 1.6540 - acc: 0.5742 - val_loss: 1.1857 - val_keras_rmse_clf: 1.6509 - val_acc: 0.5725\nEpoch 66/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1841 - keras_rmse_clf: 1.6556 - acc: 0.5752 - val_loss: 1.1817 - val_keras_rmse_clf: 1.6513 - val_acc: 0.5725\nEpoch 67/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1802 - keras_rmse_clf: 1.6578 - acc: 0.5758 - val_loss: 1.1779 - val_keras_rmse_clf: 1.6549 - val_acc: 0.5747\nEpoch 68/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.1763 - keras_rmse_clf: 1.6594 - acc: 0.5780 - val_loss: 1.1741 - val_keras_rmse_clf: 1.6572 - val_acc: 0.5784\nEpoch 69/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1725 - keras_rmse_clf: 1.6627 - acc: 0.5805 - val_loss: 1.1703 - val_keras_rmse_clf: 1.6572 - val_acc: 0.5784\nEpoch 70/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1687 - keras_rmse_clf: 1.6612 - acc: 0.5817 - val_loss: 1.1666 - val_keras_rmse_clf: 1.6570 - val_acc: 0.5788\nEpoch 71/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1650 - keras_rmse_clf: 1.6639 - acc: 0.5833 - val_loss: 1.1630 - val_keras_rmse_clf: 1.6595 - val_acc: 0.5802\nEpoch 72/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1614 - keras_rmse_clf: 1.6646 - acc: 0.5848 - val_loss: 1.1594 - val_keras_rmse_clf: 1.6627 - val_acc: 0.5824\nEpoch 73/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.1578 - keras_rmse_clf: 1.6668 - acc: 0.5878 - val_loss: 1.1560 - val_keras_rmse_clf: 1.6637 - val_acc: 0.5857\nEpoch 74/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.1543 - keras_rmse_clf: 1.6692 - acc: 0.5900 - val_loss: 1.1525 - val_keras_rmse_clf: 1.6705 - val_acc: 0.5905\nEpoch 75/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1509 - keras_rmse_clf: 1.6738 - acc: 0.5935 - val_loss: 1.1492 - val_keras_rmse_clf: 1.6725 - val_acc: 0.5930\nEpoch 76/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1475 - keras_rmse_clf: 1.6771 - acc: 0.5974 - val_loss: 1.1458 - val_keras_rmse_clf: 1.6752 - val_acc: 0.5952\nEpoch 77/300\n43/43 [==============================] - 0s 8ms/step - loss: 1.1441 - keras_rmse_clf: 1.6758 - acc: 0.5984 - val_loss: 1.1425 - val_keras_rmse_clf: 1.6752 - val_acc: 0.5952\nEpoch 78/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1408 - keras_rmse_clf: 1.6807 - acc: 0.5997 - val_loss: 1.1392 - val_keras_rmse_clf: 1.6774 - val_acc: 0.5963\nEpoch 79/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1376 - keras_rmse_clf: 1.6830 - acc: 0.6011 - val_loss: 1.1361 - val_keras_rmse_clf: 1.6791 - val_acc: 0.5978\nEpoch 80/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.1344 - keras_rmse_clf: 1.6843 - acc: 0.6019 - val_loss: 1.1330 - val_keras_rmse_clf: 1.6791 - val_acc: 0.5978\nEpoch 81/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1312 - keras_rmse_clf: 1.6851 - acc: 0.6033 - val_loss: 1.1298 - val_keras_rmse_clf: 1.6822 - val_acc: 0.6000\nEpoch 82/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1281 - keras_rmse_clf: 1.6872 - acc: 0.6036 - val_loss: 1.1267 - val_keras_rmse_clf: 1.6822 - val_acc: 0.6000\nEpoch 83/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1250 - keras_rmse_clf: 1.6871 - acc: 0.6036 - val_loss: 1.1236 - val_keras_rmse_clf: 1.6822 - val_acc: 0.6000\nEpoch 84/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1220 - keras_rmse_clf: 1.6880 - acc: 0.6036 - val_loss: 1.1206 - val_keras_rmse_clf: 1.6822 - val_acc: 0.6000\nEpoch 85/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1190 - keras_rmse_clf: 1.6886 - acc: 0.6036 - val_loss: 1.1176 - val_keras_rmse_clf: 1.6849 - val_acc: 0.6018\nEpoch 86/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1161 - keras_rmse_clf: 1.6904 - acc: 0.6059 - val_loss: 1.1147 - val_keras_rmse_clf: 1.6923 - val_acc: 0.6073\nEpoch 87/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1132 - keras_rmse_clf: 1.6922 - acc: 0.6065 - val_loss: 1.1119 - val_keras_rmse_clf: 1.6922 - val_acc: 0.6081\nEpoch 88/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1104 - keras_rmse_clf: 1.6940 - acc: 0.6094 - val_loss: 1.1091 - val_keras_rmse_clf: 1.6957 - val_acc: 0.6110\nEpoch 89/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1077 - keras_rmse_clf: 1.6952 - acc: 0.6101 - val_loss: 1.1064 - val_keras_rmse_clf: 1.6962 - val_acc: 0.6125\nEpoch 90/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1050 - keras_rmse_clf: 1.6958 - acc: 0.6108 - val_loss: 1.1038 - val_keras_rmse_clf: 1.6962 - val_acc: 0.6125\nEpoch 91/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.1024 - keras_rmse_clf: 1.6960 - acc: 0.6106 - val_loss: 1.1012 - val_keras_rmse_clf: 1.6965 - val_acc: 0.6128\nEpoch 92/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0999 - keras_rmse_clf: 1.6957 - acc: 0.6106 - val_loss: 1.0986 - val_keras_rmse_clf: 1.6962 - val_acc: 0.6125\nEpoch 93/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0973 - keras_rmse_clf: 1.6965 - acc: 0.6111 - val_loss: 1.0962 - val_keras_rmse_clf: 1.6983 - val_acc: 0.6128\nEpoch 94/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0949 - keras_rmse_clf: 1.6967 - acc: 0.6110 - val_loss: 1.0936 - val_keras_rmse_clf: 1.6983 - val_acc: 0.6128\nEpoch 95/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.0925 - keras_rmse_clf: 1.6983 - acc: 0.6110 - val_loss: 1.0913 - val_keras_rmse_clf: 1.6983 - val_acc: 0.6128\nEpoch 96/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0901 - keras_rmse_clf: 1.6989 - acc: 0.6121 - val_loss: 1.0890 - val_keras_rmse_clf: 1.6994 - val_acc: 0.6132\nEpoch 97/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0878 - keras_rmse_clf: 1.6998 - acc: 0.6138 - val_loss: 1.0867 - val_keras_rmse_clf: 1.7006 - val_acc: 0.6143\nEpoch 98/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0856 - keras_rmse_clf: 1.6997 - acc: 0.6138 - val_loss: 1.0845 - val_keras_rmse_clf: 1.7006 - val_acc: 0.6143\nEpoch 99/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0833 - keras_rmse_clf: 1.7009 - acc: 0.6154 - val_loss: 1.0823 - val_keras_rmse_clf: 1.7004 - val_acc: 0.6154\nEpoch 100/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0812 - keras_rmse_clf: 1.7000 - acc: 0.6154 - val_loss: 1.0801 - val_keras_rmse_clf: 1.7007 - val_acc: 0.6143\nEpoch 101/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0790 - keras_rmse_clf: 1.7000 - acc: 0.6151 - val_loss: 1.0780 - val_keras_rmse_clf: 1.7007 - val_acc: 0.6143\nEpoch 102/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0770 - keras_rmse_clf: 1.7001 - acc: 0.6152 - val_loss: 1.0760 - val_keras_rmse_clf: 1.7012 - val_acc: 0.6147\nEpoch 103/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0749 - keras_rmse_clf: 1.7015 - acc: 0.6157 - val_loss: 1.0740 - val_keras_rmse_clf: 1.7012 - val_acc: 0.6147\nEpoch 104/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0729 - keras_rmse_clf: 1.6999 - acc: 0.6157 - val_loss: 1.0720 - val_keras_rmse_clf: 1.7012 - val_acc: 0.6147\nEpoch 105/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0710 - keras_rmse_clf: 1.7022 - acc: 0.6162 - val_loss: 1.0701 - val_keras_rmse_clf: 1.7028 - val_acc: 0.6147\nEpoch 106/300\n43/43 [==============================] - 0s 10ms/step - loss: 1.0690 - keras_rmse_clf: 1.7048 - acc: 0.6171 - val_loss: 1.0681 - val_keras_rmse_clf: 1.7028 - val_acc: 0.6147\nEpoch 107/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0671 - keras_rmse_clf: 1.7042 - acc: 0.6175 - val_loss: 1.0663 - val_keras_rmse_clf: 1.7029 - val_acc: 0.6139\nEpoch 108/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0653 - keras_rmse_clf: 1.7032 - acc: 0.6174 - val_loss: 1.0645 - val_keras_rmse_clf: 1.7029 - val_acc: 0.6139\nEpoch 109/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0635 - keras_rmse_clf: 1.7047 - acc: 0.6180 - val_loss: 1.0626 - val_keras_rmse_clf: 1.7058 - val_acc: 0.6168\nEpoch 110/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0617 - keras_rmse_clf: 1.7043 - acc: 0.6189 - val_loss: 1.0609 - val_keras_rmse_clf: 1.7058 - val_acc: 0.6168\nEpoch 111/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0599 - keras_rmse_clf: 1.7056 - acc: 0.6189 - val_loss: 1.0591 - val_keras_rmse_clf: 1.7058 - val_acc: 0.6168\nEpoch 112/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0581 - keras_rmse_clf: 1.7045 - acc: 0.6189 - val_loss: 1.0574 - val_keras_rmse_clf: 1.7058 - val_acc: 0.6168\nEpoch 113/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0565 - keras_rmse_clf: 1.7038 - acc: 0.6189 - val_loss: 1.0557 - val_keras_rmse_clf: 1.7058 - val_acc: 0.6168\nEpoch 114/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0548 - keras_rmse_clf: 1.7057 - acc: 0.6189 - val_loss: 1.0541 - val_keras_rmse_clf: 1.7057 - val_acc: 0.6187\nEpoch 115/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0532 - keras_rmse_clf: 1.7045 - acc: 0.6199 - val_loss: 1.0524 - val_keras_rmse_clf: 1.7057 - val_acc: 0.6187\nEpoch 116/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0515 - keras_rmse_clf: 1.7050 - acc: 0.6207 - val_loss: 1.0509 - val_keras_rmse_clf: 1.7103 - val_acc: 0.6216\nEpoch 117/300\n43/43 [==============================] - 0s 5ms/step - loss: 1.0500 - keras_rmse_clf: 1.7080 - acc: 0.6215 - val_loss: 1.0493 - val_keras_rmse_clf: 1.7103 - val_acc: 0.6216\nEpoch 118/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0485 - keras_rmse_clf: 1.7092 - acc: 0.6221 - val_loss: 1.0478 - val_keras_rmse_clf: 1.7109 - val_acc: 0.6223\nEpoch 119/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0469 - keras_rmse_clf: 1.7080 - acc: 0.6215 - val_loss: 1.0463 - val_keras_rmse_clf: 1.7109 - val_acc: 0.6223\nEpoch 120/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0455 - keras_rmse_clf: 1.7090 - acc: 0.6225 - val_loss: 1.0449 - val_keras_rmse_clf: 1.7109 - val_acc: 0.6223\nEpoch 121/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0441 - keras_rmse_clf: 1.7093 - acc: 0.6235 - val_loss: 1.0434 - val_keras_rmse_clf: 1.7105 - val_acc: 0.6245\nEpoch 122/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0426 - keras_rmse_clf: 1.7089 - acc: 0.6232 - val_loss: 1.0420 - val_keras_rmse_clf: 1.7106 - val_acc: 0.6249\nEpoch 123/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0412 - keras_rmse_clf: 1.7084 - acc: 0.6235 - val_loss: 1.0406 - val_keras_rmse_clf: 1.7106 - val_acc: 0.6249\nEpoch 124/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.0399 - keras_rmse_clf: 1.7093 - acc: 0.6249 - val_loss: 1.0393 - val_keras_rmse_clf: 1.7134 - val_acc: 0.6271\nEpoch 125/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0385 - keras_rmse_clf: 1.7114 - acc: 0.6249 - val_loss: 1.0379 - val_keras_rmse_clf: 1.7134 - val_acc: 0.6271\nEpoch 126/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.0372 - keras_rmse_clf: 1.7109 - acc: 0.6252 - val_loss: 1.0366 - val_keras_rmse_clf: 1.7134 - val_acc: 0.6271\nEpoch 127/300\n43/43 [==============================] - 1s 12ms/step - loss: 1.0359 - keras_rmse_clf: 1.7092 - acc: 0.6249 - val_loss: 1.0353 - val_keras_rmse_clf: 1.7134 - val_acc: 0.6271\nEpoch 128/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.0346 - keras_rmse_clf: 1.7103 - acc: 0.6259 - val_loss: 1.0340 - val_keras_rmse_clf: 1.7134 - val_acc: 0.6271\nEpoch 129/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.0333 - keras_rmse_clf: 1.7098 - acc: 0.6263 - val_loss: 1.0327 - val_keras_rmse_clf: 1.7136 - val_acc: 0.6286\nEpoch 130/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0321 - keras_rmse_clf: 1.7106 - acc: 0.6263 - val_loss: 1.0315 - val_keras_rmse_clf: 1.7148 - val_acc: 0.6300\nEpoch 131/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.0308 - keras_rmse_clf: 1.7108 - acc: 0.6269 - val_loss: 1.0303 - val_keras_rmse_clf: 1.7148 - val_acc: 0.6300\nEpoch 132/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0296 - keras_rmse_clf: 1.7126 - acc: 0.6269 - val_loss: 1.0291 - val_keras_rmse_clf: 1.7148 - val_acc: 0.6300\nEpoch 133/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0284 - keras_rmse_clf: 1.7112 - acc: 0.6269 - val_loss: 1.0278 - val_keras_rmse_clf: 1.7148 - val_acc: 0.6300\nEpoch 134/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0272 - keras_rmse_clf: 1.7126 - acc: 0.6269 - val_loss: 1.0267 - val_keras_rmse_clf: 1.7148 - val_acc: 0.6300\nEpoch 135/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0261 - keras_rmse_clf: 1.7098 - acc: 0.6271 - val_loss: 1.0255 - val_keras_rmse_clf: 1.7182 - val_acc: 0.6319\nEpoch 136/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.0249 - keras_rmse_clf: 1.7144 - acc: 0.6280 - val_loss: 1.0244 - val_keras_rmse_clf: 1.7182 - val_acc: 0.6319\nEpoch 137/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0238 - keras_rmse_clf: 1.7148 - acc: 0.6283 - val_loss: 1.0232 - val_keras_rmse_clf: 1.7193 - val_acc: 0.6330\nEpoch 138/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0226 - keras_rmse_clf: 1.7141 - acc: 0.6289 - val_loss: 1.0221 - val_keras_rmse_clf: 1.7193 - val_acc: 0.6330\nEpoch 139/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0216 - keras_rmse_clf: 1.7156 - acc: 0.6288 - val_loss: 1.0210 - val_keras_rmse_clf: 1.7196 - val_acc: 0.6330\nEpoch 140/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0205 - keras_rmse_clf: 1.7163 - acc: 0.6286 - val_loss: 1.0199 - val_keras_rmse_clf: 1.7196 - val_acc: 0.6330\nEpoch 141/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0194 - keras_rmse_clf: 1.7163 - acc: 0.6286 - val_loss: 1.0189 - val_keras_rmse_clf: 1.7196 - val_acc: 0.6330\nEpoch 142/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0184 - keras_rmse_clf: 1.7148 - acc: 0.6286 - val_loss: 1.0178 - val_keras_rmse_clf: 1.7196 - val_acc: 0.6330\nEpoch 143/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0174 - keras_rmse_clf: 1.7166 - acc: 0.6286 - val_loss: 1.0168 - val_keras_rmse_clf: 1.7196 - val_acc: 0.6330\nEpoch 144/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0164 - keras_rmse_clf: 1.7151 - acc: 0.6286 - val_loss: 1.0158 - val_keras_rmse_clf: 1.7196 - val_acc: 0.6330\nEpoch 145/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0153 - keras_rmse_clf: 1.7166 - acc: 0.6288 - val_loss: 1.0149 - val_keras_rmse_clf: 1.7196 - val_acc: 0.6330\nEpoch 146/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0144 - keras_rmse_clf: 1.7149 - acc: 0.6286 - val_loss: 1.0139 - val_keras_rmse_clf: 1.7196 - val_acc: 0.6330\nEpoch 147/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0134 - keras_rmse_clf: 1.7175 - acc: 0.6304 - val_loss: 1.0129 - val_keras_rmse_clf: 1.7226 - val_acc: 0.6359\nEpoch 148/300\n43/43 [==============================] - 1s 13ms/step - loss: 1.0125 - keras_rmse_clf: 1.7168 - acc: 0.6306 - val_loss: 1.0120 - val_keras_rmse_clf: 1.7226 - val_acc: 0.6359\nEpoch 149/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0116 - keras_rmse_clf: 1.7165 - acc: 0.6306 - val_loss: 1.0111 - val_keras_rmse_clf: 1.7226 - val_acc: 0.6359\nEpoch 150/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0107 - keras_rmse_clf: 1.7177 - acc: 0.6306 - val_loss: 1.0102 - val_keras_rmse_clf: 1.7226 - val_acc: 0.6359\nEpoch 151/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0098 - keras_rmse_clf: 1.7175 - acc: 0.6307 - val_loss: 1.0093 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 152/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0089 - keras_rmse_clf: 1.7175 - acc: 0.6311 - val_loss: 1.0084 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 153/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0080 - keras_rmse_clf: 1.7182 - acc: 0.6312 - val_loss: 1.0076 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 154/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0072 - keras_rmse_clf: 1.7186 - acc: 0.6313 - val_loss: 1.0067 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 155/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0064 - keras_rmse_clf: 1.7176 - acc: 0.6313 - val_loss: 1.0059 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 156/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0056 - keras_rmse_clf: 1.7177 - acc: 0.6313 - val_loss: 1.0051 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 157/300\n43/43 [==============================] - 0s 7ms/step - loss: 1.0048 - keras_rmse_clf: 1.7180 - acc: 0.6313 - val_loss: 1.0043 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 158/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0040 - keras_rmse_clf: 1.7182 - acc: 0.6313 - val_loss: 1.0035 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 159/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0032 - keras_rmse_clf: 1.7171 - acc: 0.6313 - val_loss: 1.0028 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 160/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0024 - keras_rmse_clf: 1.7178 - acc: 0.6313 - val_loss: 1.0020 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 161/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0017 - keras_rmse_clf: 1.7165 - acc: 0.6313 - val_loss: 1.0012 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 162/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0009 - keras_rmse_clf: 1.7153 - acc: 0.6313 - val_loss: 1.0006 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 163/300\n43/43 [==============================] - 0s 6ms/step - loss: 1.0002 - keras_rmse_clf: 1.7184 - acc: 0.6313 - val_loss: 0.9998 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 164/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9995 - keras_rmse_clf: 1.7171 - acc: 0.6313 - val_loss: 0.9991 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 165/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9988 - keras_rmse_clf: 1.7170 - acc: 0.6313 - val_loss: 0.9985 - val_keras_rmse_clf: 1.7224 - val_acc: 0.6377\nEpoch 166/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9982 - keras_rmse_clf: 1.7191 - acc: 0.6318 - val_loss: 0.9978 - val_keras_rmse_clf: 1.7244 - val_acc: 0.6388\nEpoch 167/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9975 - keras_rmse_clf: 1.7202 - acc: 0.6327 - val_loss: 0.9971 - val_keras_rmse_clf: 1.7244 - val_acc: 0.6388\nEpoch 168/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9968 - keras_rmse_clf: 1.7178 - acc: 0.6321 - val_loss: 0.9965 - val_keras_rmse_clf: 1.7226 - val_acc: 0.6377\nEpoch 169/300\n43/43 [==============================] - 0s 8ms/step - loss: 0.9962 - keras_rmse_clf: 1.7204 - acc: 0.6325 - val_loss: 0.9959 - val_keras_rmse_clf: 1.7246 - val_acc: 0.6388\nEpoch 170/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9956 - keras_rmse_clf: 1.7211 - acc: 0.6327 - val_loss: 0.9952 - val_keras_rmse_clf: 1.7246 - val_acc: 0.6388\nEpoch 171/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9950 - keras_rmse_clf: 1.7207 - acc: 0.6327 - val_loss: 0.9946 - val_keras_rmse_clf: 1.7246 - val_acc: 0.6388\nEpoch 172/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9944 - keras_rmse_clf: 1.7199 - acc: 0.6327 - val_loss: 0.9941 - val_keras_rmse_clf: 1.7246 - val_acc: 0.6388\nEpoch 173/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9938 - keras_rmse_clf: 1.7196 - acc: 0.6327 - val_loss: 0.9935 - val_keras_rmse_clf: 1.7246 - val_acc: 0.6388\nEpoch 174/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9932 - keras_rmse_clf: 1.7206 - acc: 0.6327 - val_loss: 0.9929 - val_keras_rmse_clf: 1.7246 - val_acc: 0.6388\nEpoch 175/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9926 - keras_rmse_clf: 1.7202 - acc: 0.6327 - val_loss: 0.9923 - val_keras_rmse_clf: 1.7246 - val_acc: 0.6388\nEpoch 176/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9920 - keras_rmse_clf: 1.7187 - acc: 0.6334 - val_loss: 0.9918 - val_keras_rmse_clf: 1.7247 - val_acc: 0.6403\nEpoch 177/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9915 - keras_rmse_clf: 1.7209 - acc: 0.6343 - val_loss: 0.9911 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6407\nEpoch 178/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9909 - keras_rmse_clf: 1.7209 - acc: 0.6345 - val_loss: 0.9906 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6407\nEpoch 179/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9903 - keras_rmse_clf: 1.7215 - acc: 0.6351 - val_loss: 0.9900 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6407\nEpoch 180/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9898 - keras_rmse_clf: 1.7186 - acc: 0.6351 - val_loss: 0.9895 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6407\nEpoch 181/300\n43/43 [==============================] - 0s 8ms/step - loss: 0.9892 - keras_rmse_clf: 1.7219 - acc: 0.6351 - val_loss: 0.9890 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6407\nEpoch 182/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9887 - keras_rmse_clf: 1.7222 - acc: 0.6351 - val_loss: 0.9884 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6407\nEpoch 183/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9882 - keras_rmse_clf: 1.7207 - acc: 0.6351 - val_loss: 0.9879 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6407\nEpoch 184/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9877 - keras_rmse_clf: 1.7202 - acc: 0.6351 - val_loss: 0.9874 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6407\nEpoch 185/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9872 - keras_rmse_clf: 1.7214 - acc: 0.6351 - val_loss: 0.9869 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6407\nEpoch 186/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9867 - keras_rmse_clf: 1.7203 - acc: 0.6351 - val_loss: 0.9864 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6407\nEpoch 187/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9862 - keras_rmse_clf: 1.7212 - acc: 0.6351 - val_loss: 0.9860 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6407\nEpoch 188/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9857 - keras_rmse_clf: 1.7212 - acc: 0.6361 - val_loss: 0.9854 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6407\nEpoch 189/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9852 - keras_rmse_clf: 1.7215 - acc: 0.6355 - val_loss: 0.9850 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6407\nEpoch 190/300\n43/43 [==============================] - 0s 9ms/step - loss: 0.9848 - keras_rmse_clf: 1.7212 - acc: 0.6351 - val_loss: 0.9845 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6407\nEpoch 191/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9843 - keras_rmse_clf: 1.7210 - acc: 0.6372 - val_loss: 0.9841 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 192/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9839 - keras_rmse_clf: 1.7221 - acc: 0.6376 - val_loss: 0.9836 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 193/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9834 - keras_rmse_clf: 1.7201 - acc: 0.6376 - val_loss: 0.9832 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 194/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9830 - keras_rmse_clf: 1.7205 - acc: 0.6376 - val_loss: 0.9828 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 195/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9825 - keras_rmse_clf: 1.7218 - acc: 0.6376 - val_loss: 0.9822 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 196/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9821 - keras_rmse_clf: 1.7204 - acc: 0.6376 - val_loss: 0.9819 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 197/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9817 - keras_rmse_clf: 1.7196 - acc: 0.6376 - val_loss: 0.9814 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 198/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9812 - keras_rmse_clf: 1.7208 - acc: 0.6376 - val_loss: 0.9810 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 199/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9808 - keras_rmse_clf: 1.7212 - acc: 0.6376 - val_loss: 0.9806 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 200/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9804 - keras_rmse_clf: 1.7204 - acc: 0.6376 - val_loss: 0.9801 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 201/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9800 - keras_rmse_clf: 1.7207 - acc: 0.6376 - val_loss: 0.9797 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 202/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9795 - keras_rmse_clf: 1.7208 - acc: 0.6376 - val_loss: 0.9792 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 203/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9791 - keras_rmse_clf: 1.7214 - acc: 0.6375 - val_loss: 0.9788 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 204/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9787 - keras_rmse_clf: 1.7224 - acc: 0.6376 - val_loss: 0.9785 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 205/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9783 - keras_rmse_clf: 1.7214 - acc: 0.6376 - val_loss: 0.9780 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 206/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9780 - keras_rmse_clf: 1.7202 - acc: 0.6375 - val_loss: 0.9777 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 207/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9776 - keras_rmse_clf: 1.7201 - acc: 0.6375 - val_loss: 0.9772 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 208/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9772 - keras_rmse_clf: 1.7226 - acc: 0.6375 - val_loss: 0.9769 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 209/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9768 - keras_rmse_clf: 1.7212 - acc: 0.6375 - val_loss: 0.9765 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 210/300\n43/43 [==============================] - 0s 7ms/step - loss: 0.9764 - keras_rmse_clf: 1.7207 - acc: 0.6371 - val_loss: 0.9760 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 211/300\n43/43 [==============================] - 0s 7ms/step - loss: 0.9760 - keras_rmse_clf: 1.7211 - acc: 0.6375 - val_loss: 0.9758 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 212/300\n43/43 [==============================] - 0s 10ms/step - loss: 0.9757 - keras_rmse_clf: 1.7219 - acc: 0.6375 - val_loss: 0.9754 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 213/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9753 - keras_rmse_clf: 1.7208 - acc: 0.6375 - val_loss: 0.9750 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 214/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9750 - keras_rmse_clf: 1.7205 - acc: 0.6373 - val_loss: 0.9746 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 215/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9746 - keras_rmse_clf: 1.7193 - acc: 0.6366 - val_loss: 0.9742 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 216/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9743 - keras_rmse_clf: 1.7183 - acc: 0.6363 - val_loss: 0.9739 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 217/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9739 - keras_rmse_clf: 1.7217 - acc: 0.6375 - val_loss: 0.9735 - val_keras_rmse_clf: 1.7262 - val_acc: 0.6429\nEpoch 218/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9736 - keras_rmse_clf: 1.7200 - acc: 0.6370 - val_loss: 0.9732 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 219/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9732 - keras_rmse_clf: 1.7189 - acc: 0.6363 - val_loss: 0.9728 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 220/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9729 - keras_rmse_clf: 1.7192 - acc: 0.6363 - val_loss: 0.9725 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 221/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9726 - keras_rmse_clf: 1.7186 - acc: 0.6363 - val_loss: 0.9721 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 222/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9722 - keras_rmse_clf: 1.7188 - acc: 0.6363 - val_loss: 0.9718 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 223/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9719 - keras_rmse_clf: 1.7194 - acc: 0.6363 - val_loss: 0.9714 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 224/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9716 - keras_rmse_clf: 1.7192 - acc: 0.6363 - val_loss: 0.9711 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 225/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9713 - keras_rmse_clf: 1.7196 - acc: 0.6363 - val_loss: 0.9708 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 226/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9710 - keras_rmse_clf: 1.7179 - acc: 0.6363 - val_loss: 0.9705 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 227/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9707 - keras_rmse_clf: 1.7189 - acc: 0.6363 - val_loss: 0.9702 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 228/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9704 - keras_rmse_clf: 1.7190 - acc: 0.6363 - val_loss: 0.9698 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 229/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9700 - keras_rmse_clf: 1.7189 - acc: 0.6363 - val_loss: 0.9695 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 230/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9698 - keras_rmse_clf: 1.7193 - acc: 0.6363 - val_loss: 0.9693 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 231/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9695 - keras_rmse_clf: 1.7199 - acc: 0.6363 - val_loss: 0.9689 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 232/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9692 - keras_rmse_clf: 1.7189 - acc: 0.6363 - val_loss: 0.9686 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 233/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9689 - keras_rmse_clf: 1.7192 - acc: 0.6363 - val_loss: 0.9683 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 234/300\n43/43 [==============================] - 1s 13ms/step - loss: 0.9686 - keras_rmse_clf: 1.7190 - acc: 0.6363 - val_loss: 0.9680 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 235/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9684 - keras_rmse_clf: 1.7183 - acc: 0.6363 - val_loss: 0.9677 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 236/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9681 - keras_rmse_clf: 1.7192 - acc: 0.6366 - val_loss: 0.9674 - val_keras_rmse_clf: 1.7242 - val_acc: 0.6418\nEpoch 237/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9678 - keras_rmse_clf: 1.7187 - acc: 0.6362 - val_loss: 0.9672 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 238/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9676 - keras_rmse_clf: 1.7193 - acc: 0.6364 - val_loss: 0.9669 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 239/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9673 - keras_rmse_clf: 1.7191 - acc: 0.6368 - val_loss: 0.9666 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 240/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9671 - keras_rmse_clf: 1.7181 - acc: 0.6374 - val_loss: 0.9664 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 241/300\n43/43 [==============================] - 0s 5ms/step - loss: 0.9668 - keras_rmse_clf: 1.7197 - acc: 0.6373 - val_loss: 0.9660 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 242/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9666 - keras_rmse_clf: 1.7186 - acc: 0.6374 - val_loss: 0.9658 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 243/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9663 - keras_rmse_clf: 1.7188 - acc: 0.6375 - val_loss: 0.9655 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 244/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9661 - keras_rmse_clf: 1.7192 - acc: 0.6375 - val_loss: 0.9653 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 245/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9658 - keras_rmse_clf: 1.7180 - acc: 0.6375 - val_loss: 0.9651 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 246/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9656 - keras_rmse_clf: 1.7191 - acc: 0.6374 - val_loss: 0.9648 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 247/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9654 - keras_rmse_clf: 1.7185 - acc: 0.6375 - val_loss: 0.9646 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 248/300\n43/43 [==============================] - 0s 5ms/step - loss: 0.9652 - keras_rmse_clf: 1.7191 - acc: 0.6375 - val_loss: 0.9643 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 249/300\n43/43 [==============================] - 0s 5ms/step - loss: 0.9649 - keras_rmse_clf: 1.7174 - acc: 0.6375 - val_loss: 0.9641 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 250/300\n43/43 [==============================] - 0s 5ms/step - loss: 0.9647 - keras_rmse_clf: 1.7196 - acc: 0.6375 - val_loss: 0.9638 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 251/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9645 - keras_rmse_clf: 1.7186 - acc: 0.6375 - val_loss: 0.9636 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 252/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9642 - keras_rmse_clf: 1.7196 - acc: 0.6375 - val_loss: 0.9634 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 253/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9640 - keras_rmse_clf: 1.7204 - acc: 0.6375 - val_loss: 0.9631 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 254/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9638 - keras_rmse_clf: 1.7198 - acc: 0.6375 - val_loss: 0.9629 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 255/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9636 - keras_rmse_clf: 1.7192 - acc: 0.6375 - val_loss: 0.9627 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 256/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9634 - keras_rmse_clf: 1.7202 - acc: 0.6375 - val_loss: 0.9625 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 257/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9632 - keras_rmse_clf: 1.7187 - acc: 0.6375 - val_loss: 0.9622 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 258/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9630 - keras_rmse_clf: 1.7186 - acc: 0.6375 - val_loss: 0.9620 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 259/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9628 - keras_rmse_clf: 1.7186 - acc: 0.6375 - val_loss: 0.9618 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 260/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9626 - keras_rmse_clf: 1.7192 - acc: 0.6375 - val_loss: 0.9616 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 261/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9624 - keras_rmse_clf: 1.7184 - acc: 0.6375 - val_loss: 0.9614 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 262/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9622 - keras_rmse_clf: 1.7190 - acc: 0.6375 - val_loss: 0.9612 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 263/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9620 - keras_rmse_clf: 1.7197 - acc: 0.6375 - val_loss: 0.9610 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 264/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9618 - keras_rmse_clf: 1.7201 - acc: 0.6375 - val_loss: 0.9608 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 265/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9616 - keras_rmse_clf: 1.7193 - acc: 0.6375 - val_loss: 0.9606 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 266/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9614 - keras_rmse_clf: 1.7192 - acc: 0.6375 - val_loss: 0.9604 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 267/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9612 - keras_rmse_clf: 1.7186 - acc: 0.6375 - val_loss: 0.9602 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 268/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9611 - keras_rmse_clf: 1.7197 - acc: 0.6375 - val_loss: 0.9601 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 269/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9609 - keras_rmse_clf: 1.7197 - acc: 0.6376 - val_loss: 0.9599 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 270/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9607 - keras_rmse_clf: 1.7200 - acc: 0.6375 - val_loss: 0.9597 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 271/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9605 - keras_rmse_clf: 1.7198 - acc: 0.6379 - val_loss: 0.9595 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 272/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9603 - keras_rmse_clf: 1.7200 - acc: 0.6375 - val_loss: 0.9593 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 273/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9602 - keras_rmse_clf: 1.7198 - acc: 0.6375 - val_loss: 0.9591 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 274/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9600 - keras_rmse_clf: 1.7184 - acc: 0.6375 - val_loss: 0.9589 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 275/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9599 - keras_rmse_clf: 1.7201 - acc: 0.6378 - val_loss: 0.9588 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 276/300\n43/43 [==============================] - 0s 5ms/step - loss: 0.9597 - keras_rmse_clf: 1.7193 - acc: 0.6375 - val_loss: 0.9586 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 277/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9595 - keras_rmse_clf: 1.7172 - acc: 0.6375 - val_loss: 0.9585 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 278/300\n43/43 [==============================] - 0s 7ms/step - loss: 0.9594 - keras_rmse_clf: 1.7196 - acc: 0.6375 - val_loss: 0.9583 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 279/300\n43/43 [==============================] - 0s 7ms/step - loss: 0.9592 - keras_rmse_clf: 1.7188 - acc: 0.6375 - val_loss: 0.9582 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 280/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9590 - keras_rmse_clf: 1.7193 - acc: 0.6375 - val_loss: 0.9580 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 281/300\n43/43 [==============================] - 0s 7ms/step - loss: 0.9589 - keras_rmse_clf: 1.7182 - acc: 0.6375 - val_loss: 0.9578 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 282/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9587 - keras_rmse_clf: 1.7212 - acc: 0.6383 - val_loss: 0.9576 - val_keras_rmse_clf: 1.7265 - val_acc: 0.6440\nEpoch 283/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9586 - keras_rmse_clf: 1.7212 - acc: 0.6383 - val_loss: 0.9575 - val_keras_rmse_clf: 1.7265 - val_acc: 0.6440\nEpoch 284/300\n43/43 [==============================] - 0s 7ms/step - loss: 0.9584 - keras_rmse_clf: 1.7190 - acc: 0.6376 - val_loss: 0.9573 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 285/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9582 - keras_rmse_clf: 1.7189 - acc: 0.6375 - val_loss: 0.9571 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 286/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9581 - keras_rmse_clf: 1.7196 - acc: 0.6378 - val_loss: 0.9570 - val_keras_rmse_clf: 1.7265 - val_acc: 0.6440\nEpoch 287/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9579 - keras_rmse_clf: 1.7202 - acc: 0.6380 - val_loss: 0.9568 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 288/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9578 - keras_rmse_clf: 1.7202 - acc: 0.6381 - val_loss: 0.9567 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 289/300\n43/43 [==============================] - 0s 7ms/step - loss: 0.9577 - keras_rmse_clf: 1.7177 - acc: 0.6375 - val_loss: 0.9565 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 290/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9575 - keras_rmse_clf: 1.7185 - acc: 0.6375 - val_loss: 0.9563 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 291/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9574 - keras_rmse_clf: 1.7216 - acc: 0.6386 - val_loss: 0.9562 - val_keras_rmse_clf: 1.7265 - val_acc: 0.6440\nEpoch 292/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9572 - keras_rmse_clf: 1.7212 - acc: 0.6379 - val_loss: 0.9561 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 293/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9571 - keras_rmse_clf: 1.7202 - acc: 0.6378 - val_loss: 0.9559 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 294/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9570 - keras_rmse_clf: 1.7196 - acc: 0.6384 - val_loss: 0.9558 - val_keras_rmse_clf: 1.7265 - val_acc: 0.6440\nEpoch 295/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9568 - keras_rmse_clf: 1.7199 - acc: 0.6378 - val_loss: 0.9556 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 296/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9567 - keras_rmse_clf: 1.7196 - acc: 0.6378 - val_loss: 0.9555 - val_keras_rmse_clf: 1.7265 - val_acc: 0.6440\nEpoch 297/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9565 - keras_rmse_clf: 1.7217 - acc: 0.6388 - val_loss: 0.9553 - val_keras_rmse_clf: 1.7265 - val_acc: 0.6440\nEpoch 298/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9564 - keras_rmse_clf: 1.7208 - acc: 0.6385 - val_loss: 0.9552 - val_keras_rmse_clf: 1.7265 - val_acc: 0.6440\nEpoch 299/300\n43/43 [==============================] - 0s 8ms/step - loss: 0.9563 - keras_rmse_clf: 1.7214 - acc: 0.6386 - val_loss: 0.9551 - val_keras_rmse_clf: 1.7245 - val_acc: 0.6429\nEpoch 300/300\n43/43 [==============================] - 0s 6ms/step - loss: 0.9561 - keras_rmse_clf: 1.7202 - acc: 0.6388 - val_loss: 0.9549 - val_keras_rmse_clf: 1.7265 - val_acc: 0.6440\nEvaluating model....\n107/107 [==============================] - 0s 1ms/step - loss: 0.9777 - keras_rmse_clf: 1.7057 - acc: 0.6254\n[0 0 3 ... 0 0 0]\nComp Metric:  0.9867231165795687\n              precision    recall  f1-score   support\n\n         0.0       0.59      0.92      0.72      1499\n         1.0       0.00      0.00      0.00       648\n         2.0       0.39      0.22      0.28       544\n         3.0       0.84      0.90      0.87       709\n         4.0       0.00      0.00      0.00        12\n\n    accuracy                           0.63      3412\n   macro avg       0.36      0.41      0.37      3412\nweighted avg       0.49      0.63      0.54      3412\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▂▅▅▅▆▆▇▇▇▇█████████████████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>keras_rmse_clf</td><td>█▆▃▁▁▁▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>loss</td><td>█▇▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▅▅▅▆▆▇▇▇▇▇████████████████████████████</td></tr><tr><td>val_keras_rmse_clf</td><td>█▆▂▁▁▁▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPS</td><td>0.0</td></tr><tr><td>acc</td><td>0.63876</td></tr><tr><td>best_epoch</td><td>299</td></tr><tr><td>best_val_loss</td><td>0.95489</td></tr><tr><td>epoch</td><td>299</td></tr><tr><td>keras_rmse_clf</td><td>1.72016</td></tr><tr><td>loss</td><td>0.95613</td></tr><tr><td>val_acc</td><td>0.64396</td></tr><tr><td>val_keras_rmse_clf</td><td>1.7265</td></tr><tr><td>val_loss</td><td>0.95489</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Synced <strong style=\"color:#cdcd00\">d128_clf_mtdata-1673523296</strong>: <a href=\"https://wandb.ai/k_loki/tick-tick-bloom/runs/i5qd6xwg\" target=\"_blank\">https://wandb.ai/k_loki/tick-tick-bloom/runs/i5qd6xwg</a><br/>Synced 6 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20230112_115759-i5qd6xwg/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"pd.Series(np.argmax(model.predict(X_val), axis=1)).value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T12:09:24.486070Z","iopub.execute_input":"2023-01-12T12:09:24.486468Z","iopub.status.idle":"2023-01-12T12:09:24.633419Z","shell.execute_reply.started":"2023-01-12T12:09:24.486437Z","shell.execute_reply":"2023-01-12T12:09:24.632257Z"},"trusted":true},"execution_count":117,"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"0    0.687866\n3    0.221864\n2    0.090270\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"y_val.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T12:08:32.902001Z","iopub.execute_input":"2023-01-12T12:08:32.902454Z","iopub.status.idle":"2023-01-12T12:08:32.913448Z","shell.execute_reply.started":"2023-01-12T12:08:32.902401Z","shell.execute_reply":"2023-01-12T12:08:32.912498Z"},"trusted":true},"execution_count":114,"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"0.0    0.439332\n3.0    0.207796\n1.0    0.189918\n2.0    0.159437\n4.0    0.003517\nName: severity, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"# this is intresting...\n# rmse going up while log loss is going down!\n# When regressing severity the rmse loss is going down but acc is not going up! there is definetly some disconnect between loss func and my metric\n# predicting all zeros (ones) --> 1.65, have to fix the metrics ig","metadata":{"execution":{"iopub.status.busy":"2023-01-12T05:01:41.185909Z","iopub.execute_input":"2023-01-12T05:01:41.186252Z","iopub.status.idle":"2023-01-12T05:01:41.198503Z","shell.execute_reply.started":"2023-01-12T05:01:41.186226Z","shell.execute_reply":"2023-01-12T05:01:41.196527Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# history.history","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:08:49.448932Z","iopub.execute_input":"2023-01-09T17:08:49.449395Z","iopub.status.idle":"2023-01-09T17:08:49.455251Z","shell.execute_reply.started":"2023-01-09T17:08:49.449360Z","shell.execute_reply":"2023-01-09T17:08:49.453951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = models.load_model('/kaggle/working/d128_rmse_lndsat8_raw_v1-1673283452.h5', custom_objects={'comp_loss': comp_loss})\n# preds = model.predict(X_val)\n# int_preds = np.round(preds)\n# mse(y_val, int_preds, squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:20:25.020659Z","iopub.execute_input":"2023-01-09T17:20:25.022716Z","iopub.status.idle":"2023-01-09T17:20:25.305114Z","shell.execute_reply.started":"2023-01-09T17:20:25.022654Z","shell.execute_reply":"2023-01-09T17:20:25.303319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save something..","metadata":{}},{"cell_type":"code","source":"# save model\nif config.SAVE_MODEL:\n    model.save(config.name + '.h5')\n    print(\"Model saved as \",config.name + '.h5')","metadata":{"execution":{"iopub.status.busy":"2023-01-12T12:09:42.230837Z","iopub.execute_input":"2023-01-12T12:09:42.231433Z","iopub.status.idle":"2023-01-12T12:09:42.258128Z","shell.execute_reply.started":"2023-01-12T12:09:42.231388Z","shell.execute_reply":"2023-01-12T12:09:42.256867Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"Model saved as  d128_clf_mtdata-1673523296.h5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Make submission","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-11T05:56:22.448352Z","iopub.execute_input":"2023-01-11T05:56:22.449800Z","iopub.status.idle":"2023-01-11T05:56:22.458223Z","shell.execute_reply.started":"2023-01-11T05:56:22.449712Z","shell.execute_reply":"2023-01-11T05:56:22.456889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-12T12:10:09.990377Z","iopub.execute_input":"2023-01-12T12:10:09.990802Z","iopub.status.idle":"2023-01-12T12:10:09.999564Z","shell.execute_reply.started":"2023-01-12T12:10:09.990768Z","shell.execute_reply":"2023-01-12T12:10:09.997711Z"},"trusted":true},"execution_count":121,"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"(6510, 5)"},"metadata":{}}]},{"cell_type":"code","source":"# test_preds = np.round(model.predict(X_test)).ravel()\ntest_preds = np.argmax(model.predict(X_test), axis=1)\ntest_preds = test_preds + 1\nsub_format.severity = test_preds\nsub_format.severity = sub_format.severity.astype(int) \nsub_format.severity.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T12:10:50.636648Z","iopub.execute_input":"2023-01-12T12:10:50.637139Z","iopub.status.idle":"2023-01-12T12:10:50.855162Z","shell.execute_reply.started":"2023-01-12T12:10:50.637100Z","shell.execute_reply":"2023-01-12T12:10:50.853977Z"},"trusted":true},"execution_count":122,"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"1    2972\n4    2387\n3    1151\nName: severity, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"sub_format.to_csv(f'{config.name}_preds.csv', index=False) # expect @ 0.98","metadata":{"execution":{"iopub.status.busy":"2023-01-12T12:11:03.321782Z","iopub.execute_input":"2023-01-12T12:11:03.322600Z","iopub.status.idle":"2023-01-12T12:11:03.340639Z","shell.execute_reply.started":"2023-01-12T12:11:03.322562Z","shell.execute_reply":"2023-01-12T12:11:03.339383Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"markdown","source":"# So...\n\n- Training even simple NNs is really hard!!\n- NNs with log_loss not at all improving mostly coz of loss -func! --> I thought but\n- NNs with log loss is better compared to rmse-loss??","metadata":{}},{"cell_type":"markdown","source":"# ToDos:\n\n- Does adding data provide any value??\n- **Try to beat expanding avg_severity_by_region with the help of imgs, Other wise no use for img data**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}