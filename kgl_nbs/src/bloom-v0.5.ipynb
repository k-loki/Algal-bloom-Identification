{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Main ...\n\n \n``config, load, preprocess, train, eval  for  Tick tick bloom``\n\n**Yo DON'T rerun this unless you want to overwrite past models, always fork and do your stuff and \nDON'T forget to change the name**","metadata":{}},{"cell_type":"markdown","source":"**``Mission: NNs on expanding avg of severity metadata``**\n\n- wondering how nns perform on metadata!","metadata":{}},{"cell_type":"markdown","source":"# Load imports and dependencies","metadata":{}},{"cell_type":"code","source":"! pip install wandb --upgrade -q","metadata":{"execution":{"iopub.status.busy":"2023-01-12T14:26:50.011181Z","iopub.execute_input":"2023-01-12T14:26:50.011782Z","iopub.status.idle":"2023-01-12T14:27:07.136941Z","shell.execute_reply.started":"2023-01-12T14:26:50.011664Z","shell.execute_reply":"2023-01-12T14:27:07.135296Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.10.1 requires wandb<0.13.0,>=0.10.0, but you have wandb 0.13.8 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nimport sys\nimport os\nimport time\nimport joblib\nimport random\nfrom tqdm import tqdm\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\n\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import OrdinalEncoder\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, activations, losses, metrics, models, optimizers, callbacks\nfrom category_encoders.target_encoder import TargetEncoder\n\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:39.107257Z","iopub.execute_input":"2023-01-12T17:27:39.107983Z","iopub.status.idle":"2023-01-12T17:27:46.877102Z","shell.execute_reply.started":"2023-01-12T17:27:39.107820Z","shell.execute_reply":"2023-01-12T17:27:46.876106Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# local utilities imports\nfrom tick_tick_bloom_utils import comp_metric, den2sev_map","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:46.878960Z","iopub.execute_input":"2023-01-12T17:27:46.879717Z","iopub.status.idle":"2023-01-12T17:27:46.906124Z","shell.execute_reply.started":"2023-01-12T17:27:46.879677Z","shell.execute_reply":"2023-01-12T17:27:46.905304Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# wandb stuff for tracking\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_login = user_secrets.get_secret(\"wandb_bloom_tracker\")\n\nimport wandb\nwandb.login(key=wandb_login)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:46.907713Z","iopub.execute_input":"2023-01-12T17:27:46.908083Z","iopub.status.idle":"2023-01-12T17:27:48.543021Z","shell.execute_reply.started":"2023-01-12T17:27:46.908049Z","shell.execute_reply":"2023-01-12T17:27:48.542013Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"# dot dictionary\nclass dotdict(dict):\n    \"\"\"dot.notation access to dictionary attributes\"\"\"\n    __getattr__ = dict.get\n    __setattr__ = dict.__setitem__\n    __delattr__ = dict.__delitem__\n\n\n# Config\nconfig = {}\nconfig = dotdict(config)\nconfig['RANDOM_SEED'] = 18952\n\n\nconfig['unique_id'] = int(time.time())\nprint(f'unique_id: {config.unique_id}')\nconfig['name'] = f'd256_512_256_128_clf_mtdata-{config.unique_id}'\n\nconfig['PROJECT_NAME'] = 'tick-tick-bloom'\n# config['DATA_DIR'] = '../data/'\n# config['MODEL_DIR'] = '../models/'\nconfig['SAVE_MODEL'] = True\n\n\n# # Img config\n# config['IMG_SIZE'] = (136, 136)\n# config['CHANNELS'] = 3\n\n# training configuration\nconfig['train'] =  dotdict({\n                        'epochs': 1000,\n                        'batch_size': 256,\n                        'validation_split': 0.2,\n                        'shuffle': True,\n                        'verbose': 1,\n                        'lr' : 1e-5\n                        })\n\nconfig['desc'] = \"\"\"\nxp3-to see how nns perform only on metadata(use data upto the point of availibility.)\nrmse vs log-loss which is better?? or both could be worst than gbs!\n\"\"\" ","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:48.545495Z","iopub.execute_input":"2023-01-12T17:27:48.546151Z","iopub.status.idle":"2023-01-12T17:27:48.555896Z","shell.execute_reply.started":"2023-01-12T17:27:48.546110Z","shell.execute_reply":"2023-01-12T17:27:48.553717Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"unique_id: 1673544468\n","output_type":"stream"}]},{"cell_type":"code","source":"# seed everything\ndef seed_everything(seed=config.RANDOM_SEED):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n#     os.environ['TF_CUDNN_DETERMINISTIC'] = '1' \n#     os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\n# tf.keras.utils.set_random_seed(config.RANDOM_SEED)  # supposedly sets seed for python, numpy, tf\n\nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:48.557645Z","iopub.execute_input":"2023-01-12T17:27:48.558052Z","iopub.status.idle":"2023-01-12T17:27:48.571950Z","shell.execute_reply.started":"2023-01-12T17:27:48.557956Z","shell.execute_reply":"2023-01-12T17:27:48.570952Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def keras_rmse_clf(y_true, y_pred):\n    \"\"\"\n    valid competetion metric for clf type settings.\n    Can be trusted!\n    y_true and y_pred should be [0-4]\n    \"\"\"\n    y_pred = tf.argmax(y_pred, axis=1)\n    y_pred = tf.cast(y_pred, tf.float16)\n    y_true = tf.cast(y_true, tf.float16)\n    squared_difference = tf.square(y_true - y_pred)\n    return tf.sqrt(tf.reduce_mean(squared_difference, axis=-1))\n\ndef keras_rmse_reg(y_true, y_pred):\n    \"\"\"\n    valid competetion metric for reg type settings.\n    Can be trusted!\n    y_true and y_pred should be [0-4]\n    \"\"\"\n    y_pred = tf.math.round(y_pred)\n    y_pred = tf.cast(y_pred, tf.float16)\n    y_true = tf.cast(y_true, tf.float16)\n    squared_difference = tf.square(y_true - y_pred)\n    return tf.sqrt(tf.reduce_mean(squared_difference, axis=-1))\n\n\ndef rmse_loss(y_true, y_pred):\n    \"\"\"loss func to use in reg type settings\"\"\"\n    return tf.sqrt(losses.mean_squared_error(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:50.344350Z","iopub.execute_input":"2023-01-12T17:27:50.345373Z","iopub.status.idle":"2023-01-12T17:27:50.353686Z","shell.execute_reply.started":"2023-01-12T17:27:50.345328Z","shell.execute_reply":"2023-01-12T17:27:50.352587Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"INPUT_METADATA_DIR = '/kaggle/input/ticktickbloomdataset'\n\nmetadata = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'metadata.csv'))\nsub_format = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'submission_format.csv'))\ntrain_labels = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'train_labels.csv'))","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:50.914399Z","iopub.execute_input":"2023-01-12T17:27:50.915431Z","iopub.status.idle":"2023-01-12T17:27:51.015073Z","shell.execute_reply.started":"2023-01-12T17:27:50.915384Z","shell.execute_reply":"2023-01-12T17:27:51.014115Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# IMG_DIR = '/kaggle/input/pull-landsat-data-v1-500m/landsat8_500m_v1'   # landsat 8 data with raw \n# img_files = os.listdir(IMG_DIR)\n# img_file_names = [f.split('.')[0] for f in img_files]\n\n# # get only data for those 1k imgs\n# metadata_subset = metadata[metadata['uid'].isin(img_file_names)]\n# data = metadata_subset[metadata_subset.split == 'train']\n# data = data.merge(train_labels, on='uid')\n\n# test_data = metadata[metadata.split == 'train']","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:51.124316Z","iopub.execute_input":"2023-01-12T17:27:51.125095Z","iopub.status.idle":"2023-01-12T17:27:51.131811Z","shell.execute_reply.started":"2023-01-12T17:27:51.125054Z","shell.execute_reply":"2023-01-12T17:27:51.130732Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# def get_imgs(uids) :\n#     imgs = []\n#     for uid in uids:\n#         img_arr = np.load(IMG_DIR + f'/{uid}.npy')\n#         img_arr = np.transpose(img_arr, (2, 1, 0))\n#         # resize img\n#         img_arr = cv2.resize(img_arr, config.IMG_SIZE)\n#         img_arr = img_arr / 255   # normalizeee bro... other wise it's blowing up the networks...\n#         imgs.append(img_arr)\n#     return np.array(imgs) \n\n\n# def get_np_data(split : float = 0.2, task='train'):\n#     \"\"\"Return np data for training and validation.\"\"\"\n#     if task == 'train':\n#         print(\"Loading train and validation data...\")\n#         x_train_uids, x_val_uids, y_train, y_val = train_val_split(\n#             data['uid'],\n#             data.severity,\n#             val_size=split,\n#             random_state=config.RANDOM_SEED,\n#             stratify=data.severity\n#         )\n\n#         x_train = get_imgs(x_train_uids)\n#         x_val = get_imgs(x_val_uids)\n\n#         return x_train, y_train, x_val, y_val\n\n\n#     if task == 'test':\n#         test_ids = test_data.uids\n#         x_test\n#         return x_test","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:51.299523Z","iopub.execute_input":"2023-01-12T17:27:51.300300Z","iopub.status.idle":"2023-01-12T17:27:51.307244Z","shell.execute_reply.started":"2023-01-12T17:27:51.300250Z","shell.execute_reply":"2023-01-12T17:27:51.305382Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# x_train, y_train, x_val, y_val = get_np_data()\n# print(y_train.value_counts(normalize=True))\n# print(y_val.value_counts(normalize=True))\n# print('Done')","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:51.475517Z","iopub.execute_input":"2023-01-12T17:27:51.475874Z","iopub.status.idle":"2023-01-12T17:27:51.480199Z","shell.execute_reply.started":"2023-01-12T17:27:51.475843Z","shell.execute_reply":"2023-01-12T17:27:51.479035Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#  get data\nmetadata.date = pd.to_datetime(metadata.date)\n\nregion = pd.concat((train_labels, sub_format[['region', 'uid']]), axis=0)\n\ndata = pd.merge(metadata, region, on='uid', how='left')\nprint(data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:51.653998Z","iopub.execute_input":"2023-01-12T17:27:51.654700Z","iopub.status.idle":"2023-01-12T17:27:51.705856Z","shell.execute_reply.started":"2023-01-12T17:27:51.654672Z","shell.execute_reply":"2023-01-12T17:27:51.704715Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"(23570, 8)\n","output_type":"stream"}]},{"cell_type":"code","source":"# seasons\nseasons = {\n    1: 1,\n    2: 1,\n    3: 2,\n    4: 2,\n    5: 2,\n    6: 3,\n    7: 3,\n    8: 3,\n    9: 4,\n    10: 4,\n    11: 4,\n    12: 1\n}\n\n\n#  most of the samples are collected in the months of June, July, August.\n\n# add date time fts.\ndata['month'] = data.date.dt.month\ndata['year'] = data.date.dt.year\ndata['week'] = data.date.dt.isocalendar().week\n# data['day_of_year'] = data.date.dt.\ndata['season'] = data.month.map(seasons)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:51.799608Z","iopub.execute_input":"2023-01-12T17:27:51.802187Z","iopub.status.idle":"2023-01-12T17:27:51.828355Z","shell.execute_reply.started":"2023-01-12T17:27:51.802151Z","shell.execute_reply":"2023-01-12T17:27:51.827369Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data.sort_values(by='date', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:51.994587Z","iopub.execute_input":"2023-01-12T17:27:51.994972Z","iopub.status.idle":"2023-01-12T17:27:52.010596Z","shell.execute_reply.started":"2023-01-12T17:27:51.994939Z","shell.execute_reply":"2023-01-12T17:27:52.009579Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"data['expanding_severity'] = data.severity.expanding().mean()\ndata['expanding_severity'] = data['expanding_severity'].apply(np.round)\ndata","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:52.194076Z","iopub.execute_input":"2023-01-12T17:27:52.194411Z","iopub.status.idle":"2023-01-12T17:27:52.343629Z","shell.execute_reply.started":"2023-01-12T17:27:52.194382Z","shell.execute_reply":"2023-01-12T17:27:52.342589Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"        uid   latitude   longitude       date  split   region  severity  \\\n4387   evep  44.847993  -93.476318 2013-01-04  train  midwest       1.0   \n13644  paev  44.822478  -93.367962 2013-01-04  train  midwest       1.0   \n5566   gdxr  44.877646  -93.557842 2013-01-04  train  midwest       1.0   \n6144   guny  44.878889  -93.490833 2013-01-04  train  midwest       1.0   \n5317   fwbt  44.850500  -93.515700 2013-01-04  train  midwest       1.0   \n...     ...        ...         ...        ...    ...      ...       ...   \n12443  nsoi  36.736800 -121.734000 2021-12-29   test     west       NaN   \n17559  thki  36.725400 -121.730000 2021-12-29   test     west       NaN   \n17452  teuu  36.772300 -121.788000 2021-12-29   test     west       NaN   \n14254  prfi  36.751800 -121.742000 2021-12-29   test     west       NaN   \n6864   howu  36.708500 -121.749000 2021-12-29   test     west       NaN   \n\n       density  month  year  week  season  expanding_severity  \n4387     115.0      1  2013     1       1                 1.0  \n13644   1884.0      1  2013     1       1                 1.0  \n5566    1416.0      1  2013     1       1                 1.0  \n6144     558.0      1  2013     1       1                 1.0  \n5317     476.0      1  2013     1       1                 1.0  \n...        ...    ...   ...   ...     ...                 ...  \n12443      NaN     12  2021    52       1                 2.0  \n17559      NaN     12  2021    52       1                 2.0  \n17452      NaN     12  2021    52       1                 2.0  \n14254      NaN     12  2021    52       1                 2.0  \n6864       NaN     12  2021    52       1                 2.0  \n\n[23570 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n      <th>expanding_severity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4387</th>\n      <td>evep</td>\n      <td>44.847993</td>\n      <td>-93.476318</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>115.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>13644</th>\n      <td>paev</td>\n      <td>44.822478</td>\n      <td>-93.367962</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1884.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5566</th>\n      <td>gdxr</td>\n      <td>44.877646</td>\n      <td>-93.557842</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1416.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6144</th>\n      <td>guny</td>\n      <td>44.878889</td>\n      <td>-93.490833</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>558.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5317</th>\n      <td>fwbt</td>\n      <td>44.850500</td>\n      <td>-93.515700</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>476.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12443</th>\n      <td>nsoi</td>\n      <td>36.736800</td>\n      <td>-121.734000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17559</th>\n      <td>thki</td>\n      <td>36.725400</td>\n      <td>-121.730000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>17452</th>\n      <td>teuu</td>\n      <td>36.772300</td>\n      <td>-121.788000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>14254</th>\n      <td>prfi</td>\n      <td>36.751800</td>\n      <td>-121.742000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>6864</th>\n      <td>howu</td>\n      <td>36.708500</td>\n      <td>-121.749000</td>\n      <td>2021-12-29</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2021</td>\n      <td>52</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>23570 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data = data[data.split == 'train']\ntest_data = data[data.split == 'test']","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:52.889501Z","iopub.execute_input":"2023-01-12T17:27:52.889908Z","iopub.status.idle":"2023-01-12T17:27:52.907400Z","shell.execute_reply.started":"2023-01-12T17:27:52.889874Z","shell.execute_reply":"2023-01-12T17:27:52.906491Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# expanding avg of severity\nmse(train_data.severity, train_data.expanding_severity, squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:53.169829Z","iopub.execute_input":"2023-01-12T17:27:53.170256Z","iopub.status.idle":"2023-01-12T17:27:53.180593Z","shell.execute_reply.started":"2023-01-12T17:27:53.170220Z","shell.execute_reply":"2023-01-12T17:27:53.179346Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"1.2085810811762927"},"metadata":{}}]},{"cell_type":"code","source":"grp_by_region = data.groupby('region').severity.expanding(1).mean()\ngrp_by_region = grp_by_region.map(np.round)\n\ngrp_by_region['west'].fillna(2, inplace=True)\ngrp_by_region['northeast'].fillna(2, inplace=True)\nprint(grp_by_region.isna().sum())   # 5 --> 0.89416\n\nprint(mse(train_data.severity.sort_index(), grp_by_region.droplevel(0).loc[train_data.index].sort_index(), squared=False))\n\ndata['expndng_sev_by_reg'] = np.nan\n\nsouth = data.region == 'south'\nmidwest = data.region == 'midwest'\nnortheast = data.region == 'northeast'\nwest = data.region == 'west'\n\ndata.loc[south , 'expndng_sev_by_reg'] = grp_by_region['south']\ndata.loc[midwest , 'expndng_sev_by_reg'] = grp_by_region['midwest']\ndata.loc[northeast , 'expndng_sev_by_reg'] = grp_by_region['northeast']\ndata.loc[west , 'expndng_sev_by_reg'] = grp_by_region['west']\n\nprint(data.shape)\ndata.isna().sum()\n\ndata.sort_index()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:53.384229Z","iopub.execute_input":"2023-01-12T17:27:53.385080Z","iopub.status.idle":"2023-01-12T17:27:53.635090Z","shell.execute_reply.started":"2023-01-12T17:27:53.385041Z","shell.execute_reply":"2023-01-12T17:27:53.634039Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"0\n0.894165010958815\n(23570, 14)\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"        uid   latitude   longitude       date  split   region  severity  \\\n0      aabm  39.080319  -86.430867 2018-05-14  train  midwest       1.0   \n1      aabn  36.559700 -121.510000 2016-08-31   test     west       NaN   \n2      aacd  35.875083  -78.878434 2020-11-19  train    south       1.0   \n3      aaee  35.487000  -79.062133 2016-08-24  train    south       1.0   \n4      aaff  38.049471  -99.827001 2019-07-23  train  midwest       3.0   \n...     ...        ...         ...        ...    ...      ...       ...   \n23565  zzvv  36.708500 -121.749000 2014-12-02   test     west       NaN   \n23566  zzwo  39.792190  -99.971050 2017-06-19  train  midwest       2.0   \n23567  zzwq  35.794000  -79.012551 2015-03-24  train    south       1.0   \n23568  zzyb  35.742000  -79.238600 2016-11-21  train    south       1.0   \n23569  zzzi  39.767323  -96.028617 2015-08-31   test  midwest       NaN   \n\n        density  month  year  week  season  expanding_severity  \\\n0         585.0      5  2018    20       2                 2.0   \n1           NaN      8  2016    35       3                 2.0   \n2         290.0     11  2020    47       4                 2.0   \n3        1614.0      8  2016    34       3                 2.0   \n4      111825.0      7  2019    30       3                 2.0   \n...         ...    ...   ...   ...     ...                 ...   \n23565       NaN     12  2014    49       1                 2.0   \n23566   48510.0      6  2017    25       3                 2.0   \n23567    1271.0      3  2015    13       2                 2.0   \n23568    9682.0     11  2016    47       4                 2.0   \n23569       NaN      8  2015    36       3                 2.0   \n\n       expndng_sev_by_reg  \n0                     2.0  \n1                     4.0  \n2                     2.0  \n3                     2.0  \n4                     2.0  \n...                   ...  \n23565                 4.0  \n23566                 2.0  \n23567                 1.0  \n23568                 2.0  \n23569                 2.0  \n\n[23570 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n      <th>expanding_severity</th>\n      <th>expndng_sev_by_reg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aabm</td>\n      <td>39.080319</td>\n      <td>-86.430867</td>\n      <td>2018-05-14</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>585.0</td>\n      <td>5</td>\n      <td>2018</td>\n      <td>20</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aabn</td>\n      <td>36.559700</td>\n      <td>-121.510000</td>\n      <td>2016-08-31</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>2016</td>\n      <td>35</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aacd</td>\n      <td>35.875083</td>\n      <td>-78.878434</td>\n      <td>2020-11-19</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>290.0</td>\n      <td>11</td>\n      <td>2020</td>\n      <td>47</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aaee</td>\n      <td>35.487000</td>\n      <td>-79.062133</td>\n      <td>2016-08-24</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>1614.0</td>\n      <td>8</td>\n      <td>2016</td>\n      <td>34</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aaff</td>\n      <td>38.049471</td>\n      <td>-99.827001</td>\n      <td>2019-07-23</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>3.0</td>\n      <td>111825.0</td>\n      <td>7</td>\n      <td>2019</td>\n      <td>30</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23565</th>\n      <td>zzvv</td>\n      <td>36.708500</td>\n      <td>-121.749000</td>\n      <td>2014-12-02</td>\n      <td>test</td>\n      <td>west</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>2014</td>\n      <td>49</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>23566</th>\n      <td>zzwo</td>\n      <td>39.792190</td>\n      <td>-99.971050</td>\n      <td>2017-06-19</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>2.0</td>\n      <td>48510.0</td>\n      <td>6</td>\n      <td>2017</td>\n      <td>25</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>23567</th>\n      <td>zzwq</td>\n      <td>35.794000</td>\n      <td>-79.012551</td>\n      <td>2015-03-24</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>1271.0</td>\n      <td>3</td>\n      <td>2015</td>\n      <td>13</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>23568</th>\n      <td>zzyb</td>\n      <td>35.742000</td>\n      <td>-79.238600</td>\n      <td>2016-11-21</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>9682.0</td>\n      <td>11</td>\n      <td>2016</td>\n      <td>47</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>23569</th>\n      <td>zzzi</td>\n      <td>39.767323</td>\n      <td>-96.028617</td>\n      <td>2015-08-31</td>\n      <td>test</td>\n      <td>midwest</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>2015</td>\n      <td>36</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>23570 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# # MY ASSUMPTION: less the missing values --> more inital samples in the group are not test --> less imputations/ffills needed --> much realiable score!\n","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:53.637538Z","iopub.execute_input":"2023-01-12T17:27:53.640565Z","iopub.status.idle":"2023-01-12T17:27:53.645204Z","shell.execute_reply.started":"2023-01-12T17:27:53.640517Z","shell.execute_reply":"2023-01-12T17:27:53.644012Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"grp_by_rs = data.groupby(['region', 'season']).severity.expanding(1).mean()\ngrp_by_rs = grp_by_rs.map(np.round)\nprint(grp_by_rs.isna().sum()) # 5 --> .86\n\ndata['expanding_sev_rs'] =  grp_by_rs.droplevel(0).droplevel(0).sort_index()\n# fillna with expanding sev by region\ndata['expanding_sev_rs'] = np.where(data.expanding_sev_rs.isna(), data.expndng_sev_by_reg, data.expanding_sev_rs)\n\nprint(mse(train_data.severity.sort_index(), data['expanding_sev_rs'].sort_index()[data.split == 'train'], squared=False))\n\n# #  make submission for expanding severity by region and season\n\n# expanding_sev_rs = data[data.split == 'test'][['uid', 'expanding_sev_rs']]          # picking up only uids and expanding_sev_rs from test samples\n# expanding_sev_rs.expanding_sev_rs = expanding_sev_rs.expanding_sev_rs.astype(int)   # casting to int\n# expanding_sev_rs.sort_values(by='uid', inplace=True)                                # sorting by uid -- safest option\n# expanding_sev_rs.reset_index(drop=True, inplace=True)                               # matching indexes with submissoin\n\n# sub_format.severity = expanding_sev_rs.expanding_sev_rs\n# sub_format.severity.value_counts()  # expected 0.8594349134502333\n\n# sub_format.to_csv('expanding_sev_rs_preds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:54.200008Z","iopub.execute_input":"2023-01-12T17:27:54.200586Z","iopub.status.idle":"2023-01-12T17:27:54.869349Z","shell.execute_reply.started":"2023-01-12T17:27:54.200543Z","shell.execute_reply":"2023-01-12T17:27:54.868356Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"5\n0.8594349134502333\n","output_type":"stream"}]},{"cell_type":"code","source":"train_labels.severity.value_counts(normalize=True)\n# since test and train dists are almost similar my ideal model should follow this dist!","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:54.871388Z","iopub.execute_input":"2023-01-12T17:27:54.872442Z","iopub.status.idle":"2023-01-12T17:27:54.890102Z","shell.execute_reply.started":"2023-01-12T17:27:54.872405Z","shell.execute_reply":"2023-01-12T17:27:54.889134Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"1    0.439449\n4    0.207913\n2    0.189859\n3    0.159379\n5    0.003400\nName: severity, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:54.893760Z","iopub.execute_input":"2023-01-12T17:27:54.896635Z","iopub.status.idle":"2023-01-12T17:27:54.971917Z","shell.execute_reply.started":"2023-01-12T17:27:54.896598Z","shell.execute_reply":"2023-01-12T17:27:54.971031Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"        uid   latitude  longitude       date  split   region  severity  \\\n4387   evep  44.847993 -93.476318 2013-01-04  train  midwest       1.0   \n13644  paev  44.822478 -93.367962 2013-01-04  train  midwest       1.0   \n5566   gdxr  44.877646 -93.557842 2013-01-04  train  midwest       1.0   \n6144   guny  44.878889 -93.490833 2013-01-04  train  midwest       1.0   \n5317   fwbt  44.850500 -93.515700 2013-01-04  train  midwest       1.0   \n\n       density  month  year  week  season  expanding_severity  \\\n4387     115.0      1  2013     1       1                 1.0   \n13644   1884.0      1  2013     1       1                 1.0   \n5566    1416.0      1  2013     1       1                 1.0   \n6144     558.0      1  2013     1       1                 1.0   \n5317     476.0      1  2013     1       1                 1.0   \n\n       expndng_sev_by_reg  expanding_sev_rs  \n4387                  1.0               1.0  \n13644                 1.0               1.0  \n5566                  1.0               1.0  \n6144                  1.0               1.0  \n5317                  1.0               1.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n      <th>expanding_severity</th>\n      <th>expndng_sev_by_reg</th>\n      <th>expanding_sev_rs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4387</th>\n      <td>evep</td>\n      <td>44.847993</td>\n      <td>-93.476318</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>115.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>13644</th>\n      <td>paev</td>\n      <td>44.822478</td>\n      <td>-93.367962</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1884.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5566</th>\n      <td>gdxr</td>\n      <td>44.877646</td>\n      <td>-93.557842</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>1416.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6144</th>\n      <td>guny</td>\n      <td>44.878889</td>\n      <td>-93.490833</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>558.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5317</th>\n      <td>fwbt</td>\n      <td>44.850500</td>\n      <td>-93.515700</td>\n      <td>2013-01-04</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>476.0</td>\n      <td>1</td>\n      <td>2013</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:54.976960Z","iopub.execute_input":"2023-01-12T17:27:54.981959Z","iopub.status.idle":"2023-01-12T17:27:55.030819Z","shell.execute_reply.started":"2023-01-12T17:27:54.981919Z","shell.execute_reply":"2023-01-12T17:27:55.029343Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"uid                      0\nlatitude                 0\nlongitude                0\ndate                     0\nsplit                    0\nregion                   0\nseverity              6510\ndensity               6510\nmonth                    0\nyear                     0\nweek                     0\nseason                   0\nexpanding_severity       0\nexpndng_sev_by_reg       0\nexpanding_sev_rs         0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"all_train = data[data.split == 'train']\nall_train.sort_values(by='uid', inplace=True)\nall_train.reset_index(drop=True, inplace=True)\nall_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:55.032313Z","iopub.execute_input":"2023-01-12T17:27:55.032662Z","iopub.status.idle":"2023-01-12T17:27:55.110421Z","shell.execute_reply.started":"2023-01-12T17:27:55.032626Z","shell.execute_reply":"2023-01-12T17:27:55.108876Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(17060, 15)"},"metadata":{}}]},{"cell_type":"code","source":"all_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:55.439745Z","iopub.execute_input":"2023-01-12T17:27:55.440273Z","iopub.status.idle":"2023-01-12T17:27:55.475209Z","shell.execute_reply.started":"2023-01-12T17:27:55.440227Z","shell.execute_reply":"2023-01-12T17:27:55.474263Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"    uid   latitude  longitude       date  split   region  severity    density  \\\n0  aabm  39.080319 -86.430867 2018-05-14  train  midwest       1.0      585.0   \n1  aacd  35.875083 -78.878434 2020-11-19  train    south       1.0      290.0   \n2  aaee  35.487000 -79.062133 2016-08-24  train    south       1.0     1614.0   \n3  aaff  38.049471 -99.827001 2019-07-23  train  midwest       3.0   111825.0   \n4  aafl  39.474744 -86.898353 2021-08-23  train  midwest       4.0  2017313.0   \n\n   month  year  week  season  expanding_severity  expndng_sev_by_reg  \\\n0      5  2018    20       2                 2.0                 2.0   \n1     11  2020    47       4                 2.0                 2.0   \n2      8  2016    34       3                 2.0                 2.0   \n3      7  2019    30       3                 2.0                 2.0   \n4      8  2021    34       3                 2.0                 2.0   \n\n   expanding_sev_rs  \n0               1.0  \n1               2.0  \n2               2.0  \n3               2.0  \n4               2.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>date</th>\n      <th>split</th>\n      <th>region</th>\n      <th>severity</th>\n      <th>density</th>\n      <th>month</th>\n      <th>year</th>\n      <th>week</th>\n      <th>season</th>\n      <th>expanding_severity</th>\n      <th>expndng_sev_by_reg</th>\n      <th>expanding_sev_rs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aabm</td>\n      <td>39.080319</td>\n      <td>-86.430867</td>\n      <td>2018-05-14</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>1.0</td>\n      <td>585.0</td>\n      <td>5</td>\n      <td>2018</td>\n      <td>20</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aacd</td>\n      <td>35.875083</td>\n      <td>-78.878434</td>\n      <td>2020-11-19</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>290.0</td>\n      <td>11</td>\n      <td>2020</td>\n      <td>47</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aaee</td>\n      <td>35.487000</td>\n      <td>-79.062133</td>\n      <td>2016-08-24</td>\n      <td>train</td>\n      <td>south</td>\n      <td>1.0</td>\n      <td>1614.0</td>\n      <td>8</td>\n      <td>2016</td>\n      <td>34</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aaff</td>\n      <td>38.049471</td>\n      <td>-99.827001</td>\n      <td>2019-07-23</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>3.0</td>\n      <td>111825.0</td>\n      <td>7</td>\n      <td>2019</td>\n      <td>30</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aafl</td>\n      <td>39.474744</td>\n      <td>-86.898353</td>\n      <td>2021-08-23</td>\n      <td>train</td>\n      <td>midwest</td>\n      <td>4.0</td>\n      <td>2017313.0</td>\n      <td>8</td>\n      <td>2021</td>\n      <td>34</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_data = metadata[metadata.split == 'test']\ntest_data = test_data.merge(sub_format, on='uid')\n\ntest_data['month'] = test_data.date.dt.month\ntest_data['year'] = test_data.date.dt.year\ntest_data['season'] = test_data.month.map(seasons)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:55.529215Z","iopub.execute_input":"2023-01-12T17:27:55.531900Z","iopub.status.idle":"2023-01-12T17:27:55.561012Z","shell.execute_reply.started":"2023-01-12T17:27:55.531863Z","shell.execute_reply":"2023-01-12T17:27:55.559868Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"all_train.columns","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:55.699497Z","iopub.execute_input":"2023-01-12T17:27:55.699885Z","iopub.status.idle":"2023-01-12T17:27:55.708115Z","shell.execute_reply.started":"2023-01-12T17:27:55.699848Z","shell.execute_reply":"2023-01-12T17:27:55.706922Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Index(['uid', 'latitude', 'longitude', 'date', 'split', 'region', 'severity',\n       'density', 'month', 'year', 'week', 'season', 'expanding_severity',\n       'expndng_sev_by_reg', 'expanding_sev_rs'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"req_cols = ['region', 'month', 'year', 'season', 'expanding_sev_rs']","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:57.255158Z","iopub.execute_input":"2023-01-12T17:27:57.255628Z","iopub.status.idle":"2023-01-12T17:27:57.261385Z","shell.execute_reply.started":"2023-01-12T17:27:57.255589Z","shell.execute_reply":"2023-01-12T17:27:57.260156Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"X_ , y_ = all_train[req_cols], all_train['severity']\nX_.shape, y_.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:57.579911Z","iopub.execute_input":"2023-01-12T17:27:57.580458Z","iopub.status.idle":"2023-01-12T17:27:57.591778Z","shell.execute_reply.started":"2023-01-12T17:27:57.580412Z","shell.execute_reply":"2023-01-12T17:27:57.590472Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"((17060, 5), (17060,))"},"metadata":{}}]},{"cell_type":"code","source":"X_.isna().sum().sum(), y_.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:59.299210Z","iopub.execute_input":"2023-01-12T17:27:59.299583Z","iopub.status.idle":"2023-01-12T17:27:59.311950Z","shell.execute_reply.started":"2023-01-12T17:27:59.299554Z","shell.execute_reply":"2023-01-12T17:27:59.310646Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(0, 0)"},"metadata":{}}]},{"cell_type":"code","source":"X_train_,X_val_, y_train_, y_val_ = train_test_split(X_, y_, test_size=0.20, random_state=config.RANDOM_SEED, stratify=y_)\nX_train_.shape, y_train_.shape, X_val_.shape, y_val_.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:27:59.744591Z","iopub.execute_input":"2023-01-12T17:27:59.744986Z","iopub.status.idle":"2023-01-12T17:27:59.765915Z","shell.execute_reply.started":"2023-01-12T17:27:59.744935Z","shell.execute_reply":"2023-01-12T17:27:59.764992Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"((13648, 5), (13648,), (3412, 5), (3412,))"},"metadata":{}}]},{"cell_type":"code","source":"test_data['expanding_severity'] = data[data.split == 'test']['expanding_severity'].sort_index().values\ntest_data['expndng_sev_by_reg'] = data[data.split == 'test']['expndng_sev_by_reg'].sort_index().values\ntest_data['expanding_sev_rs'] = data[data.split == 'test']['expanding_sev_rs'].sort_index().values","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:28:00.354704Z","iopub.execute_input":"2023-01-12T17:28:00.355487Z","iopub.status.idle":"2023-01-12T17:28:00.376594Z","shell.execute_reply.started":"2023-01-12T17:28:00.355441Z","shell.execute_reply":"2023-01-12T17:28:00.375755Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"X_test_ = test_data[req_cols]\nX_test_.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:28:00.569611Z","iopub.execute_input":"2023-01-12T17:28:00.569999Z","iopub.status.idle":"2023-01-12T17:28:00.580092Z","shell.execute_reply.started":"2023-01-12T17:28:00.569948Z","shell.execute_reply":"2023-01-12T17:28:00.578927Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(6510, 5)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocess","metadata":{}},{"cell_type":"code","source":"# # change labels to 0-3(model works this way) instead of 1-4 given range(given severity)\n# -1 for to make labels look like sparse encoded labels\n\ny_train = y_train_  -1\ny_val = y_val_ - 1\n\ny_train.value_counts(normalize=True), y_val.value_counts(normalize=True)  # guessing alwyas 0 gives 43% acc","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:28:47.195770Z","iopub.execute_input":"2023-01-12T17:28:47.196234Z","iopub.status.idle":"2023-01-12T17:28:47.213678Z","shell.execute_reply.started":"2023-01-12T17:28:47.196193Z","shell.execute_reply":"2023-01-12T17:28:47.212723Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(0.0    0.439478\n 3.0    0.207943\n 1.0    0.189845\n 2.0    0.159364\n 4.0    0.003370\n Name: severity, dtype: float64,\n 0.0    0.439332\n 3.0    0.207796\n 1.0    0.189918\n 2.0    0.159437\n 4.0    0.003517\n Name: severity, dtype: float64)"},"metadata":{}}]},{"cell_type":"code","source":"y = y_ - 1\ny.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:28:47.400037Z","iopub.execute_input":"2023-01-12T17:28:47.400494Z","iopub.status.idle":"2023-01-12T17:28:47.413028Z","shell.execute_reply.started":"2023-01-12T17:28:47.400450Z","shell.execute_reply":"2023-01-12T17:28:47.412021Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"0.0    7497\n3.0    3547\n1.0    3239\n2.0    2719\n4.0      58\nName: severity, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# #  target encode the cat fts.\n\n# te = TargetEncoder(cols=['region', 'month', 'year', 'season'])\n# te.fit(X_train_, y_train)\n# X_train =  te.transform(X_train_)\n# X_val = te.transform(X_val_)\n\n# X_test = te.transform(X_test_)\n# X_test","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:28:47.519567Z","iopub.execute_input":"2023-01-12T17:28:47.519952Z","iopub.status.idle":"2023-01-12T17:28:47.524703Z","shell.execute_reply.started":"2023-01-12T17:28:47.519920Z","shell.execute_reply":"2023-01-12T17:28:47.523570Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"X_train_.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:28:47.689804Z","iopub.execute_input":"2023-01-12T17:28:47.690838Z","iopub.status.idle":"2023-01-12T17:28:47.698945Z","shell.execute_reply.started":"2023-01-12T17:28:47.690804Z","shell.execute_reply":"2023-01-12T17:28:47.697861Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"region               object\nmonth                 int64\nyear                  int64\nseason                int64\nexpanding_sev_rs    float64\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"#  Encode region\n# from category_encoders.ordinal import OrdinalEncoder as COE\n\noe = OrdinalEncoder()\nX_train = oe.fit_transform(X_train_)\nX_test = oe.transform(X_test_)\nX_val = oe.transform(X_val_)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:28:47.834347Z","iopub.execute_input":"2023-01-12T17:28:47.834714Z","iopub.status.idle":"2023-01-12T17:28:47.859829Z","shell.execute_reply.started":"2023-01-12T17:28:47.834682Z","shell.execute_reply":"2023-01-12T17:28:47.858943Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"X_train = pd.DataFrame(X_train, columns=X_train_.columns, index=X_train_.index)\nX_test = pd.DataFrame(X_test, columns=X_test_.columns, index=X_test_.index)\nX_val = pd.DataFrame(X_val, columns=X_val_.columns, index=X_val_.index)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:28:49.274748Z","iopub.execute_input":"2023-01-12T17:28:49.275156Z","iopub.status.idle":"2023-01-12T17:28:49.281419Z","shell.execute_reply.started":"2023-01-12T17:28:49.275120Z","shell.execute_reply":"2023-01-12T17:28:49.280271Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Normalize values\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:28:49.474560Z","iopub.execute_input":"2023-01-12T17:28:49.474947Z","iopub.status.idle":"2023-01-12T17:28:49.479340Z","shell.execute_reply.started":"2023-01-12T17:28:49.474913Z","shell.execute_reply":"2023-01-12T17:28:49.478289Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def get_model(mdtype='reg'):\n    print(f'Loading {mdtype} type model...')\n    #     input_shape = (*config.IMG_SIZE, config.CHANNELS)\n\n    if mdtype == 'clf':\n        loss = losses.SparseCategoricalCrossentropy()\n        comp_metric = keras_rmse_clf\n        last_layer = layers.Dense(5, activation='softmax')\n\n    if mdtype == 'reg':\n        loss = rmse_loss\n        comp_metric = keras_rmse_reg\n        last_layer = layers.Dense(1)\n    \n    \n    \n    input_imgs = layers.Input(shape=(X_train.shape[1],))\n    #     x = layers.Conv2D(32, (3, 3), activation='relu')(input_imgs)\n    #     x = layers.MaxPooling2D((2, 2))(x)\n    #     x = layers.Flatten()(x)\n    x = layers.Dense(256, activation='relu')(input_imgs)\n    x = layers.Dense(512, activation='relu')(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dense(128, activation='relu')(x)\n    output = last_layer(x)\n\n    model = models.Model(inputs=input_imgs, outputs=output, name=config.name)\n    \n    \n\n    model.compile(optimizer=optimizers.Adam(learning_rate=config.train.lr),\n                    loss = loss,\n                    metrics=[\n                        comp_metric,\n                        metrics.SparseCategoricalAccuracy(name='acc')\n                    ])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:28:50.629631Z","iopub.execute_input":"2023-01-12T17:28:50.631286Z","iopub.status.idle":"2023-01-12T17:28:50.641069Z","shell.execute_reply.started":"2023-01-12T17:28:50.631238Z","shell.execute_reply":"2023-01-12T17:28:50.639984Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model = get_model('clf')\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:28:56.515040Z","iopub.execute_input":"2023-01-12T17:28:56.515961Z","iopub.status.idle":"2023-01-12T17:29:00.438109Z","shell.execute_reply.started":"2023-01-12T17:28:56.515902Z","shell.execute_reply":"2023-01-12T17:29:00.437028Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Loading clf type model...\n","output_type":"stream"},{"name":"stderr","text":"2023-01-12 17:28:56.705849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:28:56.707180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:28:56.824873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:28:56.826187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:28:56.827338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:28:56.828462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:28:56.831160: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"d256_512_256_128_clf_mtdata-1673544468\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 5)]               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               1536      \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               131584    \n_________________________________________________________________\ndense_3 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndense_4 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndense (Dense)                (None, 5)                 645       \n=================================================================\nTotal params: 297,989\nTrainable params: 297,989\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"2023-01-12 17:28:57.143768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:28:57.145020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:28:57.146217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:28:57.147221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:28:57.148237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:28:57.149211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:29:00.026920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:29:00.027822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:29:00.028619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:29:00.029384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:29:00.030097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:29:00.030777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2023-01-12 17:29:00.033588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-12 17:29:00.034354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}]},{"cell_type":"code","source":"# model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:29:00.440524Z","iopub.execute_input":"2023-01-12T17:29:00.441252Z","iopub.status.idle":"2023-01-12T17:29:00.445748Z","shell.execute_reply.started":"2023-01-12T17:29:00.441202Z","shell.execute_reply":"2023-01-12T17:29:00.444423Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"# Train and eval","metadata":{}},{"cell_type":"code","source":"def train_(model, config=config, x_train=X_train, y_train=y_train, debug=None):\n    \"\"\"fits given model to x_train and y_train\"\"\"\n    \n    train_config = config['train']\n    my_callbacks = []\n    \n    earlystopping = callbacks.EarlyStopping(patience=15, monitor='val_loss', restore_best_weights=True)\n    my_callbacks.append(earlystopping)\n    reduce_lr_on_plateau = callbacks.ReduceLROnPlateau(\n                                            monitor=\"val_acc\",\n                                            factor=0.5,\n                                            patience=5,\n                                            verbose=1,\n                                            mode=\"auto\",\n                                            min_delta=0.01,\n                                            cooldown=0,\n                                            min_lr=0)\n    my_callbacks.append(reduce_lr_on_plateau)\n    \n    try:\n        wandb_callback = wandb.keras.WandbCallback(\n            monitor='val_loss',\n            log_weights=True,\n            log_gradients=True,\n            save_model=False,\n            training_data=(x_train, y_train),\n            log_batch_frequency=None,\n        )\n\n        my_callbacks.append(wandb_callback)\n    except:\n        print('wandb not tracking')\n        \n    print(f'Training model... {config.name}')\n    if debug == True:\n        epochs = 1000\n    else:\n        epochs = train_config.epochs\n    history = model.fit(\n                x_train, y_train,\n                epochs=epochs,\n                batch_size=train_config.batch_size, \n                callbacks=my_callbacks, \n                validation_split=0.2, \n                shuffle=True, \n                verbose=1 \n            )\n\n    return model, history\n\n\ndef eval_(model, x_val=X_val, y_val=y_val):\n    print('Evaluating model....')\n    model.evaluate(x_val, y_val, return_dict=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:31:59.024776Z","iopub.execute_input":"2023-01-12T17:31:59.025178Z","iopub.status.idle":"2023-01-12T17:31:59.036415Z","shell.execute_reply.started":"2023-01-12T17:31:59.025146Z","shell.execute_reply":"2023-01-12T17:31:59.035205Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def train_eval(model=None, mdtype='reg', X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, debug=False):\n    \n    if model is None:\n        print('Getting New model')\n        model = get_model()\n    \n    # train\n    model, history = train_(model, config, X_train, y_train=y_train, debug=debug)  # try to overfit thsi batch\n    # eval\n    eval_(model)\n\n    # classification report\n    y_pred = model.predict(X_val)\n    if mdtype == 'clf':\n        y_pred_hard = np.argmax(y_pred, axis=1)             # fuck this shit forgot to \n    if mdtype == 'reg':\n        y_pred_hard = np.round(y_pred)\n        \n    print(y_pred_hard)\n    error = mse(y_val, y_pred_hard, squared=False)\n    print(\"Comp Metric: \", error)\n    cr = classification_report(y_val, y_pred_hard)     # +1 to account for 0-4 as it should be 1-5 originallly\n    print(cr)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:33:58.983435Z","iopub.execute_input":"2023-01-12T17:33:58.983819Z","iopub.status.idle":"2023-01-12T17:33:58.994822Z","shell.execute_reply.started":"2023-01-12T17:33:58.983786Z","shell.execute_reply":"2023-01-12T17:33:58.993650Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"config.train.epochs = 1_000\nconfig.train.lr = 1e-3\nconfig.train","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:33:54.743672Z","iopub.execute_input":"2023-01-12T17:33:54.744620Z","iopub.status.idle":"2023-01-12T17:33:54.752662Z","shell.execute_reply.started":"2023-01-12T17:33:54.744573Z","shell.execute_reply":"2023-01-12T17:33:54.751607Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"{'epochs': 1000,\n 'batch_size': 256,\n 'validation_split': 0.2,\n 'shuffle': True,\n 'verbose': 1,\n 'lr': 0.001}"},"metadata":{}}]},{"cell_type":"code","source":"model = get_model('clf')\ntrain_eval(model, 'clf', X_train=X_train, X_val=X_val, y_train=y_train, y_val=y_val)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T17:34:00.783680Z","iopub.execute_input":"2023-01-12T17:34:00.784103Z","iopub.status.idle":"2023-01-12T17:34:22.271357Z","shell.execute_reply.started":"2023-01-12T17:34:00.784068Z","shell.execute_reply":"2023-01-12T17:34:22.270058Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Loading clf type model...\nwandb not tracking\nTraining model... d256_512_256_128_clf_mtdata-1673544468\nEpoch 1/1000\n43/43 [==============================] - 1s 8ms/step - loss: 1.0720 - keras_rmse_clf: 1.6846 - acc: 0.5764 - val_loss: 0.9452 - val_keras_rmse_clf: 1.7229 - val_acc: 0.6319\nEpoch 2/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.9455 - keras_rmse_clf: 1.7202 - acc: 0.6306 - val_loss: 0.9267 - val_keras_rmse_clf: 1.7264 - val_acc: 0.6462\nEpoch 3/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.9341 - keras_rmse_clf: 1.7220 - acc: 0.6353 - val_loss: 0.9218 - val_keras_rmse_clf: 1.7263 - val_acc: 0.6436\nEpoch 4/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.9295 - keras_rmse_clf: 1.7220 - acc: 0.6353 - val_loss: 0.9144 - val_keras_rmse_clf: 1.7266 - val_acc: 0.6465\nEpoch 5/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.9264 - keras_rmse_clf: 1.7201 - acc: 0.6341 - val_loss: 0.9140 - val_keras_rmse_clf: 1.7266 - val_acc: 0.6473\nEpoch 6/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.9185 - keras_rmse_clf: 1.7205 - acc: 0.6375 - val_loss: 0.9161 - val_keras_rmse_clf: 1.7240 - val_acc: 0.6473\nEpoch 7/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.9174 - keras_rmse_clf: 1.7205 - acc: 0.6382 - val_loss: 0.9085 - val_keras_rmse_clf: 1.7268 - val_acc: 0.6516\n\nEpoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\nEpoch 8/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.9101 - keras_rmse_clf: 1.7213 - acc: 0.6395 - val_loss: 0.9035 - val_keras_rmse_clf: 1.7260 - val_acc: 0.6487\nEpoch 9/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.9076 - keras_rmse_clf: 1.7219 - acc: 0.6408 - val_loss: 0.9021 - val_keras_rmse_clf: 1.7256 - val_acc: 0.6502\nEpoch 10/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.9085 - keras_rmse_clf: 1.7213 - acc: 0.6408 - val_loss: 0.9034 - val_keras_rmse_clf: 1.7257 - val_acc: 0.6505\nEpoch 11/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.9065 - keras_rmse_clf: 1.7194 - acc: 0.6402 - val_loss: 0.9001 - val_keras_rmse_clf: 1.7252 - val_acc: 0.6516\nEpoch 12/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.9066 - keras_rmse_clf: 1.7221 - acc: 0.6407 - val_loss: 0.8988 - val_keras_rmse_clf: 1.7256 - val_acc: 0.6487\n\nEpoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\nEpoch 13/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.9024 - keras_rmse_clf: 1.7208 - acc: 0.6410 - val_loss: 0.8947 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6505\nEpoch 14/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.9009 - keras_rmse_clf: 1.7224 - acc: 0.6402 - val_loss: 0.8949 - val_keras_rmse_clf: 1.7257 - val_acc: 0.6498\nEpoch 15/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.8995 - keras_rmse_clf: 1.7218 - acc: 0.6412 - val_loss: 0.8956 - val_keras_rmse_clf: 1.7255 - val_acc: 0.6480\nEpoch 16/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.9000 - keras_rmse_clf: 1.7218 - acc: 0.6411 - val_loss: 0.8969 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 17/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8998 - keras_rmse_clf: 1.7224 - acc: 0.6399 - val_loss: 0.8932 - val_keras_rmse_clf: 1.7256 - val_acc: 0.6502\n\nEpoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\nEpoch 18/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8969 - keras_rmse_clf: 1.7211 - acc: 0.6412 - val_loss: 0.8931 - val_keras_rmse_clf: 1.7253 - val_acc: 0.6505\nEpoch 19/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8966 - keras_rmse_clf: 1.7204 - acc: 0.6405 - val_loss: 0.8916 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6495\nEpoch 20/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8969 - keras_rmse_clf: 1.7218 - acc: 0.6413 - val_loss: 0.8908 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6505\nEpoch 21/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.8958 - keras_rmse_clf: 1.7223 - acc: 0.6415 - val_loss: 0.8908 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6513\nEpoch 22/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8962 - keras_rmse_clf: 1.7223 - acc: 0.6420 - val_loss: 0.8917 - val_keras_rmse_clf: 1.7259 - val_acc: 0.6502\n\nEpoch 00022: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\nEpoch 23/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8949 - keras_rmse_clf: 1.7212 - acc: 0.6414 - val_loss: 0.8895 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6505\nEpoch 24/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.8943 - keras_rmse_clf: 1.7212 - acc: 0.6421 - val_loss: 0.8898 - val_keras_rmse_clf: 1.7253 - val_acc: 0.6505\nEpoch 25/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8939 - keras_rmse_clf: 1.7221 - acc: 0.6422 - val_loss: 0.8892 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6505\nEpoch 26/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8937 - keras_rmse_clf: 1.7217 - acc: 0.6412 - val_loss: 0.8906 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6487\nEpoch 27/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.8936 - keras_rmse_clf: 1.7211 - acc: 0.6416 - val_loss: 0.8888 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6487\n\nEpoch 00027: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\nEpoch 28/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8928 - keras_rmse_clf: 1.7215 - acc: 0.6418 - val_loss: 0.8886 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6487\nEpoch 29/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8927 - keras_rmse_clf: 1.7215 - acc: 0.6417 - val_loss: 0.8886 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6487\nEpoch 30/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8927 - keras_rmse_clf: 1.7212 - acc: 0.6419 - val_loss: 0.8888 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 31/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8925 - keras_rmse_clf: 1.7222 - acc: 0.6417 - val_loss: 0.8882 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6487\nEpoch 32/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.8924 - keras_rmse_clf: 1.7209 - acc: 0.6420 - val_loss: 0.8884 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6487\n\nEpoch 00032: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\nEpoch 33/1000\n43/43 [==============================] - 0s 7ms/step - loss: 0.8922 - keras_rmse_clf: 1.7219 - acc: 0.6418 - val_loss: 0.8883 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6487\nEpoch 34/1000\n43/43 [==============================] - 0s 6ms/step - loss: 0.8920 - keras_rmse_clf: 1.7221 - acc: 0.6418 - val_loss: 0.8882 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 35/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.8920 - keras_rmse_clf: 1.7201 - acc: 0.6420 - val_loss: 0.8880 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6487\nEpoch 36/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.8920 - keras_rmse_clf: 1.7210 - acc: 0.6417 - val_loss: 0.8881 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6487\nEpoch 37/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8920 - keras_rmse_clf: 1.7201 - acc: 0.6423 - val_loss: 0.8880 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\n\nEpoch 00037: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\nEpoch 38/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8917 - keras_rmse_clf: 1.7217 - acc: 0.6415 - val_loss: 0.8880 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 39/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8917 - keras_rmse_clf: 1.7209 - acc: 0.6423 - val_loss: 0.8881 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 40/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8917 - keras_rmse_clf: 1.7224 - acc: 0.6423 - val_loss: 0.8880 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 41/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.8917 - keras_rmse_clf: 1.7212 - acc: 0.6417 - val_loss: 0.8880 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6487\nEpoch 42/1000\n43/43 [==============================] - 0s 6ms/step - loss: 0.8916 - keras_rmse_clf: 1.7220 - acc: 0.6418 - val_loss: 0.8881 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6487\n\nEpoch 00042: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\nEpoch 43/1000\n43/43 [==============================] - 0s 6ms/step - loss: 0.8915 - keras_rmse_clf: 1.7216 - acc: 0.6421 - val_loss: 0.8880 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 44/1000\n43/43 [==============================] - 0s 6ms/step - loss: 0.8915 - keras_rmse_clf: 1.7214 - acc: 0.6416 - val_loss: 0.8880 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 45/1000\n43/43 [==============================] - 0s 7ms/step - loss: 0.8915 - keras_rmse_clf: 1.7211 - acc: 0.6422 - val_loss: 0.8880 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 46/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.8914 - keras_rmse_clf: 1.7218 - acc: 0.6423 - val_loss: 0.8880 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 47/1000\n43/43 [==============================] - 0s 6ms/step - loss: 0.8915 - keras_rmse_clf: 1.7204 - acc: 0.6422 - val_loss: 0.8880 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\n\nEpoch 00047: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\nEpoch 48/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.8914 - keras_rmse_clf: 1.7208 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 49/1000\n43/43 [==============================] - 0s 7ms/step - loss: 0.8914 - keras_rmse_clf: 1.7217 - acc: 0.6417 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7258 - val_acc: 0.6487\nEpoch 50/1000\n43/43 [==============================] - 0s 6ms/step - loss: 0.8914 - keras_rmse_clf: 1.7219 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 51/1000\n43/43 [==============================] - 0s 7ms/step - loss: 0.8914 - keras_rmse_clf: 1.7212 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 52/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.8914 - keras_rmse_clf: 1.7208 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\n\nEpoch 00052: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\nEpoch 53/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8914 - keras_rmse_clf: 1.7211 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 54/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8913 - keras_rmse_clf: 1.7226 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 55/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.8913 - keras_rmse_clf: 1.7192 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 56/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8913 - keras_rmse_clf: 1.7214 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 57/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8913 - keras_rmse_clf: 1.7207 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\n\nEpoch 00057: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\nEpoch 58/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8913 - keras_rmse_clf: 1.7209 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 59/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8913 - keras_rmse_clf: 1.7230 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 60/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.8913 - keras_rmse_clf: 1.7213 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 61/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8913 - keras_rmse_clf: 1.7215 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 62/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8913 - keras_rmse_clf: 1.7209 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\n\nEpoch 00062: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\nEpoch 63/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8913 - keras_rmse_clf: 1.7222 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 64/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8913 - keras_rmse_clf: 1.7217 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 65/1000\n43/43 [==============================] - 0s 5ms/step - loss: 0.8913 - keras_rmse_clf: 1.7224 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 66/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8913 - keras_rmse_clf: 1.7217 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\nEpoch 67/1000\n43/43 [==============================] - 0s 4ms/step - loss: 0.8913 - keras_rmse_clf: 1.7222 - acc: 0.6423 - val_loss: 0.8879 - val_keras_rmse_clf: 1.7254 - val_acc: 0.6502\n\nEpoch 00067: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\nEvaluating model....\n107/107 [==============================] - 0s 2ms/step - loss: 0.9217 - keras_rmse_clf: 1.7052 - acc: 0.6298\n[0 0 3 ... 0 0 0]\nComp Metric:  0.97867053397351\n              precision    recall  f1-score   support\n\n         0.0       0.59      0.93      0.72      1499\n         1.0       0.00      0.00      0.00       648\n         2.0       0.42      0.23      0.29       544\n         3.0       0.84      0.90      0.87       709\n         4.0       0.00      0.00      0.00        12\n\n    accuracy                           0.63      3412\n   macro avg       0.37      0.41      0.38      3412\nweighted avg       0.50      0.63      0.54      3412\n\n","output_type":"stream"}]},{"cell_type":"code","source":"model.evaluate(X_val, y_val)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config.train.epochs = 1000   # mission: achieve lowest loss possible..\nconfig.desc = \"Bigger dense model on mtdata sev by rs log-loss\"","metadata":{"execution":{"iopub.status.busy":"2023-01-12T14:29:46.284887Z","iopub.execute_input":"2023-01-12T14:29:46.285666Z","iopub.status.idle":"2023-01-12T14:29:46.291740Z","shell.execute_reply.started":"2023-01-12T14:29:46.285618Z","shell.execute_reply":"2023-01-12T14:29:46.290035Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"! pip install -U setuptools","metadata":{"execution":{"iopub.status.busy":"2023-01-12T14:35:13.557677Z","iopub.execute_input":"2023-01-12T14:35:13.558385Z","iopub.status.idle":"2023-01-12T14:35:34.783484Z","shell.execute_reply.started":"2023-01-12T14:35:13.558346Z","shell.execute_reply":"2023-01-12T14:35:34.782081Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (59.8.0)\nCollecting setuptools\n  Downloading setuptools-65.7.0-py3-none-any.whl (1.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: setuptools\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 59.8.0\n    Uninstalling setuptools-59.8.0:\n      Successfully uninstalled setuptools-59.8.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-cudf 21.10.1 requires cupy-cuda114, which is not installed.\nbeatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\nnnabla 1.32.0 requires protobuf<=3.19.4; platform_system != \"Windows\", but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2022.5.0 requires fsspec==2022.5.0, but you have fsspec 2022.11.0 which is incompatible.\ndask-cudf 21.10.1 requires dask==2021.09.1, but you have dask 2022.2.0 which is incompatible.\ndask-cudf 21.10.1 requires distributed==2021.09.1, but you have distributed 2022.2.0 which is incompatible.\nallennlp 2.10.1 requires wandb<0.13.0,>=0.10.0, but you have wandb 0.13.8 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed setuptools-65.7.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"with wandb.init(project=config.PROJECT_NAME, config=config, name=config.name):\n    model = get_model('clf')\n    train_eval(model, 'clf', y_train=y_train, y_val=y_val)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T14:36:53.937819Z","iopub.execute_input":"2023-01-12T14:36:53.938206Z","iopub.status.idle":"2023-01-12T14:37:56.812833Z","shell.execute_reply.started":"2023-01-12T14:36:53.938173Z","shell.execute_reply":"2023-01-12T14:37:56.811444Z"},"trusted":true},"execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669454683331728, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f9bc3256faf4f7d9786a0ab0578ecb6"}},"metadata":{}},{"name":"stdout","text":"Problem at: /tmp/ipykernel_23/223850537.py 1 <module>\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 1108, in init\n    run = wi.init()\n  File \"/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\", line 742, in init\n    raise error\nwandb.errors.CommError: Error communicating with wandb process, exiting...\nFor more info see: https://docs.wandb.ai/library/init#init-start-error\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    741\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCommError\u001b[0m: Error communicating with wandb process, exiting...\nFor more info see: https://docs.wandb.ai/library/init#init-start-error","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/223850537.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPROJECT_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexcept_exit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"problem\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merror_seen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: problem"],"ename":"Exception","evalue":"problem","output_type":"error"}]},{"cell_type":"code","source":"preds = np.argmax(model.predict(X_val), axis=1)  # 0.9779215704185079\nmse(y_val, preds.ravel(), squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T14:35:36.314841Z","iopub.execute_input":"2023-01-12T14:35:36.315290Z","iopub.status.idle":"2023-01-12T14:35:36.526288Z","shell.execute_reply.started":"2023-01-12T14:35:36.315251Z","shell.execute_reply":"2023-01-12T14:35:36.525261Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"0.9779215704185079"},"metadata":{}}]},{"cell_type":"code","source":"pd.Series(preds).value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T14:36:14.222822Z","iopub.execute_input":"2023-01-12T14:36:14.223206Z","iopub.status.idle":"2023-01-12T14:36:14.232837Z","shell.execute_reply.started":"2023-01-12T14:36:14.223175Z","shell.execute_reply":"2023-01-12T14:36:14.231120Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"0    0.687280\n3    0.221571\n2    0.091149\ndtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"y_val.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T14:36:16.052305Z","iopub.execute_input":"2023-01-12T14:36:16.052711Z","iopub.status.idle":"2023-01-12T14:36:16.062939Z","shell.execute_reply.started":"2023-01-12T14:36:16.052677Z","shell.execute_reply":"2023-01-12T14:36:16.061538Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"0.0    0.439332\n3.0    0.207796\n1.0    0.189918\n2.0    0.159437\n4.0    0.003517\nName: severity, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"# history.history","metadata":{"execution":{"iopub.status.busy":"2023-01-12T14:30:20.080265Z","iopub.status.idle":"2023-01-12T14:30:20.080750Z","shell.execute_reply.started":"2023-01-12T14:30:20.080500Z","shell.execute_reply":"2023-01-12T14:30:20.080523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = models.load_model('/kaggle/working/d128_rmse_lndsat8_raw_v1-1673283452.h5', custom_objects={'comp_loss': comp_loss})\n# preds = model.predict(X_val)\n# int_preds = np.round(preds)\n# mse(y_val, int_preds, squared=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-12T14:30:20.082456Z","iopub.status.idle":"2023-01-12T14:30:20.082952Z","shell.execute_reply.started":"2023-01-12T14:30:20.082686Z","shell.execute_reply":"2023-01-12T14:30:20.082717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save something..","metadata":{}},{"cell_type":"code","source":"# save model\nif config.SAVE_MODEL:\n    model.save(config.name + '.h5')\n    print(\"Model saved as \",config.name + '.h5')","metadata":{"execution":{"iopub.status.busy":"2023-01-12T14:36:46.919270Z","iopub.execute_input":"2023-01-12T14:36:46.919876Z","iopub.status.idle":"2023-01-12T14:36:46.983149Z","shell.execute_reply.started":"2023-01-12T14:36:46.919831Z","shell.execute_reply":"2023-01-12T14:36:46.982152Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Model saved as  d256_512_256_128_clf_mtdata-1673533637.h5\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Make submission","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T14:38:54.208633Z","iopub.execute_input":"2023-01-12T14:38:54.209026Z","iopub.status.idle":"2023-01-12T14:38:54.216305Z","shell.execute_reply.started":"2023-01-12T14:38:54.208992Z","shell.execute_reply":"2023-01-12T14:38:54.215154Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Model: \"d256_512_256_128_clf_mtdata-1673533637\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 5)]               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 256)               1536      \n_________________________________________________________________\ndense_7 (Dense)              (None, 512)               131584    \n_________________________________________________________________\ndense_8 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndense_9 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndense_5 (Dense)              (None, 5)                 645       \n=================================================================\nTotal params: 297,989\nTrainable params: 297,989\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-12T14:38:54.728520Z","iopub.execute_input":"2023-01-12T14:38:54.729307Z","iopub.status.idle":"2023-01-12T14:38:54.737065Z","shell.execute_reply.started":"2023-01-12T14:38:54.729270Z","shell.execute_reply":"2023-01-12T14:38:54.735913Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"(6510, 5)"},"metadata":{}}]},{"cell_type":"code","source":"# test_preds = np.round(model.predict(X_test)).ravel()\ntest_preds = np.argmax(model.predict(X_test), axis=1)\ntest_preds = test_preds + 1\nsub_format.severity = test_preds\nsub_format.severity = sub_format.severity.astype(int) \nsub_format.severity.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-12T14:38:55.923599Z","iopub.execute_input":"2023-01-12T14:38:55.924310Z","iopub.status.idle":"2023-01-12T14:38:56.194205Z","shell.execute_reply.started":"2023-01-12T14:38:55.924272Z","shell.execute_reply":"2023-01-12T14:38:56.193255Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"1    2981\n4    2383\n3    1145\n2       1\nName: severity, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"save_file_to = f'{config.name}_preds.csv'\nprint(f'saving file to {save_file_to}')\nsub_format.to_csv(save_file_to, index=False) # expect @ 0.979 0.98","metadata":{"execution":{"iopub.status.busy":"2023-01-12T14:39:43.101931Z","iopub.execute_input":"2023-01-12T14:39:43.102482Z","iopub.status.idle":"2023-01-12T14:39:43.128511Z","shell.execute_reply.started":"2023-01-12T14:39:43.102448Z","shell.execute_reply":"2023-01-12T14:39:43.127509Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"saving file to d256_512_256_128_clf_mtdata-1673533637_preds.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# So...\n\n- NNs with log_loss not at all improving mostly coz of loss -func! --> I thought but\n- NNs with log loss is better compared to rmse-loss??\n- 0.9898369849328295 prev best of 0.97777 is with leaked metadata and a failuree!!","metadata":{}},{"cell_type":"markdown","source":"# ToDos:\n\n- GET a bigger network to overfit and train it to max level maybe and see how far it can go??\n- **Try to beat expanding avg_severity_by_region with the help of imgs, Other wise no use for img data**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}