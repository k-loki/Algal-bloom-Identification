{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Main ...\n\n \n``config, load, preprocess, train, eval  for  Tick tick bloom``\n\n**Yo DON'T rerun this unless you want to overwrite past models, always fork and do your stuff and \nDON'T forget to change the name**","metadata":{}},{"cell_type":"markdown","source":"**``Mission: NNs on landsat8-500x500m-v1``**\n","metadata":{}},{"cell_type":"markdown","source":"# Load imports and dependencies","metadata":{}},{"cell_type":"code","source":"import warnings\nimport sys\nimport os\nimport time\nimport joblib\nimport random\nfrom tqdm import tqdm\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\n\nfrom sklearn.metrics import mean_squared_error as mse\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import OrdinalEncoder\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, activations, losses, metrics, models, optimizers, callbacks\nfrom category_encoders.target_encoder import TargetEncoder\n\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:56:44.311210Z","iopub.execute_input":"2023-01-13T09:56:44.311626Z","iopub.status.idle":"2023-01-13T09:56:56.176712Z","shell.execute_reply.started":"2023-01-13T09:56:44.311590Z","shell.execute_reply":"2023-01-13T09:56:56.175687Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# local utilities imports\nfrom tick_tick_bloom_utils import comp_metric, den2sev_map","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:56:56.178667Z","iopub.execute_input":"2023-01-13T09:56:56.179361Z","iopub.status.idle":"2023-01-13T09:56:56.196459Z","shell.execute_reply.started":"2023-01-13T09:56:56.179326Z","shell.execute_reply":"2023-01-13T09:56:56.195357Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# wandb stuff for tracking\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_login = user_secrets.get_secret(\"wandb_bloom_tracker\")\n\nimport wandb\nwandb.login(key=wandb_login)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:56:56.199804Z","iopub.execute_input":"2023-01-13T09:56:56.200592Z","iopub.status.idle":"2023-01-13T09:57:03.440440Z","shell.execute_reply.started":"2023-01-13T09:56:56.200551Z","shell.execute_reply":"2023-01-13T09:57:03.438956Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"# dot dictionary\nclass dotdict(dict):\n    \"\"\"dot.notation access to dictionary attributes\"\"\"\n    __getattr__ = dict.get\n    __setattr__ = dict.__setitem__\n    __delattr__ = dict.__delitem__\n\n\n# Config\nconfig = {}\nconfig = dotdict(config)\nconfig['RANDOM_SEED'] = 18952\n\n\nconfig['unique_id'] = int(time.time())\nprint(f'unique_id: {config.unique_id}')\nconfig['name'] = f'conv2d64_d128-{config.unique_id}'\n\nconfig['PROJECT_NAME'] = 'tick-tick-bloom'\n# config['DATA_DIR'] = '../data/'\n# config['MODEL_DIR'] = '../models/'\nconfig['SAVE_MODEL'] = True\n\n\n# # Img config\nconfig['IMG_SIZE'] = (36, 36)\nconfig['CHANNELS'] = 5\n\n# training configuration\nconfig['train'] =  dotdict({\n                        'epochs': 1000,\n                        'batch_size': 32,\n                        'validation_split': 0.2,\n                        'shuffle': True,\n                        'verbose': 1,\n                        'lr' : 1e-5\n                        })\n\nconfig['desc'] = \"\"\"simple nns on landsat8-500x500m-v1 --> Not expecting much since data looks soo noisy...\"\"\" ","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:57:03.444570Z","iopub.execute_input":"2023-01-13T09:57:03.444940Z","iopub.status.idle":"2023-01-13T09:57:03.454576Z","shell.execute_reply.started":"2023-01-13T09:57:03.444908Z","shell.execute_reply":"2023-01-13T09:57:03.453044Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"unique_id: 1673603823\n","output_type":"stream"}]},{"cell_type":"code","source":"# seed everything\ndef seed_everything(seed=config.RANDOM_SEED):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n#     os.environ['TF_CUDNN_DETERMINISTIC'] = '1' \n#     os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\n# tf.keras.utils.set_random_seed(config.RANDOM_SEED)  # supposedly sets seed for python, numpy, tf\n\nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:57:03.456689Z","iopub.execute_input":"2023-01-13T09:57:03.457285Z","iopub.status.idle":"2023-01-13T09:57:03.467619Z","shell.execute_reply.started":"2023-01-13T09:57:03.457241Z","shell.execute_reply":"2023-01-13T09:57:03.466632Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def keras_rmse_clf(y_true, y_pred):\n    \"\"\"\n    valid competetion metric for clf type settings.\n    Can be trusted!\n    y_true and y_pred should be [0-4]\n    \"\"\"\n    y_pred = tf.argmax(y_pred, axis=1)\n    y_pred = tf.cast(y_pred, tf.float16)\n    y_true = tf.cast(y_true, tf.float16)\n    squared_difference = tf.square(y_true - y_pred)\n    return tf.sqrt(tf.reduce_mean(squared_difference, axis=-1))\n\ndef keras_rmse_reg(y_true, y_pred):\n    \"\"\"\n    valid competetion metric for reg type settings.\n    Can be trusted!\n    y_true and y_pred should be [0-4]\n    \"\"\"\n    y_pred = tf.math.round(y_pred)\n    y_pred = tf.cast(y_pred, tf.float16)\n    y_true = tf.cast(y_true, tf.float16)\n    squared_difference = tf.square(y_true - y_pred)\n    return tf.sqrt(tf.reduce_mean(squared_difference, axis=-1))\n\n\ndef rmse_loss(y_true, y_pred):\n    \"\"\"loss func to use in reg type settings\"\"\"\n    return tf.sqrt(losses.mean_squared_error(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:57:03.469566Z","iopub.execute_input":"2023-01-13T09:57:03.470060Z","iopub.status.idle":"2023-01-13T09:57:03.480249Z","shell.execute_reply.started":"2023-01-13T09:57:03.470021Z","shell.execute_reply":"2023-01-13T09:57:03.479021Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"INPUT_METADATA_DIR = '/kaggle/input/ticktickbloomdataset'\n\nmetadata = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'metadata.csv'))\nsub_format = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'submission_format.csv'))\ntrain_labels = pd.read_csv(os.path.join(INPUT_METADATA_DIR, 'train_labels.csv'))","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:57:03.481656Z","iopub.execute_input":"2023-01-13T09:57:03.482726Z","iopub.status.idle":"2023-01-13T09:57:03.605935Z","shell.execute_reply.started":"2023-01-13T09:57:03.482686Z","shell.execute_reply":"2023-01-13T09:57:03.604984Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"part1 = '/kaggle/input/pull-landsat-sr-v1-part-1'\npart2 = '/kaggle/input/pull-landsat-sr-v1-part-2'\n\npart1_imgs = os.path.join(part1, \"landsat8_sr_500m_v1\")\npart2_imgs = os.path.join(part2, \"landsat8_sr_500m_v1\")\n\np1imgs = [name.split('.')[0] for name in os.listdir(part1_imgs)]\np2imgs = [name.split('.')[0] for name in os.listdir(part2_imgs)]\n\nimg_uids = p1imgs + p2imgs\nlen(img_uids)                           # 1754 imgs missing!","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:57:03.607572Z","iopub.execute_input":"2023-01-13T09:57:03.607972Z","iopub.status.idle":"2023-01-13T09:57:04.565802Z","shell.execute_reply.started":"2023-01-13T09:57:03.607935Z","shell.execute_reply":"2023-01-13T09:57:04.564885Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"21816"},"metadata":{}}]},{"cell_type":"code","source":"metadata_subset = metadata[metadata['uid'].isin(img_uids)]\ndata = metadata_subset[metadata_subset.split == 'train']\ndata = data.merge(train_labels, on='uid')\n\ntest_data = metadata[metadata.split == 'test']\n\ndata.shape, test_data.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:57:04.568146Z","iopub.execute_input":"2023-01-13T09:57:04.568830Z","iopub.status.idle":"2023-01-13T09:57:04.634053Z","shell.execute_reply.started":"2023-01-13T09:57:04.568791Z","shell.execute_reply":"2023-01-13T09:57:04.632925Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"((15724, 8), (6510, 5))"},"metadata":{}}]},{"cell_type":"code","source":"missing_data = metadata[~metadata.uid.isin(metadata_subset.uid)]\nmissing_data.split.value_counts()  # 181 test samples are missing.","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:57:04.639571Z","iopub.execute_input":"2023-01-13T09:57:04.640497Z","iopub.status.idle":"2023-01-13T09:57:04.652571Z","shell.execute_reply.started":"2023-01-13T09:57:04.640427Z","shell.execute_reply":"2023-01-13T09:57:04.651447Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"train    1336\ntest      418\nName: split, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# load img from img paths\ndef get_img(uid: str) -> np.ndarray:\n    \"\"\"return data arr for given uid \n    Only give uids already present in the downloaded data\"\"\"\n    try:\n        arr = joblib.load(part1_imgs + f'/{uid}.npy')\n    except Exception as e:\n        arr = joblib.load(part2_imgs + f'/{uid}.npy')\n    return arr\n\ndef normalize_band(img_band):\n    # temp normailze to 0 and 1\n    m = img_band.max()\n    return img_band/m\n\ndef resize_band(norm_img_band):\n    return cv2.resize(norm_img_band, config.IMG_SIZE)\n\n\n# seperate img_arr from data and resize all\ndef get_img_arr(arr: np.ndarray, start: int = 0, end: int = 5) -> np.ndarray:\n    img_arr = arr[start:end]                       # just few bands for now!!\n    return img_arr\n\ndef norm_resize_bands(arr_bands: np.ndarray):\n    finished_bands = []\n    for band in arr_bands:\n        nb = normalize_band(band)\n        rb = resize_band(nb)\n        finished_bands.append(rb)\n    return np.array(finished_bands)\n\n#  do that for all samples in metadata_subset (and test_data)\ndef get_all_imgs(uid_list: list) -> np.ndarray:\n    data_list = []\n    # add tqdm..\n    for uid in tqdm(uid_list): \n        arr = get_img(uid)\n        img_arr = get_img_arr(arr)\n        normalized_img_arr = norm_resize_bands(img_arr)\n        data_list.append(normalized_img_arr)\n    return np.array(data_list)\n\n\n#  make into tf or np datasets","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:57:04.654306Z","iopub.execute_input":"2023-01-13T09:57:04.654792Z","iopub.status.idle":"2023-01-13T09:57:04.669385Z","shell.execute_reply.started":"2023-01-13T09:57:04.654755Z","shell.execute_reply":"2023-01-13T09:57:04.668350Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_np_data(split : float = 0.2, task='train'):\n    \"\"\"Return np data for training and validation.\"\"\"\n    if task == 'train':\n        print(\"Loading train and validation data...\")\n        x_train_uids, x_val_uids, y_train, y_val = train_test_split(\n            data['uid'],\n            data.severity,\n            test_size=split,\n            random_state=config.RANDOM_SEED,\n            stratify=data.severity\n        )\n\n        x_train = get_all_imgs(x_train_uids)\n        x_val = get_all_imgs(x_val_uids)\n\n        return x_train, y_train, x_val, y_val\n\n    if task == 'test':\n        test_ids = test_data.uids\n        x_test\n        return x_test","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:57:04.671809Z","iopub.execute_input":"2023-01-13T09:57:04.672929Z","iopub.status.idle":"2023-01-13T09:57:04.680851Z","shell.execute_reply.started":"2023-01-13T09:57:04.672890Z","shell.execute_reply":"2023-01-13T09:57:04.680022Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"%%time\nx_train_, y_train_, x_val_, y_val_ = get_np_data()\nprint(y_train_.value_counts(normalize=True))\nprint(y_val_.value_counts(normalize=True))\nprint('Done')","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:57:04.682319Z","iopub.execute_input":"2023-01-13T09:57:04.683185Z","iopub.status.idle":"2023-01-13T09:59:27.903239Z","shell.execute_reply.started":"2023-01-13T09:57:04.683146Z","shell.execute_reply":"2023-01-13T09:59:27.901874Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Loading train and validation data...\n1    0.434454\n4    0.213769\n2    0.189363\n3    0.158916\n5    0.003498\nName: severity, dtype: float64\n1    0.434340\n4    0.213990\n2    0.189189\n3    0.158983\n5    0.003498\nName: severity, dtype: float64\nDone\nCPU times: user 10.6 s, sys: 3.01 s, total: 13.6 s\nWall time: 2min 23s\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess","metadata":{}},{"cell_type":"code","source":"# # change labels to 0-3(model works this way) instead of 1-4 given range(given severity)\n# -1 for to make labels look like sparse encoded labels\n\ny_train = y_train_-1\ny_val = y_val_-1\n\n\nX_train = x_train_.transpose([0, 2, 3, 1])\nX_val = x_val_.transpose([0, 2, 3, 1])\n\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:59:27.905507Z","iopub.execute_input":"2023-01-13T09:59:27.906046Z","iopub.status.idle":"2023-01-13T09:59:27.917261Z","shell.execute_reply.started":"2023-01-13T09:59:27.905974Z","shell.execute_reply":"2023-01-13T09:59:27.916121Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"((12579, 36, 36, 5), (3145, 36, 36, 5), (12579,), (3145,))"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def get_model(mdtype='clf'):\n    print(f'Loading {mdtype} type model...')\n    input_shape = (*config.IMG_SIZE, config.CHANNELS)\n\n    if mdtype == 'clf':\n        loss = losses.SparseCategoricalCrossentropy()\n        comp_metric = keras_rmse_clf\n        last_layer = layers.Dense(5, activation='softmax')\n\n    if mdtype == 'reg':\n        loss = rmse_loss\n        comp_metric = keras_rmse_reg\n        last_layer = layers.Dense(1)\n    \n    \n    input_imgs = layers.Input(shape=input_shape)\n    x = layers.Conv2D(64, (3, 3), activation='relu')(input_imgs)\n    x = layers.MaxPooling2D((2, 2))(x)\n    x = layers.Flatten()(x)\n    x = layers.Dense(256, activation='relu')(x)\n    x = layers.Dense(128, activation='relu')(x)\n    output = last_layer(x)\n\n    model = models.Model(inputs=input_imgs, outputs=output, name=config.name)\n    \n\n    model.compile(optimizer=optimizers.Adam(learning_rate=config.train.lr),\n                    loss = loss,\n                    metrics=[\n                        comp_metric,\n                        metrics.SparseCategoricalAccuracy(name='acc')\n                    ])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:59:27.918946Z","iopub.execute_input":"2023-01-13T09:59:27.919705Z","iopub.status.idle":"2023-01-13T09:59:27.934838Z","shell.execute_reply.started":"2023-01-13T09:59:27.919660Z","shell.execute_reply":"2023-01-13T09:59:27.933567Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = get_model('clf')\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:59:27.936617Z","iopub.execute_input":"2023-01-13T09:59:27.937201Z","iopub.status.idle":"2023-01-13T09:59:33.340366Z","shell.execute_reply.started":"2023-01-13T09:59:27.937156Z","shell.execute_reply":"2023-01-13T09:59:33.336399Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Loading clf type model...\n","output_type":"stream"},{"name":"stderr","text":"2023-01-13 09:59:28.138682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:28.139698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:28.376837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:28.377870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:28.378761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:28.379625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:28.382762: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"conv2d64_d128-1673603823\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 36, 36, 5)]       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 34, 34, 64)        2944      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 17, 17, 64)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 18496)             0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               4735232   \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndense (Dense)                (None, 5)                 645       \n=================================================================\nTotal params: 4,771,717\nTrainable params: 4,771,717\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"2023-01-13 09:59:28.617868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:28.618840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:28.619627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:28.620395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:28.621186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:28.621904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:32.870642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:32.871668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:32.872483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:32.873275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:32.874032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:32.874750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2023-01-13 09:59:32.879752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 09:59:32.880538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}]},{"cell_type":"code","source":"y_train.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:59:33.343156Z","iopub.execute_input":"2023-01-13T09:59:33.343963Z","iopub.status.idle":"2023-01-13T09:59:33.353460Z","shell.execute_reply.started":"2023-01-13T09:59:33.343917Z","shell.execute_reply":"2023-01-13T09:59:33.352101Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"0    5465\n3    2689\n1    2382\n2    1999\n4      44\nName: severity, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# model.fit(X_train, y_train, epochs=5)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:59:33.355335Z","iopub.execute_input":"2023-01-13T09:59:33.356014Z","iopub.status.idle":"2023-01-13T09:59:33.364959Z","shell.execute_reply.started":"2023-01-13T09:59:33.355859Z","shell.execute_reply":"2023-01-13T09:59:33.364020Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train and eval","metadata":{}},{"cell_type":"code","source":"def train_(model, config=config, x_train=X_train, y_train=y_train, debug=None):\n    \"\"\"fits given model to x_train and y_train\"\"\"\n    \n    train_config = config['train']\n    my_callbacks = []\n    \n    earlystopping = callbacks.EarlyStopping(patience=15, monitor='val_loss', restore_best_weights=True)\n    my_callbacks.append(earlystopping)\n    reduce_lr_on_plateau = callbacks.ReduceLROnPlateau(\n                                            monitor=\"val_acc\",\n                                            factor=0.5,\n                                            patience=5,\n                                            verbose=1,\n                                            mode=\"auto\",\n                                            min_delta=0.01,\n                                            cooldown=0,\n                                            min_lr=0)\n    my_callbacks.append(reduce_lr_on_plateau)\n    \n    try:\n        wandb_callback = wandb.keras.WandbCallback(\n            monitor='val_loss',\n            log_weights=True,\n            log_gradients=True,\n            save_model=False,\n            training_data=(x_train, y_train),\n            log_batch_frequency=None,\n        )\n\n        my_callbacks.append(wandb_callback)\n    except:\n        print('wandb not tracking')\n        \n    print(f'Training model... {config.name}')\n    if debug == True:\n        epochs = 1000\n    else:\n        epochs = train_config.epochs\n    history = model.fit(\n                x_train, y_train,\n                epochs=epochs,\n                batch_size=train_config.batch_size, \n                callbacks=my_callbacks, \n                validation_split=0.2, \n                shuffle=True, \n                verbose=1 \n            )\n\n    return model, history\n\n\ndef eval_(model, x_val=X_val, y_val=y_val):\n    print('Evaluating model....')\n    model.evaluate(x_val, y_val, return_dict=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:59:33.366810Z","iopub.execute_input":"2023-01-13T09:59:33.367282Z","iopub.status.idle":"2023-01-13T09:59:33.380202Z","shell.execute_reply.started":"2023-01-13T09:59:33.367234Z","shell.execute_reply":"2023-01-13T09:59:33.379133Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train_eval(model=None, mdtype='clf', X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, debug=False):\n    \n    if model is None:\n        print('Getting New model')\n        model = get_model()\n    \n    # train\n    model, history = train_(model, config, X_train, y_train=y_train, debug=debug)  # try to overfit thsi batch\n    # eval\n    eval_(model)\n\n    # classification report\n    y_pred = model.predict(X_val)\n    if mdtype == 'clf':\n        y_pred_hard = np.argmax(y_pred, axis=1)             \n    if mdtype == 'reg':\n        y_pred_hard = np.round(y_pred)\n        \n    print(y_pred_hard)\n    error = mse(y_val, y_pred_hard, squared=False)\n    print(\"Comp Metric: \", error)\n    cr = classification_report(y_val, y_pred_hard)     # +1 to account for 0-4 as it should be 1-5 originallly\n    print(cr)\n    \n    return model, history\n","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:59:33.381880Z","iopub.execute_input":"2023-01-13T09:59:33.382352Z","iopub.status.idle":"2023-01-13T09:59:33.397156Z","shell.execute_reply.started":"2023-01-13T09:59:33.382313Z","shell.execute_reply":"2023-01-13T09:59:33.396212Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"config.train.epochs = 100\nconfig.train.lr = 1e-5\nconfig.train","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:59:33.398515Z","iopub.execute_input":"2023-01-13T09:59:33.398936Z","iopub.status.idle":"2023-01-13T09:59:33.417481Z","shell.execute_reply.started":"2023-01-13T09:59:33.398898Z","shell.execute_reply":"2023-01-13T09:59:33.416141Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{'epochs': 100,\n 'batch_size': 32,\n 'validation_split': 0.2,\n 'shuffle': True,\n 'verbose': 1,\n 'lr': 1e-05}"},"metadata":{}}]},{"cell_type":"code","source":"model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:59:33.418901Z","iopub.execute_input":"2023-01-13T09:59:33.419863Z","iopub.status.idle":"2023-01-13T09:59:49.380783Z","shell.execute_reply.started":"2023-01-13T09:59:33.419824Z","shell.execute_reply":"2023-01-13T09:59:49.379812Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"2023-01-13 09:59:34.410669: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n2023-01-13 09:59:37.071560: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"394/394 [==============================] - 15s 5ms/step - loss: 1.3267 - keras_rmse_clf: 1.1769 - acc: 0.4333\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f997c2cef90>"},"metadata":{}}]},{"cell_type":"code","source":"with wandb.init(project=config.PROJECT_NAME, config=config, name=config.name):\n    model = get_model('clf')\n    model, history = train_eval(model, 'clf', X_train=X_train, X_val=X_val, y_train=y_train, y_val=y_val)","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:59:49.382100Z","iopub.execute_input":"2023-01-13T09:59:49.382523Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mk_loki\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.9 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230113_095949-1l3wvy24</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/k_loki/tick-tick-bloom/runs/1l3wvy24\" target=\"_blank\">conv2d64_d128-1673603823</a></strong> to <a href=\"https://wandb.ai/k_loki/tick-tick-bloom\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"name":"stdout","text":"Loading clf type model...\nTraining model... conv2d64_d128-1673603823\n","output_type":"stream"},{"name":"stderr","text":"2023-01-13 10:00:08.551620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 10:00:08.552523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 10:00:08.553480: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2\n2023-01-13 10:00:08.553669: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n2023-01-13 10:00:08.554428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 10:00:08.555148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 10:00:08.556245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 10:00:08.556909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 10:00:08.558018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 10:00:08.558705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 10:00:08.560052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 10:00:08.560714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 10:00:08.561841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 10:00:08.562362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n2023-01-13 10:00:08.562548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2023-01-13 10:00:08.563522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n2023-01-13 10:00:08.572397: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n  function_optimizer: function_optimizer did nothing. time = 0.011ms.\n  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n315/315 [==============================] - 4s 9ms/step - loss: 1.3342 - keras_rmse_clf: 1.1790 - acc: 0.4302 - val_loss: 1.3170 - val_keras_rmse_clf: 1.1347 - val_acc: 0.4452\nEpoch 2/100\n315/315 [==============================] - 3s 8ms/step - loss: 1.3101 - keras_rmse_clf: 1.2183 - acc: 0.4308 - val_loss: 1.3034 - val_keras_rmse_clf: 1.1679 - val_acc: 0.4444\nEpoch 3/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.3052 - keras_rmse_clf: 1.2927 - acc: 0.4279 - val_loss: 1.3113 - val_keras_rmse_clf: 1.4693 - val_acc: 0.4392\nEpoch 4/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.3004 - keras_rmse_clf: 1.3544 - acc: 0.4335 - val_loss: 1.2944 - val_keras_rmse_clf: 1.1981 - val_acc: 0.4440\nEpoch 5/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2949 - keras_rmse_clf: 1.3650 - acc: 0.4347 - val_loss: 1.3034 - val_keras_rmse_clf: 1.4982 - val_acc: 0.4487\nEpoch 6/100\n315/315 [==============================] - 2s 7ms/step - loss: 1.2896 - keras_rmse_clf: 1.3811 - acc: 0.4370 - val_loss: 1.2897 - val_keras_rmse_clf: 1.4560 - val_acc: 0.4491\n\nEpoch 00006: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\nEpoch 7/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.2826 - keras_rmse_clf: 1.4415 - acc: 0.4405 - val_loss: 1.2864 - val_keras_rmse_clf: 1.4605 - val_acc: 0.4507\nEpoch 8/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.2805 - keras_rmse_clf: 1.4141 - acc: 0.4411 - val_loss: 1.2868 - val_keras_rmse_clf: 1.4945 - val_acc: 0.4555\nEpoch 10/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2749 - keras_rmse_clf: 1.4396 - acc: 0.4463 - val_loss: 1.2828 - val_keras_rmse_clf: 1.5030 - val_acc: 0.4551\nEpoch 11/100\n315/315 [==============================] - 2s 7ms/step - loss: 1.2737 - keras_rmse_clf: 1.4774 - acc: 0.4483 - val_loss: 1.2765 - val_keras_rmse_clf: 1.4623 - val_acc: 0.4563\nEpoch 12/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2707 - keras_rmse_clf: 1.4841 - acc: 0.4500 - val_loss: 1.2772 - val_keras_rmse_clf: 1.2826 - val_acc: 0.4503\nEpoch 13/100\n315/315 [==============================] - 2s 7ms/step - loss: 1.2683 - keras_rmse_clf: 1.4611 - acc: 0.4505 - val_loss: 1.2742 - val_keras_rmse_clf: 1.4666 - val_acc: 0.4579\n\nEpoch 00013: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\nEpoch 14/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2654 - keras_rmse_clf: 1.4844 - acc: 0.4528 - val_loss: 1.2725 - val_keras_rmse_clf: 1.4627 - val_acc: 0.4607\nEpoch 15/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.2647 - keras_rmse_clf: 1.4927 - acc: 0.4539 - val_loss: 1.2704 - val_keras_rmse_clf: 1.4682 - val_acc: 0.4575\nEpoch 16/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2628 - keras_rmse_clf: 1.5029 - acc: 0.4539 - val_loss: 1.2731 - val_keras_rmse_clf: 1.4538 - val_acc: 0.4591\nEpoch 17/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.2626 - keras_rmse_clf: 1.4989 - acc: 0.4580 - val_loss: 1.2687 - val_keras_rmse_clf: 1.4266 - val_acc: 0.4607\nEpoch 18/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2611 - keras_rmse_clf: 1.5086 - acc: 0.4564 - val_loss: 1.2691 - val_keras_rmse_clf: 1.4150 - val_acc: 0.4630\n\nEpoch 00018: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.\nEpoch 19/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2596 - keras_rmse_clf: 1.5082 - acc: 0.4568 - val_loss: 1.2673 - val_keras_rmse_clf: 1.4534 - val_acc: 0.4622\nEpoch 20/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2590 - keras_rmse_clf: 1.5053 - acc: 0.4578 - val_loss: 1.2672 - val_keras_rmse_clf: 1.4748 - val_acc: 0.4630\nEpoch 21/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2583 - keras_rmse_clf: 1.5146 - acc: 0.4561 - val_loss: 1.2673 - val_keras_rmse_clf: 1.3847 - val_acc: 0.4591\nEpoch 22/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.2583 - keras_rmse_clf: 1.5100 - acc: 0.4587 - val_loss: 1.2661 - val_keras_rmse_clf: 1.4541 - val_acc: 0.4634\nEpoch 23/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2577 - keras_rmse_clf: 1.5090 - acc: 0.4579 - val_loss: 1.2668 - val_keras_rmse_clf: 1.5064 - val_acc: 0.4662\nEpoch 24/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2570 - keras_rmse_clf: 1.5228 - acc: 0.4600 - val_loss: 1.2653 - val_keras_rmse_clf: 1.4218 - val_acc: 0.4658\nEpoch 25/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.2568 - keras_rmse_clf: 1.5056 - acc: 0.4599 - val_loss: 1.2650 - val_keras_rmse_clf: 1.4712 - val_acc: 0.4638\nEpoch 26/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2558 - keras_rmse_clf: 1.5234 - acc: 0.4593 - val_loss: 1.2645 - val_keras_rmse_clf: 1.4568 - val_acc: 0.4654\n315/315 [==============================] - 2s 5ms/step - loss: 1.2553 - keras_rmse_clf: 1.5284 - acc: 0.4619 - val_loss: 1.2640 - val_keras_rmse_clf: 1.4398 - val_acc: 0.4678\nEpoch 28/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2549 - keras_rmse_clf: 1.5204 - acc: 0.4578 - val_loss: 1.2650 - val_keras_rmse_clf: 1.5081 - val_acc: 0.4670\n\nEpoch 00028: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.\nEpoch 29/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.2540 - keras_rmse_clf: 1.5213 - acc: 0.4626 - val_loss: 1.2639 - val_keras_rmse_clf: 1.4640 - val_acc: 0.4646\nEpoch 30/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.2539 - keras_rmse_clf: 1.5413 - acc: 0.4603 - val_loss: 1.2634 - val_keras_rmse_clf: 1.4740 - val_acc: 0.4674\nEpoch 31/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2536 - keras_rmse_clf: 1.5209 - acc: 0.4632 - val_loss: 1.2632 - val_keras_rmse_clf: 1.4676 - val_acc: 0.4658\nEpoch 32/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2534 - keras_rmse_clf: 1.5219 - acc: 0.4633 - val_loss: 1.2630 - val_keras_rmse_clf: 1.4776 - val_acc: 0.4662\nEpoch 33/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2527 - keras_rmse_clf: 1.5242 - acc: 0.4635 - val_loss: 1.2635 - val_keras_rmse_clf: 1.4929 - val_acc: 0.4662\n\nEpoch 00033: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.\nEpoch 34/100\n315/315 [==============================] - 2s 8ms/step - loss: 1.2527 - keras_rmse_clf: 1.5236 - acc: 0.4628 - val_loss: 1.2632 - val_keras_rmse_clf: 1.4952 - val_acc: 0.4674\nEpoch 35/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2523 - keras_rmse_clf: 1.5253 - acc: 0.4626 - val_loss: 1.2628 - val_keras_rmse_clf: 1.4950 - val_acc: 0.4666\nEpoch 36/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2523 - keras_rmse_clf: 1.5326 - acc: 0.4620 - val_loss: 1.2626 - val_keras_rmse_clf: 1.4798 - val_acc: 0.4666\nEpoch 37/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2519 - keras_rmse_clf: 1.5399 - acc: 0.4618 - val_loss: 1.2623 - val_keras_rmse_clf: 1.4644 - val_acc: 0.4670\nEpoch 38/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.2520 - keras_rmse_clf: 1.5261 - acc: 0.4631 - val_loss: 1.2623 - val_keras_rmse_clf: 1.4826 - val_acc: 0.4662\n\nEpoch 00038: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.\nEpoch 39/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2517 - keras_rmse_clf: 1.5172 - acc: 0.4632 - val_loss: 1.2628 - val_keras_rmse_clf: 1.5053 - val_acc: 0.4666\nEpoch 40/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.2516 - keras_rmse_clf: 1.5309 - acc: 0.4635 - val_loss: 1.2625 - val_keras_rmse_clf: 1.4951 - val_acc: 0.4674\nEpoch 41/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2515 - keras_rmse_clf: 1.5401 - acc: 0.4642 - val_loss: 1.2622 - val_keras_rmse_clf: 1.4792 - val_acc: 0.4658\nEpoch 42/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2515 - keras_rmse_clf: 1.5105 - acc: 0.4642 - val_loss: 1.2623 - val_keras_rmse_clf: 1.4929 - val_acc: 0.4670\nEpoch 43/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.2514 - keras_rmse_clf: 1.5317 - acc: 0.4634 - val_loss: 1.2622 - val_keras_rmse_clf: 1.4878 - val_acc: 0.4678\n\nEpoch 00043: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-08.\nEpoch 52/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.2510 - keras_rmse_clf: 1.5291 - acc: 0.4635 - val_loss: 1.2622 - val_keras_rmse_clf: 1.4995 - val_acc: 0.4678\nEpoch 53/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.2510 - keras_rmse_clf: 1.5306 - acc: 0.4630 - val_loss: 1.2622 - val_keras_rmse_clf: 1.4998 - val_acc: 0.4674\n\nEpoch 00053: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-08.\nEpoch 54/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2510 - keras_rmse_clf: 1.5332 - acc: 0.4631 - val_loss: 1.2622 - val_keras_rmse_clf: 1.4995 - val_acc: 0.4678\nEpoch 55/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2510 - keras_rmse_clf: 1.5295 - acc: 0.4631 - val_loss: 1.2622 - val_keras_rmse_clf: 1.4998 - val_acc: 0.4674\nEpoch 56/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2510 - keras_rmse_clf: 1.5338 - acc: 0.4632 - val_loss: 1.2622 - val_keras_rmse_clf: 1.4995 - val_acc: 0.4678\nEpoch 57/100\n315/315 [==============================] - 2s 6ms/step - loss: 1.2510 - keras_rmse_clf: 1.5299 - acc: 0.4631 - val_loss: 1.2622 - val_keras_rmse_clf: 1.4995 - val_acc: 0.4678\nEpoch 58/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2510 - keras_rmse_clf: 1.5307 - acc: 0.4632 - val_loss: 1.2621 - val_keras_rmse_clf: 1.4995 - val_acc: 0.4678\n\nEpoch 00058: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-09.\nEpoch 59/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2509 - keras_rmse_clf: 1.5324 - acc: 0.4629 - val_loss: 1.2621 - val_keras_rmse_clf: 1.4995 - val_acc: 0.4678\nEpoch 60/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2509 - keras_rmse_clf: 1.5304 - acc: 0.4631 - val_loss: 1.2621 - val_keras_rmse_clf: 1.4995 - val_acc: 0.4678\nEpoch 61/100\n315/315 [==============================] - 2s 7ms/step - loss: 1.2509 - keras_rmse_clf: 1.5325 - acc: 0.4632 - val_loss: 1.2621 - val_keras_rmse_clf: 1.4995 - val_acc: 0.4678\nEpoch 62/100\n315/315 [==============================] - 2s 5ms/step - loss: 1.2509 - keras_rmse_clf: 1.5317 - acc: 0.4633 - val_loss: 1.2621 - val_keras_rmse_clf: 1.4995 - val_acc: 0.4678\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.config.list_physical_devices('GPU')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.config.list_physical_devices('GPU')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.argmax(model.predict(X_val), axis=1)\nmse(y_val, preds.ravel(), squared=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series(preds).value_counts(normalize=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_val.value_counts(normalize=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = models.load_model('/kaggle/working/d128_rmse_lndsat8_raw_v1-1673283452.h5', custom_objects={'comp_loss': comp_loss})\n# preds = model.predict(X_val)\n# int_preds = np.round(preds)\n# mse(y_val, int_preds, squared=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save something..","metadata":{}},{"cell_type":"code","source":"# save model\nif config.SAVE_MODEL:\n    model.save(config.name + '.h5')\n    print(\"Model saved as \",config.name + '.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make submission","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_preds = np.round(model.predict(X_test)).ravel()\ntest_preds = np.argmax(model.predict(X_test), axis=1)\ntest_preds = test_preds + 1\nsub_format.severity = test_preds\nsub_format.severity = sub_format.severity.astype(int) \nsub_format.severity.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_file_to = f'{config.name}_preds.csv'\nprint(f'saving file to {save_file_to}')\nsub_format.to_csv(save_file_to, index=False) # expect @ 0.979 0.98","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# So...\n\n- NNs with log_loss not at all improving mostly coz of loss -func! --> I thought but\n- NNs with log loss is better compared to rmse-loss??\n- 0.9898369849328295 prev best of 0.97777 is with leaked metadata and a failuree!!","metadata":{}},{"cell_type":"markdown","source":"# ToDos:\n\n- GET a bigger network to overfit and train it to max level maybe and see how far it can go??\n- **Try to beat expanding avg_severity_by_region with the help of imgs, Other wise no use for img data**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}