{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Mission : Error Analysis & Model metadata``\n",
    "\n",
    "- Why 0.80 vs 0.100???\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('../data/metadata.csv')\n",
    "sub_format = pd.read_csv('../data/submission_format.csv')\n",
    "train_labels = pd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return mse(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dens_to_sev(x: float)-> int:\n",
    "    \"\"\"takes in density value in cells/ml and returns severity category\"\"\"\n",
    "    if (x < 20_000) : return 1\n",
    "    elif (x >= 20_000) and (x < 100_000) : return 2\n",
    "    elif (x >= 100_000) and (x < 1_000_000) : return 3\n",
    "    elif (x >= 1_000_000) and (x < 10_000_000) : return 4\n",
    "    elif x > 10_000_000 : return 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add date fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aabm</td>\n",
       "      <td>39.080319</td>\n",
       "      <td>-86.430867</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>train</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aabn</td>\n",
       "      <td>36.559700</td>\n",
       "      <td>-121.510000</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>test</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aacd</td>\n",
       "      <td>35.875083</td>\n",
       "      <td>-78.878434</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>train</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaee</td>\n",
       "      <td>35.487000</td>\n",
       "      <td>-79.062133</td>\n",
       "      <td>2016-08-24</td>\n",
       "      <td>train</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaff</td>\n",
       "      <td>38.049471</td>\n",
       "      <td>-99.827001</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>train</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>3.0</td>\n",
       "      <td>111825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23565</th>\n",
       "      <td>zzvv</td>\n",
       "      <td>36.708500</td>\n",
       "      <td>-121.749000</td>\n",
       "      <td>2014-12-02</td>\n",
       "      <td>test</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23566</th>\n",
       "      <td>zzwo</td>\n",
       "      <td>39.792190</td>\n",
       "      <td>-99.971050</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>train</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23567</th>\n",
       "      <td>zzwq</td>\n",
       "      <td>35.794000</td>\n",
       "      <td>-79.012551</td>\n",
       "      <td>2015-03-24</td>\n",
       "      <td>train</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23568</th>\n",
       "      <td>zzyb</td>\n",
       "      <td>35.742000</td>\n",
       "      <td>-79.238600</td>\n",
       "      <td>2016-11-21</td>\n",
       "      <td>train</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23569</th>\n",
       "      <td>zzzi</td>\n",
       "      <td>39.767323</td>\n",
       "      <td>-96.028617</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>test</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23570 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid   latitude   longitude       date  split  year  month  week  \\\n",
       "0      aabm  39.080319  -86.430867 2018-05-14  train  2018      5    20   \n",
       "1      aabn  36.559700 -121.510000 2016-08-31   test  2016      8    35   \n",
       "2      aacd  35.875083  -78.878434 2020-11-19  train  2020     11    47   \n",
       "3      aaee  35.487000  -79.062133 2016-08-24  train  2016      8    34   \n",
       "4      aaff  38.049471  -99.827001 2019-07-23  train  2019      7    30   \n",
       "...     ...        ...         ...        ...    ...   ...    ...   ...   \n",
       "23565  zzvv  36.708500 -121.749000 2014-12-02   test  2014     12    49   \n",
       "23566  zzwo  39.792190  -99.971050 2017-06-19  train  2017      6    25   \n",
       "23567  zzwq  35.794000  -79.012551 2015-03-24  train  2015      3    13   \n",
       "23568  zzyb  35.742000  -79.238600 2016-11-21  train  2016     11    47   \n",
       "23569  zzzi  39.767323  -96.028617 2015-08-31   test  2015      8    36   \n",
       "\n",
       "       season   region  severity   density  \n",
       "0           2  midwest       1.0     585.0  \n",
       "1           3     west       NaN       NaN  \n",
       "2           4    south       1.0     290.0  \n",
       "3           3    south       1.0    1614.0  \n",
       "4           3  midwest       3.0  111825.0  \n",
       "...       ...      ...       ...       ...  \n",
       "23565       1     west       NaN       NaN  \n",
       "23566       3  midwest       2.0   48510.0  \n",
       "23567       2    south       1.0    1271.0  \n",
       "23568       4    south       1.0    9682.0  \n",
       "23569       3  midwest       NaN       NaN  \n",
       "\n",
       "[23570 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.date = pd.to_datetime(metadata.date)\n",
    "metadata['year'] = metadata.date.dt.year\n",
    "metadata['month'] = metadata.date.dt.month\n",
    "metadata['week'] = metadata.date.dt.isocalendar().week\n",
    "\n",
    "\n",
    "seasons = {\n",
    "    1: 1,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 2,\n",
    "    5: 2,\n",
    "    6: 3,\n",
    "    7: 3,\n",
    "    8: 3,\n",
    "    9: 4,\n",
    "    10: 4,\n",
    "    11: 4,\n",
    "    12: 1\n",
    "}\n",
    "\n",
    "metadata['season'] = metadata.month.map(seasons)\n",
    "\n",
    "\n",
    "region = pd.concat((train_labels, sub_format[['region', 'uid']]), axis=0)\n",
    "\n",
    "data = pd.merge(metadata, region, on='uid', how='left')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6510, 12), (23570, 12))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data[data.split == 'test']\n",
    "test_data.shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17060, 12), (23570, 12))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data[data.split == 'train']\n",
    "train_data.shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1459554513481827"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.severity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dens_to_sev(train_data.density.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Utils\n",
    "def get_data_by_date( date=None, data=train_data):\n",
    "    return data[data.date == date]\n",
    "\n",
    "\n",
    "def get_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).km\n",
    "\n",
    "def analyize_matches(y_true, y_pred):\n",
    "    print(\"Exact matches: \", sum(y_true == y_pred) / len(y_true))\n",
    "    \n",
    "    print(\"Missed by 1: \", sum(abs(y_true - y_pred) == 1) / len(y_true))\n",
    "    print(\"Missed by 2: \", sum(abs(y_true - y_pred) == 2) / len(y_true))\n",
    "    print(\"Missed by 3: \", sum(abs(y_true - y_pred) == 3) / len(y_true))\n",
    "    print(\"Missed by 4: \", sum(abs(y_true - y_pred) == 4) / len(y_true))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Guess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Get a sample and try to guess it's severity based on location, region, date, season, month.\n",
    "\n",
    "> Trail 1:\n",
    "\n",
    "    1. Get a test/val sample\n",
    "\n",
    "    2. Get subset of train data from the sample's date and region.\n",
    "        2.1 if subset is empty, get subset of train data from the sample's previous date and region.\n",
    "        2.2. if stil the subset is empty, fill the severity with 2.\n",
    "    \n",
    "    3. Get the nearest sample from the subset and use it's severity as the guess.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>howw</td>\n",
       "      <td>37.0062</td>\n",
       "      <td>-120.600</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>test</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>eamn</td>\n",
       "      <td>36.9818</td>\n",
       "      <td>-120.221</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>test</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668</th>\n",
       "      <td>imsv</td>\n",
       "      <td>36.9836</td>\n",
       "      <td>-120.500</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>test</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20182</th>\n",
       "      <td>wgxq</td>\n",
       "      <td>33.8011</td>\n",
       "      <td>-117.205</td>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>test</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16095</th>\n",
       "      <td>rsos</td>\n",
       "      <td>33.8892</td>\n",
       "      <td>-117.562</td>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>test</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>nsoi</td>\n",
       "      <td>36.7368</td>\n",
       "      <td>-121.734</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14254</th>\n",
       "      <td>prfi</td>\n",
       "      <td>36.7518</td>\n",
       "      <td>-121.742</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>howu</td>\n",
       "      <td>36.7085</td>\n",
       "      <td>-121.749</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>hfvr</td>\n",
       "      <td>36.7962</td>\n",
       "      <td>-121.782</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17559</th>\n",
       "      <td>thki</td>\n",
       "      <td>36.7254</td>\n",
       "      <td>-121.730</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6510 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid  latitude  longitude       date split  year  month  week  season  \\\n",
       "6865   howw   37.0062   -120.600 2013-01-08  test  2013      1     2       1   \n",
       "3661   eamn   36.9818   -120.221 2013-01-08  test  2013      1     2       1   \n",
       "7668   imsv   36.9836   -120.500 2013-01-08  test  2013      1     2       1   \n",
       "20182  wgxq   33.8011   -117.205 2013-01-25  test  2013      1     4       1   \n",
       "16095  rsos   33.8892   -117.562 2013-01-25  test  2013      1     4       1   \n",
       "...     ...       ...        ...        ...   ...   ...    ...   ...     ...   \n",
       "12443  nsoi   36.7368   -121.734 2021-12-29  test  2021     12    52       1   \n",
       "14254  prfi   36.7518   -121.742 2021-12-29  test  2021     12    52       1   \n",
       "6864   howu   36.7085   -121.749 2021-12-29  test  2021     12    52       1   \n",
       "6540   hfvr   36.7962   -121.782 2021-12-29  test  2021     12    52       1   \n",
       "17559  thki   36.7254   -121.730 2021-12-29  test  2021     12    52       1   \n",
       "\n",
       "      region  severity  density  \n",
       "6865    west       NaN      NaN  \n",
       "3661    west       NaN      NaN  \n",
       "7668    west       NaN      NaN  \n",
       "20182   west       NaN      NaN  \n",
       "16095   west       NaN      NaN  \n",
       "...      ...       ...      ...  \n",
       "12443   west       NaN      NaN  \n",
       "14254   west       NaN      NaN  \n",
       "6864    west       NaN      NaN  \n",
       "6540    west       NaN      NaN  \n",
       "17559   west       NaN      NaN  \n",
       "\n",
       "[6510 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_data = test_data.sort_values(by='date')\n",
    "te_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14501, 12), (2559, 12))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data, val_data = train_test_split(train_data, test_size=0.15, random_state=144, shuffle=True)\n",
    "tr_data.shape, val_data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guess Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_2s = []\n",
    "g_from_past = {}\n",
    "\n",
    "n_times_called = {}\n",
    "\n",
    "def make_guess1(row: pd.Series, date=None, tr_data=tr_data) -> pd.Series:\n",
    "\n",
    "    dists = []\n",
    "    region = row.region\n",
    "    date = date\n",
    "    uid = row.uid\n",
    "    tr_data = tr_data\n",
    "\n",
    "    if date is None:\n",
    "        date = row.date\n",
    "\n",
    "    rel_data = tr_data[(tr_data.date == date) & (tr_data.region == region)]\n",
    "    \n",
    "    # check if cur date is past '2013-01-04'\n",
    "    if date < pd.to_datetime('2013-01-04'):\n",
    "        print(f'No previous data for this date filling in 2s .. for {row.uid}')\n",
    "        fill_2s.append(uid)\n",
    "        return 2\n",
    "\n",
    "    if rel_data.shape[0] == 0:\n",
    "        # print(f'No data for this date, trying previous day.. for {row.uid}')\n",
    "        if g_from_past.get(uid) is not None:\n",
    "            g_from_past[uid] += 1\n",
    "        return make_guess1(row, date=date - pd.Timedelta(days=1), tr_data=tr_data)\n",
    "\n",
    "    for some_row in rel_data.itertuples():\n",
    "        dist = get_distance(row.latitude, row.longitude, some_row.latitude, some_row.longitude)\n",
    "        dists.append(dist)\n",
    "    \n",
    "    nearest = rel_data.iloc[np.argmin(dists)]\n",
    "    return nearest.severity\n",
    "\n",
    "\n",
    "def make_guess2(row: pd.Series, date=None, tr_data=tr_data, n_times_called=None) -> pd.Series:\n",
    "    \"\"\"modified version of make_guess1, Uses mean/mode of severity for the region instead of nearest severity.\"\"\"\n",
    "    dists = []\n",
    "    region = row.region\n",
    "    date = date\n",
    "    uid = row.uid\n",
    "    tr_data = tr_data\n",
    "    \n",
    "    if n_times_called is not None:\n",
    "        if n_times_called.get(uid) is None:\n",
    "            n_times_called[uid] = 1\n",
    "        else:\n",
    "            n_times_called[uid] += 1\n",
    "        \n",
    "\n",
    "    if date is None:\n",
    "        date = row.date\n",
    "\n",
    "    rel_data = tr_data[(tr_data.date == date) & (tr_data.region == region)]\n",
    "    \n",
    "    # check if cur date is past '2013-01-04'\n",
    "    if date < pd.to_datetime('2013-01-04'):\n",
    "        print(f'No previous data for this date filling in 2s .. for {row.uid}')\n",
    "        fill_2s.append(uid)\n",
    "        return 2\n",
    "\n",
    "    if rel_data.shape[0] == 0:\n",
    "        # print(f'No data for this date, trying previous day.. for {row.uid}')\n",
    "        if g_from_past.get(uid) is not None:\n",
    "            g_from_past[uid] += 1\n",
    "        global count \n",
    "        count += 1\n",
    "        return make_guess2(row, date=date - pd.Timedelta(days=1), tr_data=tr_data)\n",
    "\n",
    "    severty_mode = rel_data.severity.mode()[0]\n",
    "    severty_mean = np.round(rel_data.severity.mean())\n",
    "\n",
    "    return severty_mean\n",
    "\n",
    "\n",
    "\n",
    "def cv_loop(rand, splits=10, guess_func=make_guess1):\n",
    "    # print(\"Random Number: \", rand)\n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=rand)\n",
    "    tscv = TimeSeriesSplit(n_splits=splits)\n",
    "    rmses = []\n",
    "    guess_train_preds = np.zeros((train_data.shape[0]))\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(train_data, train_data.severity)):\n",
    "        print(f\"Fold: {fold}\")\n",
    "        tr_data, val_data = train_data.iloc[train_idx], train_data.iloc[val_idx]\n",
    "\n",
    "        val_data['guess1'] = 0\n",
    "\n",
    "        temp = []\n",
    "        for row in tqdm(val_data.itertuples(), total=val_data.shape[0]):\n",
    "            uid_series = val_data[val_data.uid == row.uid]\n",
    "            severity = guess_func(uid_series.iloc[0], date=row.date, tr_data=tr_data)\n",
    "            val_data.loc[val_data.uid == row.uid, f'guess1'] = severity\n",
    "            temp.append(severity)\n",
    "        \n",
    "        guess_train_preds[val_idx] = temp\n",
    "        \n",
    "\n",
    "                \n",
    "        errror = rmse(val_data.severity, val_data.guess1)\n",
    "        rmses.append(errror)\n",
    "        print(\"RMSE: \", errror)\n",
    "\n",
    "        print('Train Distribution: ')\n",
    "        print(tr_data.severity.value_counts(normalize=True))\n",
    "        print('Val Distribution: ')\n",
    "        print(val_data.severity.value_counts(normalize=True))\n",
    "        print('Predicted Distribution: ')\n",
    "        print(val_data.guess1.value_counts(normalize=True))\n",
    "\n",
    "    \n",
    "    print('----------------------------------------------------')\n",
    "\n",
    "    return rmses, guess_train_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data.sort_values(by='date', inplace=True)\n",
    "val_data.sort_values(by='date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>evep</td>\n",
       "      <td>44.847993</td>\n",
       "      <td>-93.476318</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>guny</td>\n",
       "      <td>44.878889</td>\n",
       "      <td>-93.490833</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5317</th>\n",
       "      <td>fwbt</td>\n",
       "      <td>44.850500</td>\n",
       "      <td>-93.515700</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13283</th>\n",
       "      <td>oqcg</td>\n",
       "      <td>37.114500</td>\n",
       "      <td>-120.890000</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4500000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13827</th>\n",
       "      <td>pfly</td>\n",
       "      <td>37.803400</td>\n",
       "      <td>-120.841000</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2881767.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6718</th>\n",
       "      <td>hkvs</td>\n",
       "      <td>36.030000</td>\n",
       "      <td>-78.706429</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>south</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14516</th>\n",
       "      <td>pykd</td>\n",
       "      <td>36.030000</td>\n",
       "      <td>-78.706927</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>south</td>\n",
       "      <td>2.0</td>\n",
       "      <td>51737.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17778</th>\n",
       "      <td>tobi</td>\n",
       "      <td>36.030000</td>\n",
       "      <td>-78.705932</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23159</th>\n",
       "      <td>zoaj</td>\n",
       "      <td>36.060000</td>\n",
       "      <td>-78.760000</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>south</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>ertx</td>\n",
       "      <td>35.980000</td>\n",
       "      <td>-78.843387</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1660.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14501 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid   latitude   longitude       date  split  year  month  week  \\\n",
       "4387   evep  44.847993  -93.476318 2013-01-04  train  2013      1     1   \n",
       "6144   guny  44.878889  -93.490833 2013-01-04  train  2013      1     1   \n",
       "5317   fwbt  44.850500  -93.515700 2013-01-04  train  2013      1     1   \n",
       "13283  oqcg  37.114500 -120.890000 2013-01-08  train  2013      1     2   \n",
       "13827  pfly  37.803400 -120.841000 2013-01-08  train  2013      1     2   \n",
       "...     ...        ...         ...        ...    ...   ...    ...   ...   \n",
       "6718   hkvs  36.030000  -78.706429 2021-12-14  train  2021     12    50   \n",
       "14516  pykd  36.030000  -78.706927 2021-12-14  train  2021     12    50   \n",
       "17778  tobi  36.030000  -78.705932 2021-12-14  train  2021     12    50   \n",
       "23159  zoaj  36.060000  -78.760000 2021-12-14  train  2021     12    50   \n",
       "4265   ertx  35.980000  -78.843387 2021-12-14  train  2021     12    50   \n",
       "\n",
       "       season   region  severity    density  \n",
       "4387        1  midwest       1.0      115.0  \n",
       "6144        1  midwest       1.0      558.0  \n",
       "5317        1  midwest       1.0      476.0  \n",
       "13283       1     west       4.0  4500000.0  \n",
       "13827       1     west       4.0  2881767.5  \n",
       "...       ...      ...       ...        ...  \n",
       "6718        1    south       2.0    31769.0  \n",
       "14516       1    south       2.0    51737.0  \n",
       "17778       1    south       1.0     4357.0  \n",
       "23159       1    south       2.0    48233.0  \n",
       "4265        1    south       1.0     1660.0  \n",
       "\n",
       "[14501 rows x 12 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "      <th>guess</th>\n",
       "      <th>guess2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13644</th>\n",
       "      <td>paev</td>\n",
       "      <td>44.822478</td>\n",
       "      <td>-93.367962</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>gdxr</td>\n",
       "      <td>44.877646</td>\n",
       "      <td>-93.557842</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>bgwz</td>\n",
       "      <td>37.413900</td>\n",
       "      <td>-121.014000</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3740000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16227</th>\n",
       "      <td>rwkd</td>\n",
       "      <td>38.115600</td>\n",
       "      <td>-121.494000</td>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1745249.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13719</th>\n",
       "      <td>pceh</td>\n",
       "      <td>37.967400</td>\n",
       "      <td>-121.464000</td>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>3.0</td>\n",
       "      <td>985182.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6435</th>\n",
       "      <td>hdjp</td>\n",
       "      <td>35.686281</td>\n",
       "      <td>-79.200202</td>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9958.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>aqae</td>\n",
       "      <td>35.658149</td>\n",
       "      <td>-79.252453</td>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15266</th>\n",
       "      <td>quux</td>\n",
       "      <td>35.877009</td>\n",
       "      <td>-78.893845</td>\n",
       "      <td>2021-12-02</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16980.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5806</th>\n",
       "      <td>gkeq</td>\n",
       "      <td>37.263900</td>\n",
       "      <td>-120.906000</td>\n",
       "      <td>2021-12-13</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6797500.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22641</th>\n",
       "      <td>yyvh</td>\n",
       "      <td>35.980000</td>\n",
       "      <td>-78.843138</td>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2559 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid   latitude   longitude       date  split  year  month  week  \\\n",
       "13644  paev  44.822478  -93.367962 2013-01-04  train  2013      1     1   \n",
       "5566   gdxr  44.877646  -93.557842 2013-01-04  train  2013      1     1   \n",
       "1126   bgwz  37.413900 -121.014000 2013-01-08  train  2013      1     2   \n",
       "16227  rwkd  38.115600 -121.494000 2013-01-15  train  2013      1     3   \n",
       "13719  pceh  37.967400 -121.464000 2013-01-15  train  2013      1     3   \n",
       "...     ...        ...         ...        ...    ...   ...    ...   ...   \n",
       "6435   hdjp  35.686281  -79.200202 2021-12-02  train  2021     12    48   \n",
       "549    aqae  35.658149  -79.252453 2021-12-02  train  2021     12    48   \n",
       "15266  quux  35.877009  -78.893845 2021-12-02  train  2021     12    48   \n",
       "5806   gkeq  37.263900 -120.906000 2021-12-13  train  2021     12    50   \n",
       "22641  yyvh  35.980000  -78.843138 2021-12-14  train  2021     12    50   \n",
       "\n",
       "       season   region  severity    density  guess  guess2  \n",
       "13644       1  midwest       1.0     1884.0    1.0     1.0  \n",
       "5566        1  midwest       1.0     1416.0    1.0     1.0  \n",
       "1126        1     west       4.0  3740000.0    3.0     4.0  \n",
       "16227       1     west       4.0  1745249.0    3.0     4.0  \n",
       "13719       1     west       3.0   985182.0    3.0     4.0  \n",
       "...       ...      ...       ...        ...    ...     ...  \n",
       "6435        1    south       1.0     9958.0    1.0     2.0  \n",
       "549         1    south       1.0      290.0    1.0     2.0  \n",
       "15266       1    south       1.0    16980.0    1.0     2.0  \n",
       "5806        1     west       4.0  6797500.0    4.0     4.0  \n",
       "22641       1    south       1.0     1660.0    1.0     2.0  \n",
       "\n",
       "[2559 rows x 14 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2559/2559 [00:42<00:00, 60.57it/s] \n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(val_data.itertuples(), total=val_data.shape[0]):\n",
    "    val_data.loc[row.Index, 'guess'] = make_guess1(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8548416232611225"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(val_data.severity, val_data.guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches:  0.6053145760062525\n",
      "Missed by 1:  0.3028526768268855\n",
      "Missed by 2:  0.08245408362641657\n",
      "Missed by 3:  0.008206330597889801\n",
      "Missed by 4:  0.0011723329425556857\n"
     ]
    }
   ],
   "source": [
    "analyize_matches(val_data.severity, val_data.guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.08284486127393513 + 0.008206330597889801 + 0.0011723329425556857\n",
    "# 91% preds < 1 offs, 99% preds < 2 offs, 88% preds == 2 offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "      <th>guess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>bgwz</td>\n",
       "      <td>37.413900</td>\n",
       "      <td>-121.014000</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.740000e+06</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16227</th>\n",
       "      <td>rwkd</td>\n",
       "      <td>38.115600</td>\n",
       "      <td>-121.494000</td>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.745249e+06</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>bils</td>\n",
       "      <td>35.658042</td>\n",
       "      <td>-79.252651</td>\n",
       "      <td>2013-01-29</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>south</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.184600e+04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>ascv</td>\n",
       "      <td>35.794000</td>\n",
       "      <td>-79.004000</td>\n",
       "      <td>2013-02-12</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>south</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.664900e+04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19900</th>\n",
       "      <td>vyle</td>\n",
       "      <td>32.384010</td>\n",
       "      <td>-104.145830</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>west</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.182287e+04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8249</th>\n",
       "      <td>jdhb</td>\n",
       "      <td>39.077955</td>\n",
       "      <td>-96.880810</td>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>midwest</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.326020e+05</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12915</th>\n",
       "      <td>ofvy</td>\n",
       "      <td>37.782398</td>\n",
       "      <td>-97.531050</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>midwest</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.587410e+05</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>aljv</td>\n",
       "      <td>39.211550</td>\n",
       "      <td>-97.005590</td>\n",
       "      <td>2021-10-11</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>midwest</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.590030e+05</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>klbq</td>\n",
       "      <td>35.876636</td>\n",
       "      <td>-78.890862</td>\n",
       "      <td>2021-10-12</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>south</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.703900e+04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>htek</td>\n",
       "      <td>35.790000</td>\n",
       "      <td>-79.037960</td>\n",
       "      <td>2021-10-12</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>south</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.485500e+04</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>377 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid   latitude   longitude       date  split  year  month  week  \\\n",
       "1126   bgwz  37.413900 -121.014000 2013-01-08  train  2013      1     2   \n",
       "16227  rwkd  38.115600 -121.494000 2013-01-15  train  2013      1     3   \n",
       "1178   bils  35.658042  -79.252651 2013-01-29  train  2013      1     5   \n",
       "629    ascv  35.794000  -79.004000 2013-02-12  train  2013      2     7   \n",
       "19900  vyle  32.384010 -104.145830 2013-03-28  train  2013      3    13   \n",
       "...     ...        ...         ...        ...    ...   ...    ...   ...   \n",
       "8249   jdhb  39.077955  -96.880810 2021-09-20  train  2021      9    38   \n",
       "12915  ofvy  37.782398  -97.531050 2021-10-04  train  2021     10    40   \n",
       "376    aljv  39.211550  -97.005590 2021-10-11  train  2021     10    41   \n",
       "9495   klbq  35.876636  -78.890862 2021-10-12  train  2021     10    41   \n",
       "6995   htek  35.790000  -79.037960 2021-10-12  train  2021     10    41   \n",
       "\n",
       "       season   region  severity       density  guess  \n",
       "1126        1     west       4.0  3.740000e+06    3.0  \n",
       "16227       1     west       4.0  1.745249e+06    3.0  \n",
       "1178        1    south       2.0  5.184600e+04    1.0  \n",
       "629         1    south       2.0  3.664900e+04    1.0  \n",
       "19900       2     west       2.0  2.182287e+04    1.0  \n",
       "...       ...      ...       ...           ...    ...  \n",
       "8249        4  midwest       3.0  4.326020e+05    2.0  \n",
       "12915       4  midwest       3.0  1.587410e+05    2.0  \n",
       "376         4  midwest       3.0  1.590030e+05    2.0  \n",
       "9495        4    south       2.0  9.703900e+04    1.0  \n",
       "6995        4    south       2.0  3.485500e+04    1.0  \n",
       "\n",
       "[377 rows x 13 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the samples missing by 1\n",
    "\n",
    "val_data[val_data.severity - val_data.guess == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "      <th>guess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>bgwz</td>\n",
       "      <td>37.4139</td>\n",
       "      <td>-121.014</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3740000.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid  latitude  longitude       date  split  year  month  week  season  \\\n",
       "1126  bgwz   37.4139   -121.014 2013-01-08  train  2013      1     2       1   \n",
       "\n",
       "     region  severity    density  guess  \n",
       "1126   west       4.0  3740000.0    3.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[val_data.uid == 'bgwz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14259</th>\n",
       "      <td>prgf</td>\n",
       "      <td>37.4918</td>\n",
       "      <td>-120.684</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4529556.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>cizy</td>\n",
       "      <td>37.1366</td>\n",
       "      <td>-120.762</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4482500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13499</th>\n",
       "      <td>owaj</td>\n",
       "      <td>37.3772</td>\n",
       "      <td>-121.058</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3755000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10819</th>\n",
       "      <td>lwjc</td>\n",
       "      <td>37.5150</td>\n",
       "      <td>-121.012</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1054871.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13840</th>\n",
       "      <td>pfsh</td>\n",
       "      <td>37.4419</td>\n",
       "      <td>-121.003</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>3.0</td>\n",
       "      <td>136538.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5172</th>\n",
       "      <td>fryq</td>\n",
       "      <td>37.2583</td>\n",
       "      <td>-120.475</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4135845.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9919</th>\n",
       "      <td>kwua</td>\n",
       "      <td>37.6003</td>\n",
       "      <td>-121.224</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>2.0</td>\n",
       "      <td>86350.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>cqge</td>\n",
       "      <td>37.1976</td>\n",
       "      <td>-120.488</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3324651.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20554</th>\n",
       "      <td>wrxx</td>\n",
       "      <td>37.3133</td>\n",
       "      <td>-120.892</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4070390.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16589</th>\n",
       "      <td>sgtc</td>\n",
       "      <td>37.3204</td>\n",
       "      <td>-120.983</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4027500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>jalu</td>\n",
       "      <td>37.2764</td>\n",
       "      <td>-120.954</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5187500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>cnsa</td>\n",
       "      <td>37.4806</td>\n",
       "      <td>-121.031</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3617736.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15663</th>\n",
       "      <td>rgbz</td>\n",
       "      <td>37.3041</td>\n",
       "      <td>-120.901</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5100000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20604</th>\n",
       "      <td>wtlv</td>\n",
       "      <td>37.2616</td>\n",
       "      <td>-120.906</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4882500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10515</th>\n",
       "      <td>lnth</td>\n",
       "      <td>37.2486</td>\n",
       "      <td>-120.851</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4732500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19257</th>\n",
       "      <td>vfgn</td>\n",
       "      <td>37.2953</td>\n",
       "      <td>-120.850</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4265000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13827</th>\n",
       "      <td>pfly</td>\n",
       "      <td>37.8034</td>\n",
       "      <td>-120.841</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2881767.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13283</th>\n",
       "      <td>oqcg</td>\n",
       "      <td>37.1145</td>\n",
       "      <td>-120.890</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4500000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid  latitude  longitude       date  split  year  month  week  season  \\\n",
       "14259  prgf   37.4918   -120.684 2013-01-08  train  2013      1     2       1   \n",
       "2107   cizy   37.1366   -120.762 2013-01-08  train  2013      1     2       1   \n",
       "13499  owaj   37.3772   -121.058 2013-01-08  train  2013      1     2       1   \n",
       "10819  lwjc   37.5150   -121.012 2013-01-08  train  2013      1     2       1   \n",
       "13840  pfsh   37.4419   -121.003 2013-01-08  train  2013      1     2       1   \n",
       "5172   fryq   37.2583   -120.475 2013-01-08  train  2013      1     2       1   \n",
       "9919   kwua   37.6003   -121.224 2013-01-08  train  2013      1     2       1   \n",
       "2366   cqge   37.1976   -120.488 2013-01-08  train  2013      1     2       1   \n",
       "20554  wrxx   37.3133   -120.892 2013-01-08  train  2013      1     2       1   \n",
       "16589  sgtc   37.3204   -120.983 2013-01-08  train  2013      1     2       1   \n",
       "8158   jalu   37.2764   -120.954 2013-01-08  train  2013      1     2       1   \n",
       "2261   cnsa   37.4806   -121.031 2013-01-08  train  2013      1     2       1   \n",
       "15663  rgbz   37.3041   -120.901 2013-01-08  train  2013      1     2       1   \n",
       "20604  wtlv   37.2616   -120.906 2013-01-08  train  2013      1     2       1   \n",
       "10515  lnth   37.2486   -120.851 2013-01-08  train  2013      1     2       1   \n",
       "19257  vfgn   37.2953   -120.850 2013-01-08  train  2013      1     2       1   \n",
       "13827  pfly   37.8034   -120.841 2013-01-08  train  2013      1     2       1   \n",
       "13283  oqcg   37.1145   -120.890 2013-01-08  train  2013      1     2       1   \n",
       "\n",
       "      region  severity     density  \n",
       "14259   west       4.0  4529556.50  \n",
       "2107    west       4.0  4482500.00  \n",
       "13499   west       4.0  3755000.00  \n",
       "10819   west       4.0  1054871.00  \n",
       "13840   west       3.0   136538.00  \n",
       "5172    west       4.0  4135845.75  \n",
       "9919    west       2.0    86350.00  \n",
       "2366    west       4.0  3324651.50  \n",
       "20554   west       4.0  4070390.00  \n",
       "16589   west       4.0  4027500.00  \n",
       "8158    west       4.0  5187500.00  \n",
       "2261    west       4.0  3617736.50  \n",
       "15663   west       4.0  5100000.00  \n",
       "20604   west       4.0  4882500.00  \n",
       "10515   west       4.0  4732500.00  \n",
       "19257   west       4.0  4265000.00  \n",
       "13827   west       4.0  2881767.50  \n",
       "13283   west       4.0  4500000.00  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_data = tr_data[tr_data.date == '2013-01-08']\n",
    "some_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see bgwz\n",
    "\n",
    "make_guess1(val_data[val_data.uid == 'bgwz'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = []\n",
    "for some_row in some_data.itertuples():\n",
    "        dist = get_distance(37.4139, -121.014, some_row.latitude, some_row.longitude)\n",
    "        dists.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uid                         pfsh\n",
       "latitude                 37.4419\n",
       "longitude               -121.003\n",
       "date         2013-01-08 00:00:00\n",
       "split                      train\n",
       "year                        2013\n",
       "month                          1\n",
       "week                           2\n",
       "season                         1\n",
       "region                      west\n",
       "severity                     3.0\n",
       "density                 136538.0\n",
       "Name: 13840, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_data.iloc[np.argmin(dists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observations:\n",
    "\n",
    "#  In this case the closest one is 3, but the actual value is 4\n",
    "#  I guess it is far better if we search for the same location in the past or try mode of the region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "      <th>guess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10194</th>\n",
       "      <td>leit</td>\n",
       "      <td>35.657803</td>\n",
       "      <td>-79.253096</td>\n",
       "      <td>2013-03-13</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>3.0</td>\n",
       "      <td>517495.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12916</th>\n",
       "      <td>ofxt</td>\n",
       "      <td>35.976000</td>\n",
       "      <td>-78.712644</td>\n",
       "      <td>2013-05-14</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>3.0</td>\n",
       "      <td>258059.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12054</th>\n",
       "      <td>nhaw</td>\n",
       "      <td>35.859897</td>\n",
       "      <td>-78.756888</td>\n",
       "      <td>2013-06-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>south</td>\n",
       "      <td>3.0</td>\n",
       "      <td>121991.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>dbwj</td>\n",
       "      <td>39.628330</td>\n",
       "      <td>-99.580000</td>\n",
       "      <td>2013-06-24</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1204875.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9775</th>\n",
       "      <td>ktdj</td>\n",
       "      <td>36.177000</td>\n",
       "      <td>-79.053877</td>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>south</td>\n",
       "      <td>3.0</td>\n",
       "      <td>613345.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14082</th>\n",
       "      <td>pmwk</td>\n",
       "      <td>35.892413</td>\n",
       "      <td>-79.017132</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>south</td>\n",
       "      <td>3.0</td>\n",
       "      <td>445365.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23233</th>\n",
       "      <td>zqbi</td>\n",
       "      <td>35.790000</td>\n",
       "      <td>-79.037119</td>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>south</td>\n",
       "      <td>3.0</td>\n",
       "      <td>117925.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>cnei</td>\n",
       "      <td>41.550878</td>\n",
       "      <td>-86.361626</td>\n",
       "      <td>2021-08-30</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1694159.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11467</th>\n",
       "      <td>mpss</td>\n",
       "      <td>37.746680</td>\n",
       "      <td>-97.779360</td>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>midwest</td>\n",
       "      <td>3.0</td>\n",
       "      <td>136045.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3808</th>\n",
       "      <td>eenf</td>\n",
       "      <td>35.980000</td>\n",
       "      <td>-78.842641</td>\n",
       "      <td>2021-11-18</td>\n",
       "      <td>train</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>south</td>\n",
       "      <td>3.0</td>\n",
       "      <td>274481.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid   latitude  longitude       date  split  year  month  week  \\\n",
       "10194  leit  35.657803 -79.253096 2013-03-13  train  2013      3    11   \n",
       "12916  ofxt  35.976000 -78.712644 2013-05-14  train  2013      5    20   \n",
       "12054  nhaw  35.859897 -78.756888 2013-06-04  train  2013      6    23   \n",
       "2778   dbwj  39.628330 -99.580000 2013-06-24  train  2013      6    26   \n",
       "9775   ktdj  36.177000 -79.053877 2013-06-26  train  2013      6    26   \n",
       "...     ...        ...        ...        ...    ...   ...    ...   ...   \n",
       "14082  pmwk  35.892413 -79.017132 2021-07-12  train  2021      7    28   \n",
       "23233  zqbi  35.790000 -79.037119 2021-07-12  train  2021      7    28   \n",
       "2241   cnei  41.550878 -86.361626 2021-08-30  train  2021      8    35   \n",
       "11467  mpss  37.746680 -97.779360 2021-09-13  train  2021      9    37   \n",
       "3808   eenf  35.980000 -78.842641 2021-11-18  train  2021     11    46   \n",
       "\n",
       "       season   region  severity    density  guess  \n",
       "10194       2    south       3.0   517495.0    1.0  \n",
       "12916       2    south       3.0   258059.0    1.0  \n",
       "12054       3    south       3.0   121991.0    1.0  \n",
       "2778        3  midwest       4.0  1204875.0    2.0  \n",
       "9775        3    south       3.0   613345.0    1.0  \n",
       "...       ...      ...       ...        ...    ...  \n",
       "14082       3    south       3.0   445365.0    1.0  \n",
       "23233       3    south       3.0   117925.0    1.0  \n",
       "2241        3  midwest       4.0  1694159.0    2.0  \n",
       "11467       4  midwest       3.0   136045.0    1.0  \n",
       "3808        4    south       3.0   274481.0    1.0  \n",
       "\n",
       "[100 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the samples missing by 2\n",
    "\n",
    "val_data[val_data.severity - val_data.guess == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_guess1(val_data[val_data.uid == 'leit'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>etfx</td>\n",
       "      <td>35.701531</td>\n",
       "      <td>-79.171876</td>\n",
       "      <td>2013-03-13</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7443</th>\n",
       "      <td>igat</td>\n",
       "      <td>35.910270</td>\n",
       "      <td>-79.160055</td>\n",
       "      <td>2013-03-13</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20379</th>\n",
       "      <td>wndy</td>\n",
       "      <td>35.910208</td>\n",
       "      <td>-79.159558</td>\n",
       "      <td>2013-03-13</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>ayfy</td>\n",
       "      <td>35.701504</td>\n",
       "      <td>-79.171926</td>\n",
       "      <td>2013-03-13</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4197</th>\n",
       "      <td>eqdu</td>\n",
       "      <td>35.657883</td>\n",
       "      <td>-79.252948</td>\n",
       "      <td>2013-03-13</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8679</th>\n",
       "      <td>jpte</td>\n",
       "      <td>35.794000</td>\n",
       "      <td>-79.004000</td>\n",
       "      <td>2013-03-13</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>3.0</td>\n",
       "      <td>193734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154</th>\n",
       "      <td>vcho</td>\n",
       "      <td>35.859275</td>\n",
       "      <td>-78.751916</td>\n",
       "      <td>2013-03-13</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>871.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15152</th>\n",
       "      <td>qrhs</td>\n",
       "      <td>35.859306</td>\n",
       "      <td>-78.752165</td>\n",
       "      <td>2013-03-13</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2324.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18806</th>\n",
       "      <td>usoo</td>\n",
       "      <td>35.910301</td>\n",
       "      <td>-79.160303</td>\n",
       "      <td>2013-03-13</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9159.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid   latitude  longitude       date  split  year  month  week  \\\n",
       "4319   etfx  35.701531 -79.171876 2013-03-13  train  2013      3    11   \n",
       "7443   igat  35.910270 -79.160055 2013-03-13  train  2013      3    11   \n",
       "20379  wndy  35.910208 -79.159558 2013-03-13  train  2013      3    11   \n",
       "831    ayfy  35.701504 -79.171926 2013-03-13  train  2013      3    11   \n",
       "4197   eqdu  35.657883 -79.252948 2013-03-13  train  2013      3    11   \n",
       "8679   jpte  35.794000 -79.004000 2013-03-13  train  2013      3    11   \n",
       "19154  vcho  35.859275 -78.751916 2013-03-13  train  2013      3    11   \n",
       "15152  qrhs  35.859306 -78.752165 2013-03-13  train  2013      3    11   \n",
       "18806  usoo  35.910301 -79.160303 2013-03-13  train  2013      3    11   \n",
       "\n",
       "       season region  severity   density  \n",
       "4319        2  south       1.0    1017.0  \n",
       "7443        2  south       1.0    3970.0  \n",
       "20379       2  south       1.0   11909.0  \n",
       "831         2  south       1.0     218.0  \n",
       "4197        2  south       1.0     581.0  \n",
       "8679        2  south       3.0  193734.0  \n",
       "19154       2  south       1.0     871.0  \n",
       "15152       2  south       1.0    2324.0  \n",
       "18806       2  south       1.0    9159.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leit_date = '2013-03-13'\n",
    "\n",
    "leit_data = tr_data[tr_data.date == leit_date]\n",
    "leit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = []\n",
    "for some_row in some_data.itertuples():\n",
    "        dist = get_distance(37.4139, -121.014, some_row.latitude, some_row.longitude)\n",
    "        dists.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With guess2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_calls = {}\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 133/2559 [00:00<00:05, 467.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for vyle\n",
      "No data for this date, trying previous day.. for veuv\n",
      "No data for this date, trying previous day.. for zxjy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 180/2559 [00:00<00:05, 465.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for xdtz\n",
      "No data for this date, trying previous day.. for xdtz\n",
      "No data for this date, trying previous day.. for xdtz\n",
      "No data for this date, trying previous day.. for xdtz\n",
      "No data for this date, trying previous day.. for xdtz\n",
      "No data for this date, trying previous day.. for xdtz\n",
      "No data for this date, trying previous day.. for xdtz\n",
      "No data for this date, trying previous day.. for xdtz\n",
      "No data for this date, trying previous day.. for kxjx\n",
      "No data for this date, trying previous day.. for kxjx\n",
      "No data for this date, trying previous day.. for kxjx\n",
      "No data for this date, trying previous day.. for kxjx\n",
      "No data for this date, trying previous day.. for kxjx\n",
      "No data for this date, trying previous day.. for kxjx\n",
      "No data for this date, trying previous day.. for kxjx\n",
      "No data for this date, trying previous day.. for hkyf\n",
      "No data for this date, trying previous day.. for hkyf\n",
      "No data for this date, trying previous day.. for hkyf\n",
      "No data for this date, trying previous day.. for hkyf\n",
      "No data for this date, trying previous day.. for hkyf\n",
      "No data for this date, trying previous day.. for hkyf\n",
      "No data for this date, trying previous day.. for hkyf\n",
      "No data for this date, trying previous day.. for rxor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 497/2559 [00:01<00:03, 532.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for msnp\n",
      "No data for this date, trying previous day.. for opci\n",
      "No data for this date, trying previous day.. for ltai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 604/2559 [00:01<00:04, 472.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for reah\n",
      "No data for this date, trying previous day.. for efgc\n",
      "No data for this date, trying previous day.. for efgc\n",
      "No data for this date, trying previous day.. for efgc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 763/2559 [00:01<00:03, 501.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for rbfi\n",
      "No data for this date, trying previous day.. for wqrh\n",
      "No data for this date, trying previous day.. for vmgb\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 814/2559 [00:01<00:06, 264.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for ipze\n",
      "No data for this date, trying previous day.. for krgi\n",
      "No data for this date, trying previous day.. for krgi\n",
      "No data for this date, trying previous day.. for krgi\n",
      "No data for this date, trying previous day.. for krgi\n",
      "No data for this date, trying previous day.. for krgi\n",
      "No data for this date, trying previous day.. for krgi\n",
      "No data for this date, trying previous day.. for krgi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 854/2559 [00:02<00:06, 274.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for kwhr\n",
      "No data for this date, trying previous day.. for kwhr\n",
      "No data for this date, trying previous day.. for kwhr\n",
      "No data for this date, trying previous day.. for kwhr\n",
      "No data for this date, trying previous day.. for kwhr\n",
      "No data for this date, trying previous day.. for kwhr\n",
      "No data for this date, trying previous day.. for kwhr\n",
      "No data for this date, trying previous day.. for kwhr\n",
      "No data for this date, trying previous day.. for kwhr\n",
      "No data for this date, trying previous day.. for kwhr\n",
      "No data for this date, trying previous day.. for kwhr\n",
      "No data for this date, trying previous day.. for kwhr\n",
      "No data for this date, trying previous day.. for kwhr\n",
      "No data for this date, trying previous day.. for kwhr\n",
      "No data for this date, trying previous day.. for wqqw\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n",
      "No data for this date, trying previous day.. for ckxf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 975/2559 [00:02<00:05, 312.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for gpzd\n",
      "No data for this date, trying previous day.. for gpzd\n",
      "No data for this date, trying previous day.. for gpzd\n",
      "No data for this date, trying previous day.. for gpzd\n",
      "No data for this date, trying previous day.. for gpzd\n",
      "No data for this date, trying previous day.. for gpzd\n",
      "No data for this date, trying previous day.. for gpzd\n",
      "No data for this date, trying previous day.. for gpzd\n",
      "No data for this date, trying previous day.. for gpzd\n",
      "No data for this date, trying previous day.. for gpzd\n",
      "No data for this date, trying previous day.. for gpzd\n",
      "No data for this date, trying previous day.. for gpzd\n",
      "No data for this date, trying previous day.. for gpzd\n",
      "No data for this date, trying previous day.. for gpzd\n",
      "No data for this date, trying previous day.. for poau\n",
      "No data for this date, trying previous day.. for qaqd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1067/2559 [00:02<00:04, 363.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for fqwk\n",
      "No data for this date, trying previous day.. for fqwk\n",
      "No data for this date, trying previous day.. for fqwk\n",
      "No data for this date, trying previous day.. for fqwk\n",
      "No data for this date, trying previous day.. for fqwk\n",
      "No data for this date, trying previous day.. for fqwk\n",
      "No data for this date, trying previous day.. for fqwk\n",
      "No data for this date, trying previous day.. for fqwk\n",
      "No data for this date, trying previous day.. for fqwk\n",
      "No data for this date, trying previous day.. for fqwk\n",
      "No data for this date, trying previous day.. for fqwk\n",
      "No data for this date, trying previous day.. for fqwk\n",
      "No data for this date, trying previous day.. for frrq\n",
      "No data for this date, trying previous day.. for frrq\n",
      "No data for this date, trying previous day.. for frrq\n",
      "No data for this date, trying previous day.. for frrq\n",
      "No data for this date, trying previous day.. for frrq\n",
      "No data for this date, trying previous day.. for frrq\n",
      "No data for this date, trying previous day.. for frrq\n",
      "No data for this date, trying previous day.. for vjei\n",
      "No data for this date, trying previous day.. for vjei\n",
      "No data for this date, trying previous day.. for vjei\n",
      "No data for this date, trying previous day.. for vjei\n",
      "No data for this date, trying previous day.. for vjei\n",
      "No data for this date, trying previous day.. for qfyy\n",
      "No data for this date, trying previous day.. for uieh\n",
      "No data for this date, trying previous day.. for xvlr\n",
      "No data for this date, trying previous day.. for xvlr\n",
      "No data for this date, trying previous day.. for xvlr\n",
      "No data for this date, trying previous day.. for xvlr\n",
      "No data for this date, trying previous day.. for xvlr\n",
      "No data for this date, trying previous day.. for xvlr\n",
      "No data for this date, trying previous day.. for xvlr\n",
      "No data for this date, trying previous day.. for xvlr\n",
      "No data for this date, trying previous day.. for xvlr\n",
      "No data for this date, trying previous day.. for xvlr\n",
      "No data for this date, trying previous day.. for xvlr\n",
      "No data for this date, trying previous day.. for xvlr\n",
      "No data for this date, trying previous day.. for xvlr\n",
      "No data for this date, trying previous day.. for hvus\n",
      "No data for this date, trying previous day.. for hvus\n",
      "No data for this date, trying previous day.. for hvus\n",
      "No data for this date, trying previous day.. for hvus\n",
      "No data for this date, trying previous day.. for hvus\n",
      "No data for this date, trying previous day.. for hvus\n",
      "No data for this date, trying previous day.. for hvus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1191/2559 [00:03<00:03, 371.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for zafy\n",
      "No data for this date, trying previous day.. for ygcr\n",
      "No data for this date, trying previous day.. for ygcr\n",
      "No data for this date, trying previous day.. for ygcr\n",
      "No data for this date, trying previous day.. for ygcr\n",
      "No data for this date, trying previous day.. for ygcr\n",
      "No data for this date, trying previous day.. for ygcr\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for ldgb\n",
      "No data for this date, trying previous day.. for fqlt\n",
      "No data for this date, trying previous day.. for fqlt\n",
      "No data for this date, trying previous day.. for fqlt\n",
      "No data for this date, trying previous day.. for fqlt\n",
      "No data for this date, trying previous day.. for fqlt\n",
      "No data for this date, trying previous day.. for fqlt\n",
      "No data for this date, trying previous day.. for fqlt\n",
      "No data for this date, trying previous day.. for zlxb\n",
      "No data for this date, trying previous day.. for zlxb\n",
      "No data for this date, trying previous day.. for zlxb\n",
      "No data for this date, trying previous day.. for zlxb\n",
      "No data for this date, trying previous day.. for zlxb\n",
      "No data for this date, trying previous day.. for zlxb\n",
      "No data for this date, trying previous day.. for zlxb\n",
      "No data for this date, trying previous day.. for zlxb\n",
      "No data for this date, trying previous day.. for wtgy\n",
      "No data for this date, trying previous day.. for vpsx\n",
      "No data for this date, trying previous day.. for vpsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1280/2559 [00:03<00:03, 402.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for abdk\n",
      "No data for this date, trying previous day.. for nute\n",
      "No data for this date, trying previous day.. for bbsi\n",
      "No data for this date, trying previous day.. for lmpf\n",
      "No data for this date, trying previous day.. for hevf\n",
      "No data for this date, trying previous day.. for mxos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1429/2559 [00:03<00:02, 453.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for ojaz\n",
      "No data for this date, trying previous day.. for jirh\n",
      "No data for this date, trying previous day.. for zqah\n",
      "No data for this date, trying previous day.. for wjjr\n",
      "No data for this date, trying previous day.. for xabs\n",
      "No data for this date, trying previous day.. for xabs\n",
      "No data for this date, trying previous day.. for xabs\n",
      "No data for this date, trying previous day.. for xabs\n",
      "No data for this date, trying previous day.. for mghh\n",
      "No data for this date, trying previous day.. for hefu\n",
      "No data for this date, trying previous day.. for hefu\n",
      "No data for this date, trying previous day.. for hefu\n",
      "No data for this date, trying previous day.. for hefu\n",
      "No data for this date, trying previous day.. for hefu\n",
      "No data for this date, trying previous day.. for hefu\n",
      "No data for this date, trying previous day.. for hefu\n",
      "No data for this date, trying previous day.. for hefu\n",
      "No data for this date, trying previous day.. for hefu\n",
      "No data for this date, trying previous day.. for hefu\n",
      "No data for this date, trying previous day.. for hefu\n",
      "No data for this date, trying previous day.. for hefu\n",
      "No data for this date, trying previous day.. for hefu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1582/2559 [00:03<00:01, 490.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for tkdo\n",
      "No data for this date, trying previous day.. for crcs\n",
      "No data for this date, trying previous day.. for crcs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1687/2559 [00:04<00:01, 469.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for bois\n",
      "No data for this date, trying previous day.. for xwpr\n",
      "No data for this date, trying previous day.. for uokp\n",
      "No data for this date, trying previous day.. for xvok\n",
      "No data for this date, trying previous day.. for xvok\n",
      "No data for this date, trying previous day.. for xvok\n",
      "No data for this date, trying previous day.. for xvok\n",
      "No data for this date, trying previous day.. for akcy\n",
      "No data for this date, trying previous day.. for yhdm\n",
      "No data for this date, trying previous day.. for xkff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1735/2559 [00:04<00:02, 403.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for dpre\n",
      "No data for this date, trying previous day.. for dpre\n",
      "No data for this date, trying previous day.. for dpre\n",
      "No data for this date, trying previous day.. for dpre\n",
      "No data for this date, trying previous day.. for dpre\n",
      "No data for this date, trying previous day.. for dpre\n",
      "No data for this date, trying previous day.. for dpre\n",
      "No data for this date, trying previous day.. for dpre\n",
      "No data for this date, trying previous day.. for dpre\n",
      "No data for this date, trying previous day.. for dpre\n",
      "No data for this date, trying previous day.. for dpre\n",
      "No data for this date, trying previous day.. for dpre\n",
      "No data for this date, trying previous day.. for dpre\n",
      "No data for this date, trying previous day.. for qbua\n",
      "No data for this date, trying previous day.. for qbua\n",
      "No data for this date, trying previous day.. for qbua\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for pptw\n",
      "No data for this date, trying previous day.. for nksl\n",
      "No data for this date, trying previous day.. for nksl\n",
      "No data for this date, trying previous day.. for nksl\n",
      "No data for this date, trying previous day.. for nksl\n",
      "No data for this date, trying previous day.. for nksl\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1816/2559 [00:04<00:02, 277.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for agqj\n",
      "No data for this date, trying previous day.. for frxr\n",
      "No data for this date, trying previous day.. for frxr\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1899/2559 [00:04<00:02, 314.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for egsc\n",
      "No data for this date, trying previous day.. for rfpi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1982/2559 [00:05<00:01, 356.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for iqvz\n",
      "No data for this date, trying previous day.. for iqvz\n",
      "No data for this date, trying previous day.. for iqvz\n",
      "No data for this date, trying previous day.. for iqvz\n",
      "No data for this date, trying previous day.. for iqvz\n",
      "No data for this date, trying previous day.. for iqvz\n",
      "No data for this date, trying previous day.. for iqvz\n",
      "No data for this date, trying previous day.. for qrsj\n",
      "No data for this date, trying previous day.. for qrsj\n",
      "No data for this date, trying previous day.. for qrsj\n",
      "No data for this date, trying previous day.. for oesj\n",
      "No data for this date, trying previous day.. for ylcj\n",
      "No data for this date, trying previous day.. for ylcj\n",
      "No data for this date, trying previous day.. for ylcj\n",
      "No data for this date, trying previous day.. for ylcj\n",
      "No data for this date, trying previous day.. for ylcj\n",
      "No data for this date, trying previous day.. for ylcj\n",
      "No data for this date, trying previous day.. for ylcj\n",
      "No data for this date, trying previous day.. for ylcj\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 2072/2559 [00:05<00:01, 401.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for copu\n",
      "No data for this date, trying previous day.. for copu\n",
      "No data for this date, trying previous day.. for copu\n",
      "No data for this date, trying previous day.. for copu\n",
      "No data for this date, trying previous day.. for copu\n",
      "No data for this date, trying previous day.. for cbnk\n",
      "No data for this date, trying previous day.. for cbnk\n",
      "No data for this date, trying previous day.. for cbnk\n",
      "No data for this date, trying previous day.. for cbnk\n",
      "No data for this date, trying previous day.. for cbnk\n",
      "No data for this date, trying previous day.. for cbnk\n",
      "No data for this date, trying previous day.. for cbnk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 2165/2559 [00:05<00:00, 427.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for tmsd\n",
      "No data for this date, trying previous day.. for tmsd\n",
      "No data for this date, trying previous day.. for tmsd\n",
      "No data for this date, trying previous day.. for tmsd\n",
      "No data for this date, trying previous day.. for tmsd\n",
      "No data for this date, trying previous day.. for tmsd\n",
      "No data for this date, trying previous day.. for tmsd\n",
      "No data for this date, trying previous day.. for nnnd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 2264/2559 [00:05<00:00, 458.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for tgmt\n",
      "No data for this date, trying previous day.. for lbby\n",
      "No data for this date, trying previous day.. for lbby\n",
      "No data for this date, trying previous day.. for lbby\n",
      "No data for this date, trying previous day.. for lbby\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n",
      "No data for this date, trying previous day.. for aclb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 2356/2559 [00:05<00:00, 420.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for nrrp\n",
      "No data for this date, trying previous day.. for gpdn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 2507/2559 [00:06<00:00, 461.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for lxjy\n",
      "No data for this date, trying previous day.. for lxjy\n",
      "No data for this date, trying previous day.. for lxjy\n",
      "No data for this date, trying previous day.. for lxjy\n",
      "No data for this date, trying previous day.. for lxjy\n",
      "No data for this date, trying previous day.. for lxjy\n",
      "No data for this date, trying previous day.. for htzk\n",
      "No data for this date, trying previous day.. for qoyi\n",
      "No data for this date, trying previous day.. for jvfg\n",
      "No data for this date, trying previous day.. for fgio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2559/2559 [00:06<00:00, 400.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for this date, trying previous day.. for gkeq\n",
      "No data for this date, trying previous day.. for gkeq\n",
      "No data for this date, trying previous day.. for gkeq\n",
      "No data for this date, trying previous day.. for gkeq\n",
      "No data for this date, trying previous day.. for gkeq\n",
      "No data for this date, trying previous day.. for gkeq\n",
      "No data for this date, trying previous day.. for gkeq\n",
      "No data for this date, trying previous day.. for gkeq\n",
      "No data for this date, trying previous day.. for gkeq\n",
      "No data for this date, trying previous day.. for gkeq\n",
      "No data for this date, trying previous day.. for gkeq\n",
      "No data for this date, trying previous day.. for gkeq\n",
      "No data for this date, trying previous day.. for gkeq\n",
      "No data for this date, trying previous day.. for gkeq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(val_data.itertuples(), total=val_data.shape[0]):\n",
    "    val_data.loc[row.Index, 'guess2'] = make_guess2(row, n_times_called=val_data_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28487690504103164"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/val_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this could be the reason! val data goes for previous dates about 1 in 4 samples. but the test data goes to previous date about 3 dates forward for every sample.!!\n",
    "\n",
    "# Validate  val data only if it looks like test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857663030948374"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(val_data.severity, val_data.guess2)\n",
    "#  this is worse on first glance but.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(val_data_calls))\n",
    "\n",
    "max(val_data_calls.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches:  0.5607659241891364\n",
      "Missed by 1:  0.3911684251660805\n",
      "Missed by 2:  0.04181320828448613\n",
      "Missed by 3:  0.005861664712778429\n",
      "Missed by 4:  0.00039077764751856197\n"
     ]
    }
   ],
   "source": [
    "analyize_matches(val_data.severity, val_data.guess2)\n",
    "\n",
    "#  much better at exact matches and 1 offs but worse at 2 offs so missed by 2s should have spiked up the error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04845642829230168"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.5592028135990621 + 0.39234075810863617 + 0.04181320828448613 + 0.0062524423602969914 + 0.00039077764751856197\n",
    "# 0.5592028135990621 + 0.39234075810863617\n",
    "\n",
    "# 95% preds <= 1 offs (thats why they are goood!)  4.8% >= 2 offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 347/2843 [00:03<00:19, 131.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for evep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 1009/2843 [00:11<00:22, 83.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for fvng\n",
      "No previous data for this date filling in 2s .. for fwbt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1204/2843 [00:13<00:15, 108.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for gdxr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 1399/2843 [00:15<00:25, 57.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for gkvw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1635/2843 [00:18<00:07, 156.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for guny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2843/2843 [00:29<00:00, 94.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.9186005352544053\n",
      "Train Distribution: \n",
      "1.0    0.437258\n",
      "4.0    0.211248\n",
      "2.0    0.184183\n",
      "3.0    0.163796\n",
      "5.0    0.003515\n",
      "Name: severity, dtype: float64\n",
      "Val Distribution: \n",
      "1.0    0.447415\n",
      "4.0    0.206120\n",
      "2.0    0.188533\n",
      "3.0    0.154063\n",
      "5.0    0.003869\n",
      "Name: severity, dtype: float64\n",
      "Predicted Distribution: \n",
      "2    0.347168\n",
      "1    0.345762\n",
      "4    0.212452\n",
      "3    0.091453\n",
      "5    0.003166\n",
      "Name: guess1, dtype: float64\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 1272/2843 [00:10<00:20, 78.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for kmki\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2843/2843 [00:28<00:00, 99.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.8637377567389661\n",
      "Train Distribution: \n",
      "1.0    0.442335\n",
      "4.0    0.208685\n",
      "2.0    0.186357\n",
      "3.0    0.158931\n",
      "5.0    0.003692\n",
      "Name: severity, dtype: float64\n",
      "Val Distribution: \n",
      "1.0    0.444953\n",
      "4.0    0.212100\n",
      "2.0    0.186423\n",
      "3.0    0.153007\n",
      "5.0    0.003517\n",
      "Name: severity, dtype: float64\n",
      "Predicted Distribution: \n",
      "2    0.371087\n",
      "1    0.349279\n",
      "4    0.221949\n",
      "3    0.056630\n",
      "5    0.001055\n",
      "Name: guess1, dtype: float64\n",
      "Fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2843/2843 [00:35<00:00, 79.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.8151312611573267\n",
      "Train Distribution: \n",
      "1.0    0.443207\n",
      "4.0    0.209823\n",
      "2.0    0.186379\n",
      "3.0    0.156957\n",
      "5.0    0.003634\n",
      "Name: severity, dtype: float64\n",
      "Val Distribution: \n",
      "1.0    0.451987\n",
      "4.0    0.204010\n",
      "2.0    0.185719\n",
      "3.0    0.156877\n",
      "5.0    0.001407\n",
      "Name: severity, dtype: float64\n",
      "Predicted Distribution: \n",
      "2    0.406964\n",
      "1    0.320084\n",
      "4    0.199085\n",
      "3    0.073514\n",
      "5    0.000352\n",
      "Name: guess1, dtype: float64\n",
      "Fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2843/2843 [00:22<00:00, 127.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.8493650770539654\n",
      "Train Distribution: \n",
      "1.0    0.445402\n",
      "4.0    0.208370\n",
      "2.0    0.186214\n",
      "3.0    0.156937\n",
      "5.0    0.003077\n",
      "Name: severity, dtype: float64\n",
      "Val Distribution: \n",
      "1.0    0.429828\n",
      "4.0    0.208934\n",
      "2.0    0.198382\n",
      "3.0    0.157580\n",
      "5.0    0.005276\n",
      "Name: severity, dtype: float64\n",
      "Predicted Distribution: \n",
      "2    0.416110\n",
      "1    0.301090\n",
      "4    0.218079\n",
      "3    0.064369\n",
      "5    0.000352\n",
      "Name: guess1, dtype: float64\n",
      "Fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2843/2843 [00:23<00:00, 120.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.8001055153771268\n",
      "Train Distribution: \n",
      "1.0    0.442287\n",
      "4.0    0.208483\n",
      "2.0    0.188647\n",
      "3.0    0.157065\n",
      "5.0    0.003517\n",
      "Name: severity, dtype: float64\n",
      "Val Distribution: \n",
      "1.0    0.425255\n",
      "4.0    0.205065\n",
      "2.0    0.195920\n",
      "3.0    0.170946\n",
      "5.0    0.002814\n",
      "Name: severity, dtype: float64\n",
      "Predicted Distribution: \n",
      "2    0.410482\n",
      "1    0.310236\n",
      "4    0.205065\n",
      "3    0.073162\n",
      "5    0.001055\n",
      "Name: guess1, dtype: float64\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rmses, guess2_mean = cv_loop(rand=1859, splits=5,  guess_func=make_guess2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8493880291163581, 0.04146945508927233)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmses), np.std(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches:  0.45791324736225086\n",
      "Missed by 1:  0.3899179366940211\n",
      "Missed by 2:  0.0794841735052755\n",
      "Missed by 3:  0.03622508792497069\n",
      "Missed by 4:  0.03587338804220398\n"
     ]
    }
   ],
   "source": [
    "analyize_matches(train_data.severity, guess2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8471864009378665"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4587338804220399 + 0.3884525205158265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "west         0.366667\n",
       "midwest      0.240399\n",
       "south        0.232104\n",
       "northeast    0.160829\n",
       "Name: region, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Is there any difference between test and val sets?\n",
    "\n",
    "te_data.region.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "south        0.579132\n",
       "west         0.221180\n",
       "midwest      0.130911\n",
       "northeast    0.068777\n",
       "Name: region, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.region.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "south        0.583118\n",
       "west         0.220926\n",
       "midwest      0.128957\n",
       "northeast    0.066999\n",
       "Name: region, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.region.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-09-17    40\n",
       "2014-07-30    38\n",
       "2019-01-17    32\n",
       "2019-08-27    30\n",
       "2019-05-28    29\n",
       "              ..\n",
       "2020-01-17     1\n",
       "2014-06-16     1\n",
       "2018-05-23     1\n",
       "2020-11-05     1\n",
       "2013-11-21     1\n",
       "Name: date, Length: 1278, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.date.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-08-10    0.008089\n",
       "2015-07-07    0.006389\n",
       "2015-06-22    0.006038\n",
       "2015-08-24    0.005627\n",
       "2015-06-10    0.005569\n",
       "                ...   \n",
       "2018-12-10    0.000059\n",
       "2014-02-20    0.000059\n",
       "2021-03-18    0.000059\n",
       "2021-02-24    0.000059\n",
       "2020-04-20    0.000059\n",
       "Name: date, Length: 1255, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.date.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "south = val_data[val_data.region == 'south']\n",
    "west = val_data[val_data.region == 'west']\n",
    "midwest = val_data[val_data.region == 'midwest']\n",
    "northeast = val_data[val_data.region == 'northeast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8131842079168767, 0.9132404377632387)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(south.severity, south.guess2), rmse(south.severity, south.guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5670579955507383, 0.5763293130075913)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(west.severity, west.guess2), rmse(west.severity, west.guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9288092200038601, 0.9478963354115085)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(midwest.severity, midwest.guess2), rmse(midwest.severity, midwest.guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.856127645538062, 0.9076693430779935)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(northeast.severity, northeast.guess2), rmse(northeast.severity, northeast.guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6790564218619121"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(val_data.guess2, val_data.guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches:  0.6228995701445877\n",
      "Missed by 1:  0.3540445486518171\n",
      "Missed by 2:  0.022274325908558032\n",
      "Missed by 3:  0.0007815552950371239\n",
      "Missed by 4:  0.0\n"
     ]
    }
   ],
   "source": [
    "analyize_matches(val_data.guess2, val_data.guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "west         0.366667\n",
       "midwest      0.240399\n",
       "south        0.232104\n",
       "northeast    0.160829\n",
       "Name: region, dtype: float64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg = te_data.region.value_counts(normalize=True)\n",
    "rg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7576406832145016"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8131842079168767 * rg['south']  + 0.5670579955507383 * rg['west'] + 0.9288092200038601 * rg['midwest'] + 0.856127645538062 * rg['northeast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "west         0.366733\n",
       "south        0.240481\n",
       "midwest      0.232465\n",
       "northeast    0.160321\n",
       "Name: region, dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "west = train_data[train_data.region == 'west'].sample(366*2, random_state=42)\n",
    "south = train_data[train_data.region == 'south'].sample(240*2, random_state=42)\n",
    "midwest = train_data[train_data.region == 'midwest'].sample(232*2, random_state=42)\n",
    "northeast = train_data[train_data.region == 'northeast'].sample(160*2, random_state=42)\n",
    "\n",
    "\n",
    "new_val_data = pd.concat([west, south, midwest, northeast])\n",
    "new_val_data.region.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "south        0.628518\n",
       "west         0.201606\n",
       "midwest      0.115242\n",
       "northeast    0.054634\n",
       "Name: region, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tr_data = train_data[~train_data.uid.isin(new_val_data.uid)]\n",
    "new_tr_data.region.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1996/1996 [00:05<00:00, 334.32it/s]\n"
     ]
    }
   ],
   "source": [
    "newval_calls = {}\n",
    "for row in tqdm(new_val_data.itertuples(), total=new_val_data.shape[0]):\n",
    "    new_val_data.loc[row.Index, 'guess2'] = make_guess2(row, tr_data=new_tr_data, n_times_called=newval_calls)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(newval_calls))\n",
    "\n",
    "max(newval_calls.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7734315695558147"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(new_val_data.severity, new_val_data.guess2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    0.342685\n",
       "1.0    0.318136\n",
       "3.0    0.166834\n",
       "2.0    0.165832\n",
       "5.0    0.006513\n",
       "Name: severity, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_val_data.severity.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    0.334669\n",
       "2.0    0.294088\n",
       "1.0    0.233968\n",
       "3.0    0.133267\n",
       "5.0    0.004008\n",
       "Name: guess2, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_val_data.guess2.value_counts(normalize=True)\n",
    "#  4 1 2 3 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches:  0.6277555110220441\n",
      "Missed by 1:  0.31312625250501\n",
      "Missed by 2:  0.04909819639278557\n",
      "Missed by 3:  0.009519038076152305\n",
      "Missed by 4:  0.000501002004008016\n"
     ]
    }
   ],
   "source": [
    "analyize_matches(new_val_data.severity, new_val_data.guess2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1178187403993856"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_calls))\n",
    "\n",
    "max(test_calls.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "      <th>guess2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aabn</td>\n",
       "      <td>36.559700</td>\n",
       "      <td>-121.510000</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>test</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aair</td>\n",
       "      <td>33.042600</td>\n",
       "      <td>-117.076000</td>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>test</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aajw</td>\n",
       "      <td>40.703968</td>\n",
       "      <td>-80.293050</td>\n",
       "      <td>2015-08-26</td>\n",
       "      <td>test</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>northeast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aalr</td>\n",
       "      <td>38.972500</td>\n",
       "      <td>-94.672930</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>test</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aalw</td>\n",
       "      <td>34.279000</td>\n",
       "      <td>-118.905000</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>test</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23556</th>\n",
       "      <td>zzpn</td>\n",
       "      <td>40.136410</td>\n",
       "      <td>-80.473740</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>test</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>northeast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23560</th>\n",
       "      <td>zzrv</td>\n",
       "      <td>36.875400</td>\n",
       "      <td>-121.561000</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>test</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23563</th>\n",
       "      <td>zzsx</td>\n",
       "      <td>34.210000</td>\n",
       "      <td>-78.929389</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>test</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>south</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23565</th>\n",
       "      <td>zzvv</td>\n",
       "      <td>36.708500</td>\n",
       "      <td>-121.749000</td>\n",
       "      <td>2014-12-02</td>\n",
       "      <td>test</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23569</th>\n",
       "      <td>zzzi</td>\n",
       "      <td>39.767323</td>\n",
       "      <td>-96.028617</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>test</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6510 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid   latitude   longitude       date split  year  month  week  \\\n",
       "1      aabn  36.559700 -121.510000 2016-08-31  test  2016      8    35   \n",
       "12     aair  33.042600 -117.076000 2014-11-01  test  2014     11    44   \n",
       "14     aajw  40.703968  -80.293050 2015-08-26  test  2015      8    35   \n",
       "15     aalr  38.972500  -94.672930 2019-08-26  test  2019      8    35   \n",
       "16     aalw  34.279000 -118.905000 2018-01-08  test  2018      1     2   \n",
       "...     ...        ...         ...        ...   ...   ...    ...   ...   \n",
       "23556  zzpn  40.136410  -80.473740 2019-07-08  test  2019      7    28   \n",
       "23560  zzrv  36.875400 -121.561000 2019-09-17  test  2019      9    38   \n",
       "23563  zzsx  34.210000  -78.929389 2019-07-16  test  2019      7    29   \n",
       "23565  zzvv  36.708500 -121.749000 2014-12-02  test  2014     12    49   \n",
       "23569  zzzi  39.767323  -96.028617 2015-08-31  test  2015      8    36   \n",
       "\n",
       "       season     region  severity  density  guess2  \n",
       "1           3       west       NaN      NaN     2.0  \n",
       "12          4       west       NaN      NaN     4.0  \n",
       "14          3  northeast       NaN      NaN     2.0  \n",
       "15          3    midwest       NaN      NaN     3.0  \n",
       "16          1       west       NaN      NaN     4.0  \n",
       "...       ...        ...       ...      ...     ...  \n",
       "23556       3  northeast       NaN      NaN     5.0  \n",
       "23560       4       west       NaN      NaN     4.0  \n",
       "23563       3      south       NaN      NaN     1.0  \n",
       "23565       1       west       NaN      NaN     4.0  \n",
       "23569       3    midwest       NaN      NaN     2.0  \n",
       "\n",
       "[6510 rows x 13 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>bqzw</td>\n",
       "      <td>37.6756</td>\n",
       "      <td>-121.264</td>\n",
       "      <td>2016-08-17</td>\n",
       "      <td>train</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.765920e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10710</th>\n",
       "      <td>ltlm</td>\n",
       "      <td>38.2361</td>\n",
       "      <td>-121.419</td>\n",
       "      <td>2016-08-17</td>\n",
       "      <td>train</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.680760e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11941</th>\n",
       "      <td>ncup</td>\n",
       "      <td>37.9718</td>\n",
       "      <td>-121.374</td>\n",
       "      <td>2016-08-17</td>\n",
       "      <td>train</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.596380e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20573</th>\n",
       "      <td>wspe</td>\n",
       "      <td>38.3070</td>\n",
       "      <td>-121.794</td>\n",
       "      <td>2016-08-17</td>\n",
       "      <td>train</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.534027e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22972</th>\n",
       "      <td>zilg</td>\n",
       "      <td>38.3677</td>\n",
       "      <td>-121.521</td>\n",
       "      <td>2016-08-17</td>\n",
       "      <td>train</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>west</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.920500e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid  latitude  longitude       date  split  year  month  week  season  \\\n",
       "1467   bqzw   37.6756   -121.264 2016-08-17  train  2016      8    33       3   \n",
       "10710  ltlm   38.2361   -121.419 2016-08-17  train  2016      8    33       3   \n",
       "11941  ncup   37.9718   -121.374 2016-08-17  train  2016      8    33       3   \n",
       "20573  wspe   38.3070   -121.794 2016-08-17  train  2016      8    33       3   \n",
       "22972  zilg   38.3677   -121.521 2016-08-17  train  2016      8    33       3   \n",
       "\n",
       "      region  severity       density  \n",
       "1467    west       4.0  1.765920e+06  \n",
       "10710   west       4.0  1.680760e+06  \n",
       "11941   west       4.0  1.596380e+06  \n",
       "20573   west       4.0  1.534027e+06  \n",
       "22972   west       4.0  1.920500e+06  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[(train_data.date == '2016-08-17') & (train_data.region == 'west')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 382, 0)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(val_data.date) - set(train_data.date) ), len(set(test_data.date) - set(train_data.date)), len(set(new_val_data.date) - set(train_data.date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  So this could be one possible reason for the difference in val and test set scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "      <th>guess2</th>\n",
       "      <th>guess1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aabm</td>\n",
       "      <td>39.080319</td>\n",
       "      <td>-86.430867</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>train</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aabn</td>\n",
       "      <td>36.559700</td>\n",
       "      <td>-121.510000</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>test</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aacd</td>\n",
       "      <td>35.875083</td>\n",
       "      <td>-78.878434</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>train</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaee</td>\n",
       "      <td>35.487000</td>\n",
       "      <td>-79.062133</td>\n",
       "      <td>2016-08-24</td>\n",
       "      <td>train</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1614.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaff</td>\n",
       "      <td>38.049471</td>\n",
       "      <td>-99.827001</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>train</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>3.0</td>\n",
       "      <td>111825.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23565</th>\n",
       "      <td>zzvv</td>\n",
       "      <td>36.708500</td>\n",
       "      <td>-121.749000</td>\n",
       "      <td>2014-12-02</td>\n",
       "      <td>test</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23566</th>\n",
       "      <td>zzwo</td>\n",
       "      <td>39.792190</td>\n",
       "      <td>-99.971050</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>train</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48510.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23567</th>\n",
       "      <td>zzwq</td>\n",
       "      <td>35.794000</td>\n",
       "      <td>-79.012551</td>\n",
       "      <td>2015-03-24</td>\n",
       "      <td>train</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23568</th>\n",
       "      <td>zzyb</td>\n",
       "      <td>35.742000</td>\n",
       "      <td>-79.238600</td>\n",
       "      <td>2016-11-21</td>\n",
       "      <td>train</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9682.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23569</th>\n",
       "      <td>zzzi</td>\n",
       "      <td>39.767323</td>\n",
       "      <td>-96.028617</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>test</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23570 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid   latitude   longitude       date  split  year  month  week  \\\n",
       "0      aabm  39.080319  -86.430867 2018-05-14  train  2018      5    20   \n",
       "1      aabn  36.559700 -121.510000 2016-08-31   test  2016      8    35   \n",
       "2      aacd  35.875083  -78.878434 2020-11-19  train  2020     11    47   \n",
       "3      aaee  35.487000  -79.062133 2016-08-24  train  2016      8    34   \n",
       "4      aaff  38.049471  -99.827001 2019-07-23  train  2019      7    30   \n",
       "...     ...        ...         ...        ...    ...   ...    ...   ...   \n",
       "23565  zzvv  36.708500 -121.749000 2014-12-02   test  2014     12    49   \n",
       "23566  zzwo  39.792190  -99.971050 2017-06-19  train  2017      6    25   \n",
       "23567  zzwq  35.794000  -79.012551 2015-03-24  train  2015      3    13   \n",
       "23568  zzyb  35.742000  -79.238600 2016-11-21  train  2016     11    47   \n",
       "23569  zzzi  39.767323  -96.028617 2015-08-31   test  2015      8    36   \n",
       "\n",
       "       season   region  severity   density  guess2  guess1  \n",
       "0           2  midwest       1.0     585.0     NaN     NaN  \n",
       "1           3     west       NaN       NaN     2.0     2.0  \n",
       "2           4    south       1.0     290.0     NaN     NaN  \n",
       "3           3    south       1.0    1614.0     NaN     NaN  \n",
       "4           3  midwest       3.0  111825.0     NaN     NaN  \n",
       "...       ...      ...       ...       ...     ...     ...  \n",
       "23565       1     west       NaN       NaN     4.0     4.0  \n",
       "23566       3  midwest       2.0   48510.0     NaN     NaN  \n",
       "23567       2    south       1.0    1271.0     NaN     NaN  \n",
       "23568       4    south       1.0    9682.0     NaN     NaN  \n",
       "23569       3  midwest       NaN       NaN     2.0     1.0  \n",
       "\n",
       "[23570 rows x 14 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([train_data, test_data])\n",
    "data.sort_index(inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "      <th>guess2</th>\n",
       "      <th>guess1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>evep</td>\n",
       "      <td>44.847993</td>\n",
       "      <td>-93.476318</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13644</th>\n",
       "      <td>paev</td>\n",
       "      <td>44.822478</td>\n",
       "      <td>-93.367962</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>gdxr</td>\n",
       "      <td>44.877646</td>\n",
       "      <td>-93.557842</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>guny</td>\n",
       "      <td>44.878889</td>\n",
       "      <td>-93.490833</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5317</th>\n",
       "      <td>fwbt</td>\n",
       "      <td>44.850500</td>\n",
       "      <td>-93.515700</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>nsoi</td>\n",
       "      <td>36.736800</td>\n",
       "      <td>-121.734000</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17559</th>\n",
       "      <td>thki</td>\n",
       "      <td>36.725400</td>\n",
       "      <td>-121.730000</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17452</th>\n",
       "      <td>teuu</td>\n",
       "      <td>36.772300</td>\n",
       "      <td>-121.788000</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14254</th>\n",
       "      <td>prfi</td>\n",
       "      <td>36.751800</td>\n",
       "      <td>-121.742000</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>howu</td>\n",
       "      <td>36.708500</td>\n",
       "      <td>-121.749000</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23570 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid   latitude   longitude       date  split  year  month  week  \\\n",
       "4387   evep  44.847993  -93.476318 2013-01-04  train  2013      1     1   \n",
       "13644  paev  44.822478  -93.367962 2013-01-04  train  2013      1     1   \n",
       "5566   gdxr  44.877646  -93.557842 2013-01-04  train  2013      1     1   \n",
       "6144   guny  44.878889  -93.490833 2013-01-04  train  2013      1     1   \n",
       "5317   fwbt  44.850500  -93.515700 2013-01-04  train  2013      1     1   \n",
       "...     ...        ...         ...        ...    ...   ...    ...   ...   \n",
       "12443  nsoi  36.736800 -121.734000 2021-12-29   test  2021     12    52   \n",
       "17559  thki  36.725400 -121.730000 2021-12-29   test  2021     12    52   \n",
       "17452  teuu  36.772300 -121.788000 2021-12-29   test  2021     12    52   \n",
       "14254  prfi  36.751800 -121.742000 2021-12-29   test  2021     12    52   \n",
       "6864   howu  36.708500 -121.749000 2021-12-29   test  2021     12    52   \n",
       "\n",
       "       season   region  severity  density  guess2  guess1  \n",
       "4387        1  midwest       1.0    115.0     NaN     NaN  \n",
       "13644       1  midwest       1.0   1884.0     NaN     NaN  \n",
       "5566        1  midwest       1.0   1416.0     NaN     NaN  \n",
       "6144        1  midwest       1.0    558.0     NaN     NaN  \n",
       "5317        1  midwest       1.0    476.0     NaN     NaN  \n",
       "...       ...      ...       ...      ...     ...     ...  \n",
       "12443       1     west       NaN      NaN     4.0     4.0  \n",
       "17559       1     west       NaN      NaN     4.0     4.0  \n",
       "17452       1     west       NaN      NaN     4.0     4.0  \n",
       "14254       1     west       NaN      NaN     4.0     4.0  \n",
       "6864        1     west       NaN      NaN     4.0     4.0  \n",
       "\n",
       "[23570 rows x 14 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(by='date', inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0 days     5232\n",
       "1 days      784\n",
       "4 days      112\n",
       "2 days       93\n",
       "5 days       85\n",
       "3 days       62\n",
       "6 days       45\n",
       "7 days       43\n",
       "8 days       12\n",
       "13 days       7\n",
       "11 days       6\n",
       "10 days       4\n",
       "17 days       4\n",
       "9 days        4\n",
       "19 days       3\n",
       "12 days       3\n",
       "16 days       3\n",
       "26 days       2\n",
       "20 days       2\n",
       "14 days       1\n",
       "15 days       1\n",
       "18 days       1\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ig the exact answer lies in How is the test set different from val set?\n",
    "\n",
    "#  find difference in consecutive dates between test samples\n",
    "\n",
    "\n",
    "te_data.date.diff().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0 days     1737\n",
       "1 days      371\n",
       "5 days       69\n",
       "2 days       68\n",
       "6 days       68\n",
       "4 days       64\n",
       "7 days       53\n",
       "3 days       39\n",
       "8 days       21\n",
       "14 days      11\n",
       "13 days      10\n",
       "10 days       7\n",
       "19 days       6\n",
       "9 days        6\n",
       "12 days       4\n",
       "20 days       4\n",
       "15 days       3\n",
       "11 days       3\n",
       "34 days       2\n",
       "16 days       2\n",
       "23 days       1\n",
       "35 days       1\n",
       "18 days       1\n",
       "24 days       1\n",
       "26 days       1\n",
       "17 days       1\n",
       "30 days       1\n",
       "21 days       1\n",
       "33 days       1\n",
       "39 days       1\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.date.diff().value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Understanding how the data is split into test set is the key!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-78.96708942.027378          94\n",
       "-120.8537.2953               87\n",
       "-121.79438.307               84\n",
       "-120.85137.2486              82\n",
       "-121.52637.8717              80\n",
       "                             ..\n",
       "-84.1799937.54089             1\n",
       "-78.969905045800436.00756     1\n",
       "-79.106425726211636.15        1\n",
       "-86.7025339.29887             1\n",
       "-79.238600417233535.742       1\n",
       "Name: location, Length: 10614, dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['location'] = train_data.longitude.astype(str) + train_data.latitude.astype(str)\n",
    "train_data.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-78.96708942.027378                  79\n",
      "-121.79438.307                       77\n",
      "-120.8537.2953                       77\n",
      "-120.8937.1145                       68\n",
      "-121.52637.8717                      68\n",
      "                                     ..\n",
      "-78.81306251168935.8669153379229      1\n",
      "-79.229900752108535.742               1\n",
      "-78.930880833668135.8816361964081     1\n",
      "-78.930383709946635.8815740830812     1\n",
      "-78.843387058696335.98                1\n",
      "Name: location, Length: 9130, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-120.96737.4583                      17\n",
       "-120.85137.2486                      16\n",
       "-78.96708942.027378                  15\n",
       "-120.75937.4125                      15\n",
       "-121.49438.1156                      14\n",
       "                                     ..\n",
       "-78.758876026053135.976               1\n",
       "-79.163274703268535.7061617064181     1\n",
       "-79.146071708472135.7154236165606     1\n",
       "-78.974876283014735.61133             1\n",
       "-78.843138496835635.98                1\n",
       "Name: location, Length: 1806, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data['location'] = tr_data.longitude.astype(str) + tr_data.latitude.astype(str)\n",
    "print(tr_data.location.value_counts())\n",
    "\n",
    "val_data['location'] = val_data.longitude.astype(str) + val_data.latitude.astype(str)\n",
    "val_data.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-120.637.0062                75\n",
       "-120.03637.4363              44\n",
       "-95.7069703238.51613412      42\n",
       "-84.966144444444539.61525    42\n",
       "-84.986841666666739.4981     42\n",
       "                             ..\n",
       "-119.256346.95433             1\n",
       "-95.3966145.91673             1\n",
       "-96.0239435.74527             1\n",
       "-95.8400246.41943             1\n",
       "-79.119822311239835.04        1\n",
       "Name: location, Length: 2067, dtype: int64"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "te_data['location'] = te_data.longitude.astype(str) + te_data.latitude.astype(str)\n",
    "te_data.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39172749391727496"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(val_data.location).intersection(set(tr_data.location)))/val_data.date.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(te_data.location).intersection(set(tr_data.location)))/te_data.date.nunique()\n",
    "\n",
    "#  This could be a reason !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.701095461658842"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check overlap of dates between train and test set\n",
    "\n",
    "len(set(test_data.date).intersection(set(train_data.date)))/test_data.date.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9708029197080292"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(val_data.date).intersection(set(tr_data.date)))/val_data.date.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Check overlap of date and region between train and test set\n",
    "\n",
    "train_data['date_reg'] = train_data.date.astype(str) + \"_\" +  train_data.region\n",
    "test_data['date_reg'] = test_data.date.astype(str) + \"_\" +  test_data.region\n",
    "val_data['date_reg'] = val_data.date.astype(str) + \"_\" +  val_data.region\n",
    "\n",
    "tr_data['date_reg'] = tr_data.date.astype(str) + \"_\" +  tr_data.region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5178926441351889"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  what percentage of date_reg present in test set are present in train set\n",
    "len(set(test_data.date_reg).intersection(set(train_data.date_reg)))/test_data.date_reg.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9224880382775119"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(val_data.date_reg).intersection(set(tr_data.date_reg)))/val_data.date_reg.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New val data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data2 = val_data.drop(columns=['guess', 'guess2'])\n",
    "tr_data2 = tr_data.copy()\n",
    "\n",
    "val_data2['date_reg'] = val_data2.date.astype(str) + \"_\" +  val_data2.region\n",
    "tr_data2['date_reg'] = tr_data2.date.astype(str) + \"_\" +  tr_data2.region\n",
    "\n",
    "\n",
    "te_data2 = test_data.copy()\n",
    "te_data2.sort_values(by='date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (val_data2.columns == tr_data2.columns).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uid', 'latitude', 'longitude', 'date', 'split', 'year', 'month',\n",
       "       'week', 'season', 'region', 'severity', 'density', 'guess2', 'guess1',\n",
       "       'date_reg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(val_data2.uid).intersection(set(tr_data2.uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9224880382775119"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(val_data2.date_reg).intersection(set(tr_data2.date_reg)))/val_data2.date_reg.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  remove 50% of datereg from tr_data2 present in val_data2 (to match test set)\n",
    "\n",
    "datereg_to_remove = val_data2.date_reg.sample(frac=0.40, random_state=42)\n",
    "tr_data2_ = tr_data2[~tr_data2.date_reg.isin(datereg_to_remove)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37320574162679426"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(val_data2.date_reg).intersection(set(tr_data2_.date_reg)))/val_data2.date_reg.nunique()    # matching test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6593673965936739"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(val_data2.date).intersection(set(tr_data2_.date)))/val_data2.date.nunique()\n",
    "#  almost matchine test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2559/2559 [00:37<00:00, 67.64it/s] \n"
     ]
    }
   ],
   "source": [
    "val_calls = {}\n",
    "for row in tqdm(val_data2.itertuples(), total=val_data2.shape[0]):\n",
    "    val_data2.loc[row.Index, 'guess_2_new'] = make_guess2(row, tr_data=tr_data2_, n_times_called=val_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0007812501191629"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(val_data2.severity, val_data2.guess_2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches:  0.5162172723720203\n",
      "Missed by 1:  0.3614693239546698\n",
      "Missed by 2:  0.09378663540445487\n",
      "Missed by 3:  0.027354435326299335\n",
      "Missed by 4:  0.0011723329425556857\n"
     ]
    }
   ],
   "source": [
    "analyize_matches(val_data2.severity, val_data2.guess_2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(val_calls.values())/len(val_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2559/2559 [00:09<00:00, 274.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 0.7857663030948374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_calls = {}\n",
    "for row in tqdm(val_data2.itertuples(), total=val_data2.shape[0]):\n",
    "    val_data2.loc[row.Index, 'guess_2'] = make_guess2(row, tr_data=tr_data2, n_times_called=val_calls)\n",
    "\n",
    "\n",
    "print(\"rmse:\", rmse(val_data2.severity, val_data2.guess_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches:  0.5607659241891364\n",
      "Missed by 1:  0.3911684251660805\n",
      "Missed by 2:  0.04181320828448613\n",
      "Missed by 3:  0.005861664712778429\n",
      "Missed by 4:  0.00039077764751856197\n"
     ]
    }
   ],
   "source": [
    "analyize_matches(val_data2.severity, val_data2.guess_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(val_calls.values())/len(val_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new val data with different split\n",
    "\n",
    "tr_data3, val_data3 = train_test_split(train_data, test_size=0.2, random_state=123456789, shuffle=True)\n",
    "\n",
    "tr_data3['date_reg'] = tr_data3.date.astype(str) + \"_\" +  tr_data3.region\n",
    "val_data3['date_reg'] = val_data3.date.astype(str) + \"_\" +  val_data3.region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of datereg matching in train data 0.37320574162679426\n",
      "% of dates matching in train-data 0.6593673965936739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/3412 [00:00<01:57, 28.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for pbfb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 73/3412 [00:01<00:44, 75.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for jalu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 928/3412 [00:14<00:32, 75.82it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for jubi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1427/3412 [00:21<00:35, 55.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for pfly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 2989/3412 [00:43<00:05, 70.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for dvpi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 3087/3412 [00:44<00:04, 76.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for wrxx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 3149/3412 [00:45<00:04, 63.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for seke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 3343/3412 [00:48<00:01, 59.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for evep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3412/3412 [00:50<00:00, 68.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9905769394242474\n",
      "Exact matches:  0.5199296600234466\n",
      "Missed by 1:  0.358147713950762\n",
      "Missed by 2:  0.09525205158264947\n",
      "Missed by 3:  0.02637749120750293\n",
      "Missed by 4:  0.00029308323563892143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# new way of making val data\n",
    "\n",
    "datereg_to_remove = val_data3.date_reg.sample(frac=0.40, random_state=123456789)\n",
    "tr_data3_ = tr_data3[~tr_data3.date_reg.isin(datereg_to_remove)]\n",
    "\n",
    "print(\"% of datereg matching in train data\", len(set(val_data2.date_reg).intersection(set(tr_data2_.date_reg)))/val_data2.date_reg.nunique())   # matching test set\n",
    "\n",
    "print(\"% of dates matching in train-data\", len(set(val_data2.date).intersection(set(tr_data2_.date)))/val_data2.date.nunique())\n",
    "\n",
    "\n",
    "val_calls = {}\n",
    "\n",
    "for row in tqdm(val_data3.itertuples(), total=val_data3.shape[0]):\n",
    "    val_data3.loc[row.Index, 'guess_2_new'] = make_guess2(row, tr_data=tr_data3_, n_times_called=val_calls)\n",
    "\n",
    "print(rmse(val_data3.severity, val_data3.guess_2_new))\n",
    "\n",
    "analyize_matches(val_data3.severity, val_data3.guess_2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8780773739742087"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5199296600234466 + 0.358147713950762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9005339044216468\n",
      "Exact matches:  0.3698710433763189\n",
      "Missed by 1:  0.5908558030480656\n",
      "Missed by 2:  0.026670574443141852\n",
      "Missed by 3:  0.012602579132473623\n",
      "Missed by 4:  0.0\n"
     ]
    }
   ],
   "source": [
    "avg_sev_by_reg = np.round(tr_data3_.groupby('region').severity.mean())\n",
    "\n",
    "print(rmse(val_data3.severity, val_data3.region.map(avg_sev_by_reg)))\n",
    "\n",
    "analyize_matches(val_data3.severity, val_data3.region.map(avg_sev_by_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9607268464243846"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3698710433763189 + 0.5908558030480656 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3412/3412 [00:10<00:00, 312.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8031663598789893\n",
      "Exact matches:  0.5565650644783119\n",
      "Missed by 1:  0.3886283704572098\n",
      "Missed by 2:  0.0477725674091442\n",
      "Missed by 3:  0.006740914419695193\n",
      "Missed by 4:  0.00029308323563892143\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# past way of making val data\n",
    "val_calls = {}\n",
    "for row in tqdm(val_data3.itertuples(), total=val_data3.shape[0]):\n",
    "    val_data3.loc[row.Index, 'guess_2'] = make_guess2(row, tr_data=tr_data3, n_times_called=val_calls)\n",
    "\n",
    "print(rmse(val_data3.severity, val_data3.guess_2))\n",
    "\n",
    "analyize_matches(val_data3.severity, val_data3.guess_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9451934349355218"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5565650644783119 + 0.3886283704572098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07356389214536929, 0.19631336405529953, 0.3212192262602579)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.date.nunique()/len(train_data), test_data.date.nunique()/len(test_data), val_data.date.nunique()/len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 92/6510 [00:02<01:17, 83.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for igpa\n",
      "No previous data for this date filling in 2s .. for lkpf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 101/6510 [00:02<03:28, 30.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous data for this date filling in 2s .. for paez\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6510/6510 [01:40<00:00, 64.90it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aabn</td>\n",
       "      <td>west</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aair</td>\n",
       "      <td>west</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aajw</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aalr</td>\n",
       "      <td>midwest</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aalw</td>\n",
       "      <td>west</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6505</th>\n",
       "      <td>zzpn</td>\n",
       "      <td>northeast</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>zzrv</td>\n",
       "      <td>west</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6507</th>\n",
       "      <td>zzsx</td>\n",
       "      <td>south</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>zzvv</td>\n",
       "      <td>west</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>zzzi</td>\n",
       "      <td>midwest</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6510 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid     region  severity\n",
       "0     aabn       west         2\n",
       "1     aair       west         4\n",
       "2     aajw  northeast         2\n",
       "3     aalr    midwest         3\n",
       "4     aalw       west         4\n",
       "...    ...        ...       ...\n",
       "6505  zzpn  northeast         5\n",
       "6506  zzrv       west         4\n",
       "6507  zzsx      south         1\n",
       "6508  zzvv       west         4\n",
       "6509  zzzi    midwest         2\n",
       "\n",
       "[6510 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #  Making submission with guess2 mean\n",
    "\n",
    "# sub_format['severity'] = 0\n",
    "\n",
    "# for row in tqdm(te_data.itertuples(), total=te_data.shape[0]):\n",
    "#     uid_series = te_data[te_data.uid == row.uid]\n",
    "#     severity = make_guess2(uid_series.iloc[0], date=row.date, tr_data=train_data)   # use all train data for making test submission\n",
    "#     sub_format.loc[sub_format.uid == row.uid, 'severity'] = severity\n",
    "\n",
    "# sub_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    0.326575\n",
      "1    0.284178\n",
      "2    0.214132\n",
      "3    0.172197\n",
      "5    0.002919\n",
      "Name: severity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print(sub_format.severity.value_counts(normalize=True))\n",
    "\n",
    "# sub_format.to_csv('../submissions/to submit/guess2_mean_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sooo....\n",
    "\n",
    "- The discrepancy is due to high percentage of dates and region combinations (as in myguess2) is missing in the test set, where as the val set is so sweet and nice and has all the    combinations\n",
    "- finally figured out something, but not sure if it's right.\n",
    "- \n",
    "\n",
    "# Todos :\n",
    "\n",
    "- check this theory with a submission.\n",
    "- analyise date missses vs date_reg misses.\n",
    "- Figure out better hypothesis guessing on new val set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "186db977f413ae6598820b658aed1651932768522d0652c07d949b3f5fb38b63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
