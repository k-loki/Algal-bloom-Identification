{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Mission : Error Analysis & Model metadata``\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from geopy.distance import geodesic\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('../data/metadata.csv')\n",
    "sub_format = pd.read_csv('../data/submission_format.csv')\n",
    "train_labels = pd.read_csv('../data/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return mse(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dens_to_sev(x: float)-> int:\n",
    "    \"\"\"takes in density value in cells/ml and returns severity category\"\"\"\n",
    "    if (x < 20_000) : return 1\n",
    "    elif (x >= 20_000) and (x < 100_000) : return 2\n",
    "    elif (x >= 100_000) and (x < 1_000_000) : return 3\n",
    "    elif (x >= 1_000_000) and (x < 10_000_000) : return 4\n",
    "    elif x > 10_000_000 : return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add date fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aabm</td>\n",
       "      <td>39.080319</td>\n",
       "      <td>-86.430867</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>train</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aabn</td>\n",
       "      <td>36.559700</td>\n",
       "      <td>-121.510000</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>test</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aacd</td>\n",
       "      <td>35.875083</td>\n",
       "      <td>-78.878434</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>train</td>\n",
       "      <td>2020</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaee</td>\n",
       "      <td>35.487000</td>\n",
       "      <td>-79.062133</td>\n",
       "      <td>2016-08-24</td>\n",
       "      <td>train</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaff</td>\n",
       "      <td>38.049471</td>\n",
       "      <td>-99.827001</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>train</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>3.0</td>\n",
       "      <td>111825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23565</th>\n",
       "      <td>zzvv</td>\n",
       "      <td>36.708500</td>\n",
       "      <td>-121.749000</td>\n",
       "      <td>2014-12-02</td>\n",
       "      <td>test</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23566</th>\n",
       "      <td>zzwo</td>\n",
       "      <td>39.792190</td>\n",
       "      <td>-99.971050</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>train</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23567</th>\n",
       "      <td>zzwq</td>\n",
       "      <td>35.794000</td>\n",
       "      <td>-79.012551</td>\n",
       "      <td>2015-03-24</td>\n",
       "      <td>train</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23568</th>\n",
       "      <td>zzyb</td>\n",
       "      <td>35.742000</td>\n",
       "      <td>-79.238600</td>\n",
       "      <td>2016-11-21</td>\n",
       "      <td>train</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "      <td>south</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23569</th>\n",
       "      <td>zzzi</td>\n",
       "      <td>39.767323</td>\n",
       "      <td>-96.028617</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>test</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23570 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid   latitude   longitude       date  split  year  month  week  \\\n",
       "0      aabm  39.080319  -86.430867 2018-05-14  train  2018      5    20   \n",
       "1      aabn  36.559700 -121.510000 2016-08-31   test  2016      8    35   \n",
       "2      aacd  35.875083  -78.878434 2020-11-19  train  2020     11    47   \n",
       "3      aaee  35.487000  -79.062133 2016-08-24  train  2016      8    34   \n",
       "4      aaff  38.049471  -99.827001 2019-07-23  train  2019      7    30   \n",
       "...     ...        ...         ...        ...    ...   ...    ...   ...   \n",
       "23565  zzvv  36.708500 -121.749000 2014-12-02   test  2014     12    49   \n",
       "23566  zzwo  39.792190  -99.971050 2017-06-19  train  2017      6    25   \n",
       "23567  zzwq  35.794000  -79.012551 2015-03-24  train  2015      3    13   \n",
       "23568  zzyb  35.742000  -79.238600 2016-11-21  train  2016     11    47   \n",
       "23569  zzzi  39.767323  -96.028617 2015-08-31   test  2015      8    36   \n",
       "\n",
       "       season   region  severity   density  \n",
       "0           2  midwest       1.0     585.0  \n",
       "1           3     west       NaN       NaN  \n",
       "2           4    south       1.0     290.0  \n",
       "3           3    south       1.0    1614.0  \n",
       "4           3  midwest       3.0  111825.0  \n",
       "...       ...      ...       ...       ...  \n",
       "23565       1     west       NaN       NaN  \n",
       "23566       3  midwest       2.0   48510.0  \n",
       "23567       2    south       1.0    1271.0  \n",
       "23568       4    south       1.0    9682.0  \n",
       "23569       3  midwest       NaN       NaN  \n",
       "\n",
       "[23570 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.date = pd.to_datetime(metadata.date)\n",
    "metadata['year'] = metadata.date.dt.year\n",
    "metadata['month'] = metadata.date.dt.month\n",
    "metadata['week'] = metadata.date.dt.isocalendar().week\n",
    "\n",
    "\n",
    "seasons = {\n",
    "    1: 1,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 2,\n",
    "    5: 2,\n",
    "    6: 3,\n",
    "    7: 3,\n",
    "    8: 3,\n",
    "    9: 4,\n",
    "    10: 4,\n",
    "    11: 4,\n",
    "    12: 1\n",
    "}\n",
    "\n",
    "metadata['season'] = metadata.month.map(seasons)\n",
    "\n",
    "\n",
    "region = pd.concat((train_labels, sub_format[['region', 'uid']]), axis=0)\n",
    "\n",
    "data = pd.merge(metadata, region, on='uid', how='left')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6510, 12), (23570, 12))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data[data.split == 'test']\n",
    "test_data.shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17060, 12), (23570, 12))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data[data.split == 'train']\n",
    "train_data.shape, data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Utils\n",
    "def get_data_by_date( date=None, data=train_data):\n",
    "    return data[data.date == date]\n",
    "\n",
    "\n",
    "def get_distance(lat1, lon1, lat2, lon2):\n",
    "    return geodesic((lat1, lon1), (lat2, lon2)).km\n",
    "\n",
    "def analyize_matches(y_true, y_pred):\n",
    "    print(\"Exact matches: \", sum(y_true == y_pred) / len(y_true))\n",
    "    \n",
    "    print(\"Missed by 1: \", sum(abs(y_true - y_pred) == 1) / len(y_true))\n",
    "    print(\"Missed by 2: \", sum(abs(y_true - y_pred) == 2) / len(y_true))\n",
    "    print(\"Missed by 3: \", sum(abs(y_true - y_pred) == 3) / len(y_true))\n",
    "    print(\"Missed by 4: \", sum(abs(y_true - y_pred) == 4) / len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>howw</td>\n",
       "      <td>37.0062</td>\n",
       "      <td>-120.600</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>test</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>eamn</td>\n",
       "      <td>36.9818</td>\n",
       "      <td>-120.221</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>test</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7668</th>\n",
       "      <td>imsv</td>\n",
       "      <td>36.9836</td>\n",
       "      <td>-120.500</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>test</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20182</th>\n",
       "      <td>wgxq</td>\n",
       "      <td>33.8011</td>\n",
       "      <td>-117.205</td>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>test</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16095</th>\n",
       "      <td>rsos</td>\n",
       "      <td>33.8892</td>\n",
       "      <td>-117.562</td>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>test</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>nsoi</td>\n",
       "      <td>36.7368</td>\n",
       "      <td>-121.734</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14254</th>\n",
       "      <td>prfi</td>\n",
       "      <td>36.7518</td>\n",
       "      <td>-121.742</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>howu</td>\n",
       "      <td>36.7085</td>\n",
       "      <td>-121.749</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>hfvr</td>\n",
       "      <td>36.7962</td>\n",
       "      <td>-121.782</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17559</th>\n",
       "      <td>thki</td>\n",
       "      <td>36.7254</td>\n",
       "      <td>-121.730</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6510 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid  latitude  longitude       date split  year  month  week  season  \\\n",
       "6865   howw   37.0062   -120.600 2013-01-08  test  2013      1     2       1   \n",
       "3661   eamn   36.9818   -120.221 2013-01-08  test  2013      1     2       1   \n",
       "7668   imsv   36.9836   -120.500 2013-01-08  test  2013      1     2       1   \n",
       "20182  wgxq   33.8011   -117.205 2013-01-25  test  2013      1     4       1   \n",
       "16095  rsos   33.8892   -117.562 2013-01-25  test  2013      1     4       1   \n",
       "...     ...       ...        ...        ...   ...   ...    ...   ...     ...   \n",
       "12443  nsoi   36.7368   -121.734 2021-12-29  test  2021     12    52       1   \n",
       "14254  prfi   36.7518   -121.742 2021-12-29  test  2021     12    52       1   \n",
       "6864   howu   36.7085   -121.749 2021-12-29  test  2021     12    52       1   \n",
       "6540   hfvr   36.7962   -121.782 2021-12-29  test  2021     12    52       1   \n",
       "17559  thki   36.7254   -121.730 2021-12-29  test  2021     12    52       1   \n",
       "\n",
       "      region  severity  density  \n",
       "6865    west       NaN      NaN  \n",
       "3661    west       NaN      NaN  \n",
       "7668    west       NaN      NaN  \n",
       "20182   west       NaN      NaN  \n",
       "16095   west       NaN      NaN  \n",
       "...      ...       ...      ...  \n",
       "12443   west       NaN      NaN  \n",
       "14254   west       NaN      NaN  \n",
       "6864    west       NaN      NaN  \n",
       "6540    west       NaN      NaN  \n",
       "17559   west       NaN      NaN  \n",
       "\n",
       "[6510 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_data = test_data.sort_values(by='date')\n",
    "te_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14501, 12), (2559, 12))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data, val_data = train_test_split(train_data, test_size=0.15, random_state=123456789, shuffle=True)\n",
    "tr_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14501, 12), (2559, 12))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data2, val_data2 = train_test_split(train_data, test_size=0.15, random_state=123456789, shuffle=True)\n",
    "tr_data2.shape, val_data2.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guess Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_2s = []\n",
    "g_from_past = {}\n",
    "\n",
    "n_times_called = {}\n",
    "\n",
    "def make_guess1(row: pd.Series, date=None, tr_data=tr_data) -> pd.Series:\n",
    "\n",
    "    dists = []\n",
    "    region = row.region\n",
    "    date = date\n",
    "    uid = row.uid\n",
    "    tr_data = tr_data\n",
    "\n",
    "    if date is None:\n",
    "        date = row.date\n",
    "\n",
    "    rel_data = tr_data[(tr_data.date == date) & (tr_data.region == region)]\n",
    "    \n",
    "    # check if cur date is past '2013-01-04'\n",
    "    if date < pd.to_datetime('2013-01-04'):\n",
    "        print(f'No previous data for this date filling in 2s .. for {row.uid}')\n",
    "        fill_2s.append(uid)\n",
    "        return 2\n",
    "\n",
    "    if rel_data.shape[0] == 0:\n",
    "        # print(f'No data for this date, trying previous day.. for {row.uid}')\n",
    "        if g_from_past.get(uid) is not None:\n",
    "            g_from_past[uid] += 1\n",
    "        return make_guess1(row, date=date - pd.Timedelta(days=1), tr_data=tr_data)\n",
    "\n",
    "    for some_row in rel_data.itertuples():\n",
    "        dist = get_distance(row.latitude, row.longitude, some_row.latitude, some_row.longitude)\n",
    "        dists.append(dist)\n",
    "    \n",
    "    nearest = rel_data.iloc[np.argmin(dists)]\n",
    "    return nearest.severity\n",
    "\n",
    "\n",
    "def make_guess2(row: pd.Series, date=None, tr_data=tr_data, n_times_called=None) -> pd.Series:\n",
    "    \"\"\"modified version of make_guess1, Uses mean/mode of severity for the region instead of nearest severity.\"\"\"\n",
    "    dists = []\n",
    "    region = row.region\n",
    "    date = date\n",
    "    uid = row.uid\n",
    "    tr_data = tr_data\n",
    "    \n",
    "    if n_times_called is not None:\n",
    "        if n_times_called.get(uid) is None:\n",
    "            n_times_called[uid] = 1\n",
    "        else:\n",
    "            n_times_called[uid] += 1\n",
    "        \n",
    "\n",
    "    if date is None:\n",
    "        date = row.date\n",
    "\n",
    "    rel_data = tr_data[(tr_data.date == date) & (tr_data.region == region)]\n",
    "    \n",
    "    # check if cur date is past '2013-01-04'\n",
    "    if date < pd.to_datetime('2013-01-04'):\n",
    "        print(f'No previous data for this date filling in 2s .. for {row.uid}')\n",
    "        fill_2s.append(uid)\n",
    "        return 2\n",
    "\n",
    "    if rel_data.shape[0] == 0:\n",
    "        # print(f'No data for this date, trying previous day.. for {row.uid}')\n",
    "        if g_from_past.get(uid) is not None:\n",
    "            g_from_past[uid] += 1\n",
    "        global count \n",
    "        count += 1\n",
    "        return make_guess2(row, date=date - pd.Timedelta(days=1), tr_data=tr_data)\n",
    "\n",
    "    severty_mode = rel_data.severity.mode()[0]\n",
    "    severty_mean = np.round(rel_data.severity.mean())\n",
    "\n",
    "    return severty_mean\n",
    "\n",
    "\n",
    "\n",
    "def cv_loop(rand, splits=10, guess_func=make_guess1):\n",
    "    # print(\"Random Number: \", rand)\n",
    "    skf = StratifiedKFold(n_splits=splits, shuffle=True, random_state=rand)\n",
    "    tscv = TimeSeriesSplit(n_splits=splits)\n",
    "    \n",
    "    rmses = []\n",
    "    guess_train_preds = np.zeros((train_data.shape[0]))\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(train_data, train_data.severity)):\n",
    "        print(f\"Fold: {fold}\")\n",
    "        tr_data, val_data = train_data.iloc[train_idx], train_data.iloc[val_idx]\n",
    "\n",
    "        val_data['guess'] = 0\n",
    "\n",
    "        temp = []\n",
    "        for row in tqdm(val_data.itertuples(), total=val_data.shape[0]):\n",
    "            uid_series = val_data[val_data.uid == row.uid]\n",
    "            severity = guess_func(uid_series.iloc[0], date=row.date, tr_data=tr_data)\n",
    "            val_data.loc[val_data.uid == row.uid, f'guess'] = severity\n",
    "            temp.append(severity)\n",
    "        \n",
    "        guess_train_preds[val_idx] = temp\n",
    "        \n",
    "\n",
    "                \n",
    "        errror = rmse(val_data.severity, val_data.guess1)\n",
    "        rmses.append(errror)\n",
    "        print(\"RMSE: \", errror)\n",
    "\n",
    "        print('Train Distribution: ')\n",
    "        print(tr_data.severity.value_counts(normalize=True))\n",
    "        print('Val Distribution: ')\n",
    "        print(val_data.severity.value_counts(normalize=True))\n",
    "        print('Predicted Distribution: ')\n",
    "        print(val_data.guess1.value_counts(normalize=True))\n",
    "\n",
    "    \n",
    "    print('----------------------------------------------------')\n",
    "\n",
    "    return rmses, guess_train_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data.sort_values(by='date', inplace=True)\n",
    "val_data.sort_values(by='date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data2.sort_values(by='date', inplace=True)\n",
    "val_data2.sort_values(by='date', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failed way of validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.08284486127393513 + 0.008206330597889801 + 0.0011723329425556857\n",
    "# 91% preds < 1 offs, 99% preds < 2 offs, 88% preds == 2 offs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Era VAL SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "0.9328793774319066\n"
     ]
    }
   ],
   "source": [
    "val_data2['date_reg'] = val_data2.date.astype(str) + \"_\" +  val_data2.region\n",
    "tr_data2['date_reg'] = tr_data2.date.astype(str) + \"_\" +  tr_data2.region\n",
    "\n",
    "assert (val_data2.columns == tr_data2.columns).all()\n",
    "\n",
    "print(set(val_data2.uid).intersection(set(tr_data2.uid)))\n",
    "\n",
    "#  Intersection percentage of date and regs before\n",
    "print(len(set(val_data2.date_reg).intersection(set(tr_data2.date_reg)))/val_data2.date_reg.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.372568093385214"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datereg_to_remove = val_data2.date_reg.sample(frac=0.40, random_state=123456789)\n",
    "tr_data2_ = tr_data2[~tr_data2.date_reg.isin(datereg_to_remove)]\n",
    "\n",
    "len(set(val_data2.date_reg).intersection(set(tr_data2_.date_reg)))/val_data2.date_reg.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6537013801756587"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(val_data2.date).intersection(set(tr_data2_.date)))/val_data2.date.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.701095461658842"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(test_data.date).intersection(set(train_data.date)))/test_data.date.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5712, 13), (2559, 13), (17060, 12), (2559, 12))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data2_.shape, val_data2.shape, train_data.shape, val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43902439024390244"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data3 = tr_data2.copy()\n",
    "val_data3 = val_data2.copy()\n",
    "\n",
    "datereg_to_remove = tr_data3.date_reg.sample(frac=0.60, random_state=123456789)\n",
    "val_data3_ = val_data3[~val_data3.date_reg.isin(datereg_to_remove)]\n",
    "\n",
    "len(set(val_data3_.date_reg).intersection(set(tr_data3.date_reg)))/val_data3_.date_reg.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6186440677966102"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(val_data3_.date).intersection(set(tr_data2_.date)))/val_data3_.date.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2559, 13), (137, 13), (14501, 13))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data3.shape, val_data3_.shape, tr_data3.shape\n",
    "\n",
    "#  I wonder if this is a good idea!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't foreget to clip values and trees are not good at extrapolation!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guess based on nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region\n",
       "midwest      2.194091\n",
       "northeast    1.805774\n",
       "south        1.567652\n",
       "west         3.747413\n",
       "Name: severity, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('region').severity.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_sev_map = {\n",
    "    'midwest': 2,\n",
    "    'northeast': 2,\n",
    "    'south' : 2,\n",
    "    'west' : 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(row=None, train_data=tr_data, k=1):\n",
    "    \"\"\"\n",
    "    row : pd.Series (row from val_data)\n",
    "    train_data : pd.DataFrame (all_data)\n",
    "    k : int number of nearest neighbours to consider\n",
    "    \n",
    "    algo:\n",
    "    1. Get past month data collected till the current row\n",
    "    2. Get the k nearest neighbours (geodesic dist using lat, lng) from the above data\n",
    "    3. Get the mean of the severity from the above rows\n",
    "    4. Return the mean of the nearest neighbours severity\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if row is None:\n",
    "        print('Row None bruv!')\n",
    "        return None\n",
    "    \n",
    "    uid = row.uid\n",
    "    date = row.date\n",
    "    region = row.region\n",
    "    past_date = date - pd.Timedelta(days=30)\n",
    "    \n",
    "    past_month_data = train_data[(train_data.date < date) & (train_data.date >= past_date)]\n",
    "    past_month_data.sort_values(by='date', inplace=True)\n",
    "    \n",
    "    # if no past data, return the mean of the region\n",
    "    if len(past_month_data) == 0:\n",
    "        return reg_sev_map[region]\n",
    "\n",
    "    \n",
    "    dist_matrix =pd.DataFrame(columns=['uid', 'dist'])       # 0th col for uid, 1st col for dist\n",
    "    for i, past_row in enumerate(past_month_data.itertuples()):\n",
    "        dist_matrix.loc[i, 'uid'] = past_row.uid\n",
    "        dist_matrix.loc[i, 'dist'] = get_distance(row.latitude, row.longitude, past_row.latitude, past_row.longitude)  # returns geodesic dist in km\n",
    "\n",
    "    # get top k nearest neighbours\n",
    "    n_uids = dist_matrix.sort_values(by='dist').head(k).uid.values\n",
    "    nn_severity = train_data[train_data.uid.isin(n_uids)].severity.mean()\n",
    "    \n",
    "    return np.round(nn_severity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.uid.isin(tr_data.uid).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2559/2559 [06:19<00:00,  6.74it/s]\n"
     ]
    }
   ],
   "source": [
    "#  iterate over val_data and get the severity for each row\n",
    "\n",
    "k = 10\n",
    "\n",
    "for row in tqdm(val_data.itertuples(), total=val_data.shape[0]):\n",
    "    severity = knn(row, train_data=tr_data, k=k)\n",
    "    val_data.loc[val_data.uid == row.uid, f'nn{k}_guess'] = severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8965654582604005"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(val_data.severity, val_data.nn10_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8738303744155784"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(val_data.severity, val_data.nn5_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=1 0.9515418063860925\n",
    "# k=2 0.9511310393449847\n",
    "# k=3 0.9076118558993864\n",
    "# k=4 0.8820647913897578\n",
    "# k=5 0.8738303744155784\n",
    "# k=6 0.8884654455787772\n",
    "# k=7 0.8873651783510002\n",
    "# k=8 0.8853812517340963\n",
    "# k=9 0.894165010958815\n",
    "# k=10 0.8965654582604005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14501, 13), (2559, 13), (5712, 13))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data2.shape, val_data2.shape, tr_data2_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data2.uid.isin(tr_data2_.uid).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data2_['latlng'] = tr_data2_.latitude.astype(str) + \"_\" + tr_data2_.longitude.astype(str)\n",
    "val_data2['latlng'] = val_data2.latitude.astype(str) + \"_\" + val_data2.longitude.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1574023115024766"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tr_data2_.latlng).intersection(set(val_data2.latlng)))/len(set(val_data2.latlng))\n",
    "# 15% intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2559/2559 [03:32<00:00, 12.02it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(val_data2.itertuples(), total=val_data2.shape[0]):\n",
    "    severity = knn(row, train_data=tr_data2_, k=5)\n",
    "    val_data2.loc[val_data2.uid == row.uid, f'nn5_guess'] = severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.010882559084407"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(val_data2.severity, val_data2.nn5_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14501, 13), (2559, 13), (137, 14))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data3.shape, val_data3.shape, val_data3_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data3_.uid.isin(tr_data3.uid).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5964912280701754"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data3['latlng'] = tr_data3.latitude.astype(str) + \"_\" + tr_data3.longitude.astype(str)\n",
    "val_data3_['latlng'] = val_data3_.latitude.astype(str) + \"_\" + val_data3_.longitude.astype(str)\n",
    "\n",
    "len(set(tr_data3.latlng).intersection(set(val_data3_.latlng)))/len(set(val_data3_.latlng))\n",
    "# 60% intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:18<00:00,  7.59it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(val_data3_.itertuples(), total=val_data3_.shape[0]):\n",
    "    severity = knn(row, train_data=tr_data3, k=5)\n",
    "    val_data3_.loc[val_data3_.uid == row.uid, f'nn5_guess'] = severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9778570343163892"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(val_data3_.severity, val_data3_.nn5_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2559"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "      <th>latlng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>evep</td>\n",
       "      <td>44.847993</td>\n",
       "      <td>-93.476318</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>44.847993_-93.476318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13644</th>\n",
       "      <td>paev</td>\n",
       "      <td>44.822478</td>\n",
       "      <td>-93.367962</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>44.822478_-93.367962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>gdxr</td>\n",
       "      <td>44.877646</td>\n",
       "      <td>-93.557842</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>44.877646_-93.557842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>guny</td>\n",
       "      <td>44.878889</td>\n",
       "      <td>-93.490833</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>44.878889_-93.490833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5317</th>\n",
       "      <td>fwbt</td>\n",
       "      <td>44.850500</td>\n",
       "      <td>-93.515700</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>train</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>midwest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>44.8505_-93.5157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>nsoi</td>\n",
       "      <td>36.736800</td>\n",
       "      <td>-121.734000</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.7368_-121.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17559</th>\n",
       "      <td>thki</td>\n",
       "      <td>36.725400</td>\n",
       "      <td>-121.730000</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.7254_-121.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17452</th>\n",
       "      <td>teuu</td>\n",
       "      <td>36.772300</td>\n",
       "      <td>-121.788000</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.7723_-121.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14254</th>\n",
       "      <td>prfi</td>\n",
       "      <td>36.751800</td>\n",
       "      <td>-121.742000</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.7518_-121.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>howu</td>\n",
       "      <td>36.708500</td>\n",
       "      <td>-121.749000</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>test</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.7085_-121.749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23570 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid   latitude   longitude       date  split  year  month  week  \\\n",
       "4387   evep  44.847993  -93.476318 2013-01-04  train  2013      1     1   \n",
       "13644  paev  44.822478  -93.367962 2013-01-04  train  2013      1     1   \n",
       "5566   gdxr  44.877646  -93.557842 2013-01-04  train  2013      1     1   \n",
       "6144   guny  44.878889  -93.490833 2013-01-04  train  2013      1     1   \n",
       "5317   fwbt  44.850500  -93.515700 2013-01-04  train  2013      1     1   \n",
       "...     ...        ...         ...        ...    ...   ...    ...   ...   \n",
       "12443  nsoi  36.736800 -121.734000 2021-12-29   test  2021     12    52   \n",
       "17559  thki  36.725400 -121.730000 2021-12-29   test  2021     12    52   \n",
       "17452  teuu  36.772300 -121.788000 2021-12-29   test  2021     12    52   \n",
       "14254  prfi  36.751800 -121.742000 2021-12-29   test  2021     12    52   \n",
       "6864   howu  36.708500 -121.749000 2021-12-29   test  2021     12    52   \n",
       "\n",
       "       season   region  severity  density                latlng  \n",
       "4387        1  midwest       1.0    115.0  44.847993_-93.476318  \n",
       "13644       1  midwest       1.0   1884.0  44.822478_-93.367962  \n",
       "5566        1  midwest       1.0   1416.0  44.877646_-93.557842  \n",
       "6144        1  midwest       1.0    558.0  44.878889_-93.490833  \n",
       "5317        1  midwest       1.0    476.0      44.8505_-93.5157  \n",
       "...       ...      ...       ...      ...                   ...  \n",
       "12443       1     west       NaN      NaN      36.7368_-121.734  \n",
       "17559       1     west       NaN      NaN       36.7254_-121.73  \n",
       "17452       1     west       NaN      NaN      36.7723_-121.788  \n",
       "14254       1     west       NaN      NaN      36.7518_-121.742  \n",
       "6864        1     west       NaN      NaN      36.7085_-121.749  \n",
       "\n",
       "[23570 rows x 13 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12681"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['latlng'] = data.latitude.astype(str) + '_' + data.longitude.astype(str)\n",
    "\n",
    "data['latlng'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3175115207373272"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.split == 'test'].latlng.nunique()/len(data[data.split == 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6221570926143024"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.split == 'train'].latlng.nunique()/len(data[data.split == 'train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data[data.split == 'test'].latlng).intersection(set(data[data.split == 'train'].latlng))\n",
    "# no common latlngs between test and train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aabn</td>\n",
       "      <td>36.559700</td>\n",
       "      <td>-121.510000</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>test</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aair</td>\n",
       "      <td>33.042600</td>\n",
       "      <td>-117.076000</td>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>test</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aajw</td>\n",
       "      <td>40.703968</td>\n",
       "      <td>-80.293050</td>\n",
       "      <td>2015-08-26</td>\n",
       "      <td>test</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>northeast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aalr</td>\n",
       "      <td>38.972500</td>\n",
       "      <td>-94.672930</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>test</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aalw</td>\n",
       "      <td>34.279000</td>\n",
       "      <td>-118.905000</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>test</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23556</th>\n",
       "      <td>zzpn</td>\n",
       "      <td>40.136410</td>\n",
       "      <td>-80.473740</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>test</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>northeast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23560</th>\n",
       "      <td>zzrv</td>\n",
       "      <td>36.875400</td>\n",
       "      <td>-121.561000</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>test</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23563</th>\n",
       "      <td>zzsx</td>\n",
       "      <td>34.210000</td>\n",
       "      <td>-78.929389</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>test</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>south</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23565</th>\n",
       "      <td>zzvv</td>\n",
       "      <td>36.708500</td>\n",
       "      <td>-121.749000</td>\n",
       "      <td>2014-12-02</td>\n",
       "      <td>test</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23569</th>\n",
       "      <td>zzzi</td>\n",
       "      <td>39.767323</td>\n",
       "      <td>-96.028617</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>test</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6510 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid   latitude   longitude       date split  year  month  week  \\\n",
       "1      aabn  36.559700 -121.510000 2016-08-31  test  2016      8    35   \n",
       "12     aair  33.042600 -117.076000 2014-11-01  test  2014     11    44   \n",
       "14     aajw  40.703968  -80.293050 2015-08-26  test  2015      8    35   \n",
       "15     aalr  38.972500  -94.672930 2019-08-26  test  2019      8    35   \n",
       "16     aalw  34.279000 -118.905000 2018-01-08  test  2018      1     2   \n",
       "...     ...        ...         ...        ...   ...   ...    ...   ...   \n",
       "23556  zzpn  40.136410  -80.473740 2019-07-08  test  2019      7    28   \n",
       "23560  zzrv  36.875400 -121.561000 2019-09-17  test  2019      9    38   \n",
       "23563  zzsx  34.210000  -78.929389 2019-07-16  test  2019      7    29   \n",
       "23565  zzvv  36.708500 -121.749000 2014-12-02  test  2014     12    49   \n",
       "23569  zzzi  39.767323  -96.028617 2015-08-31  test  2015      8    36   \n",
       "\n",
       "       season     region  severity  density  \n",
       "1           3       west       NaN      NaN  \n",
       "12          4       west       NaN      NaN  \n",
       "14          3  northeast       NaN      NaN  \n",
       "15          3    midwest       NaN      NaN  \n",
       "16          1       west       NaN      NaN  \n",
       "...       ...        ...       ...      ...  \n",
       "23556       3  northeast       NaN      NaN  \n",
       "23560       4       west       NaN      NaN  \n",
       "23563       3      south       NaN      NaN  \n",
       "23565       1       west       NaN      NaN  \n",
       "23569       3    midwest       NaN      NaN  \n",
       "\n",
       "[6510 rows x 12 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 5\n",
    "\n",
    "# for row in tqdm(test_data.itertuples(), total=test_data.shape[0]):\n",
    "#     severity = knn(row, train_data=train_data, k=k)\n",
    "#     test_data.loc[test_data.uid == row.uid, f'nn{k}_guess'] = severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6510"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  parrllelize the above code\n",
    "k = 5\n",
    "sev_list = Parallel(n_jobs=-1, backend='loky')([delayed(knn)(row, train_data=train_data, k=k) for row in test_data.itertuples()])\n",
    "len(sev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "      <th>severity</th>\n",
       "      <th>density</th>\n",
       "      <th>nn5_guess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aabn</td>\n",
       "      <td>36.559700</td>\n",
       "      <td>-121.51000</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>test</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>aair</td>\n",
       "      <td>33.042600</td>\n",
       "      <td>-117.07600</td>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>test</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aajw</td>\n",
       "      <td>40.703968</td>\n",
       "      <td>-80.29305</td>\n",
       "      <td>2015-08-26</td>\n",
       "      <td>test</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>northeast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aalr</td>\n",
       "      <td>38.972500</td>\n",
       "      <td>-94.67293</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>test</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>midwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aalw</td>\n",
       "      <td>34.279000</td>\n",
       "      <td>-118.90500</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>test</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>west</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid   latitude  longitude       date split  year  month  week  season  \\\n",
       "1   aabn  36.559700 -121.51000 2016-08-31  test  2016      8    35       3   \n",
       "12  aair  33.042600 -117.07600 2014-11-01  test  2014     11    44       4   \n",
       "14  aajw  40.703968  -80.29305 2015-08-26  test  2015      8    35       3   \n",
       "15  aalr  38.972500  -94.67293 2019-08-26  test  2019      8    35       3   \n",
       "16  aalw  34.279000 -118.90500 2018-01-08  test  2018      1     2       1   \n",
       "\n",
       "       region  severity  density  nn5_guess  \n",
       "1        west       NaN      NaN        4.0  \n",
       "12       west       NaN      NaN        4.0  \n",
       "14  northeast       NaN      NaN        1.0  \n",
       "15    midwest       NaN      NaN        4.0  \n",
       "16       west       NaN      NaN        4.0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  hoping sev_list is in the same order as test_data\n",
    "test_data[f'nn{k}_guess'] = sev_list\n",
    "test_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['severity', 'uid', 'date'], axis=1)\n",
    "y_train = train_data.severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(n_estimators=1000, random_state=123456789, tree_method='gpu_hist', gpu_id=0)\n",
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_eval(model, X_train=None, X_val=None, y_train=None, y_val=None, X_test=None, y_test=None):\n",
    "    \"\"\"\n",
    "    train and eval util func,\n",
    "    returns trained model, soft_preds, and rmse\n",
    "    REMEMBER to round myself\n",
    "    \"\"\"\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "    rmse = mse(y_val, np.round(preds), squared=False)\n",
    "    test_rmse = mse(y_test, np.round(model.predict(X_test)), squared=False)\n",
    "    print(\"Train RMSE: \", mse(y_train, np.round(model.predict(X_train)), squared=False))\n",
    "    print(\"Val RMSE:\", rmse)\n",
    "    print('TEST RMSE: ', test_rmse)\n",
    "    \n",
    "    # print(\"TEST RMSE:\", mse(y_val, np.round(model.predict(X_val)), squared=False))\n",
    "    return model, preds, rmse, test_rmse\n",
    "\n",
    "\n",
    "def cv_it(model, X_train=X_train, y_train=y_train, X_test=None, y_test=None, splits=10, cv_predict=False):\n",
    "#     skf = StratifiedKFold(n_splits=splits, random_state=config.RANDOM_STATE, shuffle=True)\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=splits, test_size=200)\n",
    "    \n",
    "    val_rmse = []\n",
    "    test_rmses = []\n",
    "    \n",
    "    if cv_predict:\n",
    "        cvpreds_test = np.zeros(shape=(6510, splits))\n",
    "        cvpreds_train = np.zeros(shape=(len(X_train)))\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train, y_train)):\n",
    "\n",
    "        print(f'-----------------------Fold-{fold}-------------------------')\n",
    "        X_train_subset, y_train_subset = X_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        X_val_subset, y_val_subset = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        print(f'Training on {X_train_subset.shape[0]} samples' )\n",
    "        print(f'Validating on {X_val_subset.shape[0]} samples' )\n",
    "\n",
    "        model, val_preds, rmse, test_rmse= train_eval(\n",
    "                                    model=model, \n",
    "                                    X_train=X_train_subset, \n",
    "                                    y_train=y_train_subset, \n",
    "                                    X_val=X_val_subset, \n",
    "                                    y_val=y_val_subset,\n",
    "                                    X_test=X_test,\n",
    "                                    y_test=y_test)\n",
    "        val_rmse.append(rmse)\n",
    "        test_rmses.append(test_rmse)\n",
    "        \n",
    "        if cv_predict:\n",
    "            # save predictions for ensembling\n",
    "            cvpreds_test[:, fold] = model.predict(X_test)\n",
    "            cvpreds_train[val_idx] = val_preds\n",
    "                    \n",
    "    print()\n",
    "    print(\"Mean Val RMSE:\", np.mean(val_rmse), \"std:\", np.std(val_rmse))\n",
    "    print(\"Mean Test RMSE:\", np.mean(test_rmses), \"std:\", np.std(test_rmses))\n",
    "\n",
    "    \n",
    "    if cv_predict:\n",
    "        return cvpreds_test, cvpreds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Fold-0-------------------------\n",
      "Training on 3756 samples\n",
      "Validating on 1000 samples\n",
      "Train RMSE:  0.40497439406819935\n",
      "Val RMSE: 0.9523654760647301\n",
      "TEST RMSE:  0.9606356350066096\n",
      "-----------------------Fold-1-------------------------\n",
      "Training on 4756 samples\n",
      "Validating on 1000 samples\n",
      "Train RMSE:  0.4433889672540245\n",
      "Val RMSE: 0.8012490249604052\n",
      "TEST RMSE:  0.9506592589536919\n",
      "-----------------------Fold-2-------------------------\n",
      "Training on 5756 samples\n",
      "Validating on 1000 samples\n",
      "Train RMSE:  0.4450328126200894\n",
      "Val RMSE: 0.8882567196480982\n",
      "TEST RMSE:  0.9149683438337731\n",
      "-----------------------Fold-3-------------------------\n",
      "Training on 6756 samples\n",
      "Validating on 1000 samples\n",
      "Train RMSE:  0.47182298915642806\n",
      "Val RMSE: 0.8276472678623424\n",
      "TEST RMSE:  0.8819552348728436\n",
      "-----------------------Fold-4-------------------------\n",
      "Training on 7756 samples\n",
      "Validating on 1000 samples\n",
      "Train RMSE:  0.4760916177252889\n",
      "Val RMSE: 0.9813256340277675\n",
      "TEST RMSE:  0.8283344822762391\n",
      "-----------------------Fold-5-------------------------\n",
      "Training on 8756 samples\n",
      "Validating on 1000 samples\n",
      "Train RMSE:  0.47227857610637336\n",
      "Val RMSE: 0.9803060746521975\n",
      "TEST RMSE:  0.8228354096538051\n",
      "-----------------------Fold-6-------------------------\n",
      "Training on 9756 samples\n",
      "Validating on 1000 samples\n",
      "Train RMSE:  0.4731408232465111\n",
      "Val RMSE: 0.7968688725254613\n",
      "TEST RMSE:  0.8735070279311073\n",
      "-----------------------Fold-7-------------------------\n",
      "Training on 10756 samples\n",
      "Validating on 1000 samples\n",
      "Train RMSE:  0.47236773341023763\n",
      "Val RMSE: 0.9332738076256079\n",
      "TEST RMSE:  0.8635755391767456\n",
      "-----------------------Fold-8-------------------------\n",
      "Training on 11756 samples\n",
      "Validating on 1000 samples\n",
      "Train RMSE:  0.475317984214491\n",
      "Val RMSE: 0.7321202087089251\n",
      "TEST RMSE:  0.8658506433339086\n",
      "-----------------------Fold-9-------------------------\n",
      "Training on 12756 samples\n",
      "Validating on 1000 samples\n",
      "Train RMSE:  0.4723459463224092\n",
      "Val RMSE: 0.9137833441248533\n",
      "TEST RMSE:  0.84210476535604\n",
      "\n",
      "Mean Val RMSE: 0.8807196430200388 std: 0.08205431371143952\n",
      "Mean Test RMSE: 0.8804426340394764 std: 0.045392484055490526\n"
     ]
    }
   ],
   "source": [
    "cv_it(xgb, X_test=X_val, y_test=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13644</th>\n",
       "      <td>44.822478</td>\n",
       "      <td>-93.367962</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>44.847993</td>\n",
       "      <td>-93.476318</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>44.877646</td>\n",
       "      <td>-93.557842</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>44.878889</td>\n",
       "      <td>-93.490833</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5317</th>\n",
       "      <td>44.850500</td>\n",
       "      <td>-93.515700</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        latitude  longitude  year  month  week  season  region\n",
       "13644  44.822478 -93.367962  2013      1     1       1       1\n",
       "4387   44.847993 -93.476318  2013      1     1       1       1\n",
       "5566   44.877646 -93.557842  2013      1     1       1       1\n",
       "6144   44.878889 -93.490833  2013      1     1       1       1\n",
       "5317   44.850500 -93.515700  2013      1     1       1       1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data2_new = tr_data2_.copy()\n",
    "val_data2_new = val_data2.copy()\n",
    "\n",
    "X_train2 = tr_data2_new.drop(drop_cols, axis=1)\n",
    "y_train2 = tr_data2_new['severity']\n",
    "X_val2 = val_data2_new.drop(drop_cols, axis=1)\n",
    "y_val2 = val_data2_new['severity']\n",
    "\n",
    "X_train2['region'] = X_train2['region'].map({'midwest': 1, 'west': 2, 'south': 3, 'northeast': 4}) \n",
    "X_train2.week = X_train2.week.astype('int')\n",
    "X_val2['region'] = X_val2['region'].map({'midwest': 1, 'west': 2, 'south': 3, 'northeast': 4})\n",
    "X_val2.week = X_val2.week.astype('int')\n",
    "\n",
    "X_val2.drop('date_reg', axis=1, inplace=True)\n",
    "X_train2.drop('date_reg', axis=1, inplace=True)\n",
    "\n",
    "X_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (X_val2.columns == X_train2.columns).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Fold-0-------------------------\n",
      "Training on 3712 samples\n",
      "Validating on 200 samples\n",
      "Train RMSE:  0.3207950790748211\n",
      "Val RMSE: 0.8306623862918074\n",
      "TEST RMSE:  0.8257766010973492\n",
      "-----------------------Fold-1-------------------------\n",
      "Training on 3912 samples\n",
      "Validating on 200 samples\n",
      "Train RMSE:  0.3091977878052171\n",
      "Val RMSE: 0.5196152422706632\n",
      "TEST RMSE:  0.8219820877364625\n",
      "-----------------------Fold-2-------------------------\n",
      "Training on 4112 samples\n",
      "Validating on 200 samples\n",
      "Train RMSE:  0.3153806914583502\n",
      "Val RMSE: 0.7905694150420949\n",
      "TEST RMSE:  0.7963869172221666\n",
      "-----------------------Fold-3-------------------------\n",
      "Training on 4312 samples\n",
      "Validating on 200 samples\n",
      "Train RMSE:  0.3083561057294485\n",
      "Val RMSE: 1.036822067666386\n",
      "TEST RMSE:  0.8073519158712397\n",
      "-----------------------Fold-4-------------------------\n",
      "Training on 4512 samples\n",
      "Validating on 200 samples\n",
      "Train RMSE:  0.3122782901459112\n",
      "Val RMSE: 0.6324555320336759\n",
      "TEST RMSE:  0.7924516891030828\n",
      "-----------------------Fold-5-------------------------\n",
      "Training on 4712 samples\n",
      "Validating on 200 samples\n",
      "Train RMSE:  0.31142642414709426\n",
      "Val RMSE: 0.6928203230275509\n",
      "TEST RMSE:  0.7966322235323805\n",
      "-----------------------Fold-6-------------------------\n",
      "Training on 4912 samples\n",
      "Validating on 200 samples\n",
      "Train RMSE:  0.3089991197820127\n",
      "Val RMSE: 1.002496882788171\n",
      "TEST RMSE:  0.8145799196435658\n",
      "-----------------------Fold-7-------------------------\n",
      "Training on 5112 samples\n",
      "Validating on 200 samples\n",
      "Train RMSE:  0.3235053508832246\n",
      "Val RMSE: 0.7483314773547883\n",
      "TEST RMSE:  0.7936835438636244\n",
      "-----------------------Fold-8-------------------------\n",
      "Training on 5312 samples\n",
      "Validating on 200 samples\n",
      "Train RMSE:  0.3255555955334396\n",
      "Val RMSE: 0.7483314773547883\n",
      "TEST RMSE:  0.7971226096813349\n",
      "-----------------------Fold-9-------------------------\n",
      "Training on 5512 samples\n",
      "Validating on 200 samples\n",
      "Train RMSE:  0.32354396403244606\n",
      "Val RMSE: 0.8246211251235321\n",
      "TEST RMSE:  0.7867603152608819\n",
      "\n",
      "Mean Val RMSE: 0.7826725928953457 std: 0.14806624304842844\n",
      "Mean Test RMSE: 0.8032727823012088 std: 0.012696450517041184\n"
     ]
    }
   ],
   "source": [
    "cv_it(xgb, X_train=X_train2, y_train=y_train2, X_test=X_val2, y_test=y_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9307388359437742"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.7826725928953457  + 0.14806624304842844"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.806625553226778"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train2, y_train2)\n",
    "preds = xgb.predict(X_val2)  # new validation set with lng and lats !\n",
    "preds = np.clip(np.round(preds), 1, 5)\n",
    "rmse(y_val2, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.364596\n",
       "2.0    0.305588\n",
       "4.0    0.199297\n",
       "3.0    0.129347\n",
       "5.0    0.001172\n",
       "dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(preds).apply(np.round).clip(1, 5).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>season</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13644</th>\n",
       "      <td>44.822478</td>\n",
       "      <td>-93.367962</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>44.847993</td>\n",
       "      <td>-93.476318</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>44.877646</td>\n",
       "      <td>-93.557842</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>44.878889</td>\n",
       "      <td>-93.490833</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5317</th>\n",
       "      <td>44.850500</td>\n",
       "      <td>-93.515700</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        latitude  longitude  year  month  week  season  region\n",
       "13644  44.822478 -93.367962  2013      1     1       1       1\n",
       "4387   44.847993 -93.476318  2013      1     1       1       1\n",
       "5566   44.877646 -93.557842  2013      1     1       1       1\n",
       "6144   44.878889 -93.490833  2013      1     1       1       1\n",
       "5317   44.850500 -93.515700  2013      1     1       1       1"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_data3new = tr_data3.copy()\n",
    "val_data3__new = val_data3_.copy()\n",
    "\n",
    "X_train3 = tr_data3new.drop(drop_cols, axis=1)\n",
    "y_train3 = tr_data3new['severity']\n",
    "X_val3 = val_data3__new.drop(drop_cols, axis=1)\n",
    "y_val3 = val_data3__new['severity']\n",
    "\n",
    "X_train3['region'] = X_train3['region'].map({'midwest': 1, 'west': 2, 'south': 3, 'northeast': 4}) \n",
    "X_train3.week = X_train3.week.astype('int')\n",
    "X_val3['region'] = X_val3['region'].map({'midwest': 1, 'west': 2, 'south': 3, 'northeast': 4})\n",
    "X_val3.week = X_val3.week.astype('int')\n",
    "\n",
    "X_val3.drop('date_reg', axis=1, inplace=True)\n",
    "X_train3.drop('date_reg', axis=1, inplace=True)\n",
    "\n",
    "X_train3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8014585244561053"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train3, y_train3)\n",
    "preds = xgb.predict(X_val3)  # new validation set with lng and lats !\n",
    "preds = np.clip(np.round(preds), 1, 5)\n",
    "rmse(y_val3, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49635036496350365"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3['latlng'] = X_train3['latitude'].astype('str') + X_train3['longitude'].astype('str')\n",
    "X_val3['latlng'] = X_val3['latitude'].astype('str') + X_val3['longitude'].astype('str')\n",
    "\n",
    "len(set(X_train3.latlng.unique()) & set(X_val3.latlng.unique()))/len(X_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    2198\n",
       "1    1963\n",
       "2    1631\n",
       "3     718\n",
       "Name: severity, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Making submission with knn-5 @ 1.00\n",
    "\n",
    "assert sub_format.uid.equals(test_data.reset_index().uid) == True\n",
    "\n",
    "sub_format.severity = test_data.nn5_guess.values\n",
    "\n",
    "sub_format.severity = sub_format.severity.astype(int)\n",
    "sub_format.severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save submission\n",
    "sub_format.to_csv('../submissions/to submit/nn5_guess_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  May be its better if start from "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sooo....\n",
    "\n",
    "Why am I behind?\n",
    "\n",
    "- They clearly saw something in metadata that I didn't\n",
    "- I know for a fact that no one on the top is using images as features\n",
    "- How the train test split was done :\n",
    "    - No overlapping geo locations\n",
    "    - only 51% of test date_regs are in train vs 92% in val\n",
    "    \n",
    "\n",
    "# Todos :\n",
    "\n",
    "- idk.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "186db977f413ae6598820b658aed1651932768522d0652c07d949b3f5fb38b63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
